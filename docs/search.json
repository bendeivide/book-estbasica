[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estatística Básica aplicada às Ciências Agrárias",
    "section": "",
    "text": "Bem-vindo\nEsse é um livro digital intitulado “Estatística Básica aplicada às Ciências Agrárias”, com o selo Democratizando Conhecimento (DC). Este livro é um convite à leitura para as bases da Estatística Básica, apresentando de forma aplicada os conceitos tão importantes para a área da ciência de uma forma geral. Todos os exemplos são aplicados às Ciências Agrárias.   O número de leitores que acessaram esse livro: \n\n\n \n\n\n\nLivro físico\n\n\nISBN\n\nISBN (Digital): 978-65-01-05500-8\nISBN (Físico): 978-65-01-05508-4\n\n\n\nLicença\n\n\n\n\n\nEste trabalho está sob a Licença Creative Commons - Atribuição-NãoComercial 4.0 Internacional.\n\n\n\n\n\n\n\nUsamos também a filosofia de trabalho com o Selo Democratizando Conhecimento (DC), que pode ser acessada em https://bendeivide.github.io/dc/. O leitor é livre para compartilhar, redistribuir, transformar ou adaptar esta obra, desde que não venha a utilizá-la em nenhuma atividade de propósito comercial. Por fim, a única exigência é a atribuição dos créditos aos autores da obra.\n\n\n \n\n\nComo citar\n\nComo citar essa obra (Impressa):\n\nCUSTÓDIO, T. C.; BATISTA, B. D. O.. Estatística Básica Aplicada às Ciências Agrárias. Ouro Branco, MG: [s.n.]. 2024. 336 p. ISBN 978-65-01-05508-4.\n\nComo citar essa obra (Digital):\n\nCUSTÓDIO, T. C.; BATISTA, B. D. O.. Estatística Básica Aplicada às Ciências Agrárias. Ouro Branco, MG: [s.n.]. 2024. ISBN 978-65-01-05500-8. Disponível em: https://bendeivide. github.io/book-estbasica/. Acesso em: 10 de junho de 2024.\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "cap01.html",
    "href": "cap01.html",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "",
    "text": "1.1 Introdução\nEm todo processo produtivo do setor agropecuário constantemente se busca a melhoria da qualidade de seus produtos e serviços. Uma porção significativa deste esforço de melhoria da qualidade será comandada por profissionais das ciências agrárias, pois esses profissionais projetam e desenvolvem novos sistemas e processos de produção, sendo também aqueles que melhoram os sistemas de produção existentes.\nNas diferentes áreas das ciências agrárias frequentemente trabalha-se com um grande volume de dados, sendo necessário dar um tratamento matemático a esses dados. Assim surge a Ciência Estatística, pois seus métodos são uma importante ferramenta nessas atividades, porque eles proveem os profissionais envolvidos com métodos descritivos e analíticos, para lidar com a variabilidade nos dados observados.\nPara o entendimento da Estatística se faz necessário que uma série de termos, definições e apresentação de alguns teoremas sejam apresentados e compreendidos. Assim, ao longo de todo o livro será realizado uma abordagem de todas essas informações, sem se estender ao rigor matemático, para que de forma prática a base necessária para o conhecimento da Estatística seja acessível a todos os níveis de aprendizagem dentro das ciências agrárias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#definições-gerais",
    "href": "cap01.html#definições-gerais",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "1.2 Definições Gerais",
    "text": "1.2 Definições Gerais\nA seguir são apresentados alguns termos que serão empregados no decorrer deste livro.\n\n1.2.1 Estatística\nEstatística pode ser definida como sendo um conjunto de técnicas que permite: coletar, organizar, analisar e interpretar dados oriundos de estudos ou experimentos, realizados em qualquer área do conhecimento.\n\nExemplo 1.1 Seja uma área cultivada com algodão em que se mede a altura de vinte plantas.\n\nColeta:\n\n1ª planta: \\(1,0\\) m;\n2ª planta: \\(1,5\\) m;\n3ª planta: \\(1,3\\) m;\n\\(\\qquad\\vdots\\)\n20ª planta: \\(0,8\\) m.\n\nOrganização: Tabelas e gráficos.\nAnálise: Qual é a altura média?\nInterpretação: Por que tão baixa (ou tão alta) essa altura média?\n\n\n\n\n1.2.2 População\nUm conjunto de elementos com pelo menos uma característica em comum é chamado de população. Corresponde, portanto, ao grande conjunto de dados que contém a característica que se deseja descrever.\n\nExemplo 1.2  \n\nPlantas de uma determinada cultura;\nAnimais de um rebanho;\nÁrvores de um povoamento florestal;\nTratores de uma região produtora de grãos;\netc.\n\n\nO tamanho da população, ou seja, o número de elementos que a compõem, é representado pela letra maiúscula “\\(N\\)”.\n\n\n1.2.3 Censo\nUm estudo envolvendo todos os elementos de uma população é denominado censo.\n\nExemplo 1.3  \n\nLevantamento de dados referentes a situação sanitária do rebanho bovino leiteiro da região Sul de Minas Gerais;\nContagem do número de máquinas agrícolas nas propriedades rurais de uma determinada região;\nLevantamento sócio-econômico das famílias de uma comunidade rural, de uma determinada região produtora de cana-de-açúcar;\netc.\n\n\n\n\n1.2.4 Amostra\nEm muitos casos na execução de uma pesquisa é impossível avaliar todos os elementos de uma população, isto por problemas de custo e/ou tempo. Quando este é o caso, conhece-se a população a partir do estudo de uma parte dela, chamada amostra. Assim amostra é um subconjunto de elementos que pertence a uma população.\n\nExemplo 1.4  \n\n30 plantas de uma determinada cultura;\n100 bovinos leiteiros da região sul de Minas Gerais;\n20 pés de café de uma lavoura;\n200 árvores de um povoamento florestal;\n15 tratores de uma região produtora de grãos;\netc.\n\n\nO tamanho da amostra, isto é, o número de elementos que a compõem, é representado pela letra minúscula “\\(n\\)”.\n\n\n1.2.5 Variável\nUma variável é a característica pela qual deseja-se que a população seja descrita. Pode assumir diferentes valores de elemento para elemento.\nSão usadas as seguintes notações para variável: \\(X\\), \\(Y\\), \\(Z\\), etc. (letras maiúsculas).\n\nExemplo 1.5  \n\n\\(X\\): Peso, em kg, de bovinos da raça nelore.\n\n\nAs variáveis podem ser qualitativas ou quantitativas.\n\n1.2.5.1 Variável Qualitativa\nAs variáveis qualitativas correspondem a atributos ou categorias. Subdivididas em:\n\nVariável Qualitativa Nominal: Quando os atributos não são passíveis de ordenação.\n\n\nExemplo 1.6  \n\n\\(X\\): Culturas predominantes numa região: milho, cana, soja, etc;\n\\(Y\\): Atividades exercidas pelos produtores rurais de uma determinada região: pecuária leiteira, avicultura, suinocultura, produção de hortaliças, etc.\n\n\n\nVariável Qualitativa Ordinal: Quando os atributos são passíveis de ordenação.\n\n\nExemplo 1.7  \n\n\\(X\\): Graus de ataque de insetos numa lavoura: baixo, médio, alto;\n\\(Y\\): Índice de tecnificação adotado pelos agricultores de uma determinada região: baixo, médio, alto;\n\n\n\n\n1.2.5.2 Variável Quantitativa\nAs variáveis quantitativas correspondem a números resultantes de contagens ou medidas. Podem ser:\n\nVariável Quantitativa Discreta: São próprias de dados de contagem, isto é, estão definidas em um conjunto enumerável de valores.\n\n\nExemplo 1.8  \n\n\\(X\\): Número de ovos depositados por um inseto nas folhas de uma cultura: \\(5\\), \\(3\\), \\(10\\), etc;\n\\(Y\\): Número de tratores nas propriedades rurais de uma região: \\(1\\), \\(2\\), \\(0\\), \\(3\\), \\(1\\), etc;\n\\(Z\\): Número de animais infectados pela febre aftosa em fazendas leiteiras de uma região produtora de leite: \\(4\\), \\(2\\), \\(6\\), \\(5\\), etc.\n\n\n\nVariável Quantitativa Contínua: São aquelas em que as realizações resultam de uma medida, e que podem assumir qualquer valor real dentro de um intervalo de valores.\n\n\nExemplo 1.9  \n\n\\(X\\): Altura dos pés de algodão: 1,0 m; 1,5 m; 0,8 m; etc;\n\\(Y\\): Pesos de bezerras da raça holandesa de uma fazenda produtora de leite: 32,0 kg; 28,0 kg; 26,0 kg; etc.\n\n\n\n\n\n1.2.6 Dado\nDado é a realização de uma variável, ou seja, é o valor registrado para um elemento em particular. As notações utilizadas para o dado são: \\(x\\), \\(y\\), \\(z\\), etc. (letras minúsculas).\n\nExemplo 1.10 Considere a variável:\n\n\\(X\\): Peso, em kg, de bovinos da raça nelore.\n\nPode-se ter, por exemplo, os seguintes dados:\n\n\\(x_1 = 322,0\\) kg;\n\\(x_2 = 335,0\\) kg;\n\\(x_3 = 318,0\\) kg;\netc.\n\n\n\n\n1.2.7 Divisão da Estatística\nA Estatística pode ser dividida basicamente em duas partes:\n\nEstatística Descritiva: É utilizada na fase inicial da análise, ou seja, quando se tem um primeiro contato com os dados, onde se objetiva tirar conclusões de modo informal e direto de características de interesse. Pode ser definida como sendo um conjunto de técnicas para descrever e resumir um conjunto de dados, sejam eles amostrais ou populacionais.\nInferência Estatística: É um conjunto de técnicas responsáveis pela análise e interpretação dos dados, obtidos a partir de uma amostra, que possibilita a extrapolação dos resultados para toda a população de interesse.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#técnicas-de-somatório",
    "href": "cap01.html#técnicas-de-somatório",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "1.3 Técnicas de Somatório",
    "text": "1.3 Técnicas de Somatório\nEm estatística frequentemente trabalha-se com variáveis quantitativas, e nos próximos capítulos aparecerão diversas expressões que envolverão cálculos de somas, somas de termos ao quadrado, produtos de duas variáveis, e para isso é necessário uma simplificação da notação. Assim, é usual representar somas por um operador chamado somatório, que é representado pela letra grega sigma maiúscula (\\(\\Sigma\\)).\nPor exemplo, a soma: \\[\\begin{align*}\n  x_1 + x_2 + x_3 + x_4 + x_5,\n\\end{align*}\\] pode ser representada em notação de somatório da seguinte forma: \\[\\begin{align*}\n  \\sum_{i=1}^{5}x_i,\n\\end{align*}\\] ou seja, corresponde à soma dos termos \\(x_i\\) onde o índice \\(i\\) varia de \\(1\\) a \\(5\\).\n\n1.3.1 Propriedades\nSejam \\(X\\), \\(Y\\) e \\(Z\\) variáveis quantitativas, e sejam \\(a\\) e \\(b\\) valores constantes. Assim o operador somatório apresenta as seguintes propriedades, dadas por:\n\n\\(\\sum_{i=1}^{n}a=a+a+\\ldots+a=n a\\);\n\\(\\sum_{i=1}^{n}ax_{i}=ax_{1}+ax_{2}+ \\ldots +ax_{n}=a(x_{1}+x_{2}+\\ldots+x_{n})=a\\sum_{i=1}^{n}x_i\\);\n\\(\\sum_{i=1}^{n}(a+bx_{i})=\\sum_{i=1}^{n}a+\\sum_{i=1}^{n}bx_{i}=na+b\\sum_{i=1}^{n}x_i\\);\n\\(\\sum_{i=1}^{n}(x_{i}+y_{i}+z_{i})=\\sum_{i=1}^{n}x_i+\\sum_{i=1}^{n}y_i+\\sum_{i=1}^{n}z_i\\);\n\\(x_1y_1+x_2y_2+ \\ldots +x_ny_n=\\sum_{i=1}^{n}x_{i}y_{i}\\).\n\n\nExemplo 1.11 Sejam os seguintes conjuntos de dados: \\[\\begin{align*}\n    X = \\left\\{ 1, 3, 2, 0 \\right\\} \\textrm{ e } Y = \\left\\{ 0, 2, 2, 1 \\right\\}.\n\\end{align*}\\] Assim, pode-se obter os seguintes somatórios:\n\n\\(\\sum_{i=1}^{4}x_i=x_1+x_2+x_3+x_4=1+3+2+0=6\\);\n\\(\\sum_{j=1}^{4}y_j=y_1+y_2+y_3+y_4=0+2+2+1=5\\);\n\\(\\sum_{i=2}^{4}x_i=x_2+x_3+x_4=3+2+0=5\\);\n\\(\\sum_{j=2}^{4}y_j=y_2+y_3+y_4=2+2+1=5\\);\n\\(\\sum_{i=1}^{4}x_{i}^{2}=x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}=1^2+3^2+2^2+0^2=14\\);\n\\(\\sum_{j=1}^{4}y_{j}^{2}=y_{1}^{2}+y_{2}^{2}+y_{3}^{2}+y_{4}^{2}=0^2+2^2+2^2+1^2=9\\);\n\\(\\left(\\sum_{i=1}^{4}x_i \\right)^2=6^2=36\\);\n\\(\\left(\\sum_{j=1}^{4}y_j \\right)^2=5^2=25\\);\n\\(\\sum_{i=1}^{4}4x_i=4\\sum_{i=1}^{4}x_i=4(6)=24\\);\n\\(\\sum_{j=1}^{4}3y_j=3\\sum_{j=1}^{4}y_j=3(5)=15\\);\n\\(\\sum_{i=1,j=1}^{n}x_iy_j=x_1y_1+x_2y_2+x_3y_3+x_4y_4=1(0)+3(2)+2(2)+0(1)=10\\);\n\\(\\sum_{i=1,j=1}^{n}x_iy_j+\\sum_{i=1}^{4}x_{i}^{2}+\\sum_{i=1}^{4}y_{i}^{2}=10+14+9=33\\);\n\\(\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{4}x_i}{n}=\\frac{6}{4}=1,5\\);\n\\(\\bar{\\text{y}}=\\frac{\\sum_{j=1}^{4}y_j}{n}=\\frac{5}{4}=1,25\\).\n\n\n\nExemplo 1.12 Expressando as seguintes somas usando notação de somatório, tem-se:\n\n\\(y_1+y_2+y_3+\\cdots+y_{15}=\\sum_{i=1}^{15}y_i\\);\n\\(x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+\\cdots+x_{n}^{2}=\\sum_{i=1}^{n}x_{i}^{2}\\);\n\\(z_{1}^{1}+z_{3}^{2}+z_{5}^{3}+\\cdots+z_{59}^{30}=\\sum_{i=1}^{30}z_{2i-1}^{i}\\);\n\\(logx_1+logx_2+logx_3+\\cdots+logx_{12}=\\sum_{i=1}^{12}logx_i\\);\n\\((x_{1}-1)+(x_{2}^{2}-2^2)^2+(x_{3}^{3}-3^3)^3+\\cdots+(x_{n}^{n}-n^n)^n=\\sum_{i=1}^{n}(x_{i}^{i}-i^i)^i\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#exercícios",
    "href": "cap01.html#exercícios",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "1.4 Exercícios",
    "text": "1.4 Exercícios\n\nExercício 1.1 Apresente um exemplo para cada tipo de variável e inclua um possível valor (dado) para cada uma delas.\n\nQualitativa nominal;\nQualitativa ordinal;\nQuantitativa discreta;\nQuantitativa contínua.\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap02.html",
    "href": "cap02.html",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "",
    "text": "2.1 Introdução\nO material básico com que o pesquisador trabalha são os dados provenientes de variáveis, sendo que a coleta destes é o passo inicial na avaliação estatística de uma pesquisa. Os dados da forma como foram coletados representam os dados brutos, e sempre se apresentam desordenados. Os dados colocados em ordem crescente ou decrescente representam os dados elaborados.\nO passo seguinte é sintetizar os valores que uma ou mais variáveis podem assumir, para que se tenha uma visão global da variação dessa ou dessas variáveis. Inicialmente esses valores são apresentados em tabelas e gráficos, que irão nos fornecer rápidas e seguras informações a respeito das variáveis em estudo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#representação-tabular",
    "href": "cap02.html#representação-tabular",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.2 Representação Tabular",
    "text": "2.2 Representação Tabular\nUma tabela é um quadro que resume um conjunto de dados. Segundo Crespo (2009), uma tabela pode ser dividida em duas partes: principais e secundárias. As partes principais são:\n\nCorpo: Conjunto de linhas e colunas que contêm informações sobre a variável em estudo.\nCabeçalho: Parte superior da tabela que especifica o conteúdo das colunas.\nColuna indicadora: Parte da tabela que especifica o conteúdo das linhas.\nLinhas: Retas imaginárias que facilitam a leitura no sentido horizontal, de dados que se inscrevem nos seus cruzamentos com as colunas.\nCasa ou célula: Espaço destinado a um só valor.\n\nAs partes secundárias são:\n\nTítulo: Conjunto de informações as mais completas possíveis. Deve responder as seguintes perguntas: O quê? Quando? Onde?, relativas à variável estudada.\nRodapé: É um espaço na parte inferior da tabela utilizado para colocar informações necessárias referentes aos dados.\nFonte: É a indicação da entidade responsável pela elaboração da tabela. Deve ser colocada no rodapé, no final da tabela. Esse procedimento garante a honestidade científica e serve como indicativo para posteriores consultas.\nNotas: Também podem ser colocadas no rodapé, depois da fonte, de forma sintética. As notas têm caráter geral, referindo-se à totalidade da tabela. Devem ser enumeradas em algarismos romanos, quando existirem duas ou mais.\nChamadas: As chamadas têm caráter particular, referindo-se a um item específico da tabela. São enumeradas em algarismos arábicos, entre parênteses.\n\nA seguir será abordado o Exemplo 2.1 para se observar o desenvolvimento de uma tabela.\n\nExemplo 2.1 Considere o exemplo de tabela a seguir, que representa a produção de grãos, em ordem decrescente da quantidade produzida, segundo os principais produtos agrícolas, Brasil, 2005.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#tabela-de-distribuição-de-frequências",
    "href": "cap02.html#tabela-de-distribuição-de-frequências",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.3 Tabela de distribuição de frequências",
    "text": "2.3 Tabela de distribuição de frequências\nUm das maneiras de se organizar e resumir um conjunto de dados é através de uma tabela de distribuição de frequências, sendo que estas permitem identificar características de interesse dos dados sob análise. Essas tabelas podem ser de dois tipos:\n\ntabela de distribuição de frequências simples1: Os dados são agrupados sem intervalos de classes com as respectivas frequências de ocorrência.\nTabela de Distribuição de Frequências com dados agrupados em intervalos de classes: Os dados são agrupados em intervalos de classes com as respectivas frequências de ocorrência.\n\nNa Tabela de Distribuição de Frequências, podem ser identificadas as seguintes frequências:\n\nAbsoluta \\((F_i)\\)}: Número de dados ocorridos em cada nível ou categoria da variável sob estudo. A soma das frequências absolutas corresponde ao total de dados (tamanho da amostra ou população);\nRelativa \\((Fr_i)\\)}: Obtida pela divisão da frequência absoluta pelo número total de dados;\nPercentual \\((Fp_i)\\)}: Frequência relativa multiplicada por 100;\nFrequência acumulada para baixo \\((Fc\\downarrow)\\)}: Mostra quantos dados são menores que um determinado valor;\nFrequência acumulada para cima \\((Fc\\uparrow)\\)}: Mostra quantos dados são maiores que um determinado valor.\n\nPara se organizar um conjunto de dados em uma tabela de distribuição de frequências, primeiro deve-se conhecer qual é o tipo de informação que se está trabalhando, isto é, que tipo de variável correspondem os dados coletados, se qualitativos ou quantitativos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#variáveis-qualitativas",
    "href": "cap02.html#variáveis-qualitativas",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.4 Variáveis qualitativas",
    "text": "2.4 Variáveis qualitativas\nNo caso de variáveis qualitativas, nominal ou ordinal, utiliza-se de uma tabela de distribuição de frequências simples para se organizar e resumir tais variáveis, sendo apresentado o Exemplo 2.2 a seguir.\n\nExemplo 2.2 Um Engenheiro Agrônomo conduziu um estudo com o objetivo de se conhecer o nível de tecnificação (baixo, médio ou alto), adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais. Foi avaliada uma amostra de 50 produtores rurais e os resultados estão apresentados na Tabela 2.1.\n\n\n\nTabela 2.1: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007 (dados brutos).\n\n\n\n\n\nBaixo\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nAlto\nMédio\nAlto\nMédio\n\n\nAlto\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nMédio\nBaixo\nMédio\nMédio\n\n\nMédio\nMédio\nMédio\nMédio\nBaixo\n\n\nMédio\nBaixo\nMédio\nMédio\nMédio\n\n\nAlto\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nMédio\nMédio\nBaixo\nAlto\n\n\nBaixo\nAlto\nMédio\nMédio\nMédio\n\n\nMédio\nMédio\nBaixo\nMédio\nMédio\n\n\n\n\n\n\nO próximo passo é ordenar os dados pelo nível de tecnificação (baixo, médio e alto), obtendo-se os dados elaborados dispostos na Tabela 2.2.\n\n\n\nTabela 2.2: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007 (dados elaborados).\n\n\n\n\n\nBaixo\nBaixo\nMédio\nMédio\nMédio\n\n\nBaixo\nBaixo\nMédio\nMédio\nAlto\n\n\nBaixo\nBaixo\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\n\n\n\n\nA seguir conta-se o número de produtores rurais com nível de tecnificação baixo, médio e alto, ou seja, a frequência absoluta, e organiza-se os dados em uma tabela, dividida em classes (baixo, médio e alto) com as respectivas frequências de ocorrência. Os resultados estão apresentados na Tabela 2.3.\n\n\n\nTabela 2.3: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007.2\n\n\n\n\n\n\n\n\n\n\n\nNível de Tecnificação\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\nBaixo\n13\n0,26\n26,0\n\n\nMédio\n28\n0,56\n56,0\n\n\nAlto\n9\n0,18\n18,0\n\n\nTotal\n50\n1,00\n100,0\n\n\n\n\n\n\nObservando os resultados da Tabela 2.3, tem-se que 56,0% dos produtores rurais adotam em suas propriedades um nível médio de tecnologia, porém apenas 18,0% empregam altas tecnologias, e 26,0% utilizam-se de baixas tecnologias de produção. Esses resultados pode orientar melhor os trabalhos dos Extensionistas que trabalham na região.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#variáveis-quantitativas",
    "href": "cap02.html#variáveis-quantitativas",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.5 Variáveis quantitativas",
    "text": "2.5 Variáveis quantitativas\n\nDiscretas: Se os dados de uma amostra ou população estiverem representados por variáveis quantitativas discretas, eles estarão naturalmente classificados, isto é, separados em grupos distintas. Para se ter uma ideia do modo como os dados se distribuem, basta escrever em uma coluna os valores da variável discreta estudada em ordem crescente e, assinalar em outra coluna paralela, o número de vezes em que cada um desses valores foi observado, isto é, a frequência absoluta de cada valor. Neste caso utiliza-se de uma tabela de distribuição de frequências simples para se organizar e resumir tais variáveis, sendo apresentado no Exemplo 2.3.\n\n\nExemplo 2.3 Um Engenheiro Agrônomo examinou um lote de 150 caixas de banana maçã, escolhidos aleatoriamente num carregamento de 10.000 caixas, no CEAGESP de São Paulo, SP, anotando o número de pencas com empedramento. Os dados estão apresentados na Tabela 2.4.\n\n\n\nTabela 2.4: Número de pencas de banana maçã com empedramento (dados brutos).\n\n\n\n\n\n2\n3\n1\n1\n0\n0\n2\n2\n3\n5\n\n\n\n4\n0\n4\n0\n1\n1\n0\n6\n5\n0\n\n\n\n1\n1\n0\n4\n0\n0\n5\n0\n0\n2\n\n\n\n0\n4\n5\n0\n4\n0\n2\n1\n1\n1\n\n\n\n2\n0\n0\n1\n0\n4\n0\n5\n0\n0\n\n\n\n0\n5\n0\n4\n1\n0\n1\n0\n2\n1\n\n\n\n0\n1\n1\n0\n2\n5\n0\n2\n0\n0\n\n\n\n3\n5\n0\n1\n0\n0\n1\n4\n3\n3\n\n\n\n2\n0\n4\n0\n3\n4\n0\n0\n1\n1\n\n\n\n0\n2\n1\n3\n2\n1\n2\n3\n1\n0\n\n\n\n1\n5\n2\n2\n1\n2\n1\n1\n2\n3\n\n\n\n3\n2\n6\n1\n5\n3\n2\n1\n1\n1\n\n\n\n6\n2\n2\n4\n1\n4\n1\n6\n3\n4\n\n\n\n1\n4\n1\n3\n3\n1\n3\n2\n4\n1\n\n\n\n3\n1\n3\n2\n2\n3\n2\n3\n4\n3\n\n\n\n\n\n\n\nApós coletar os dados o Engenheiro Agrônomo ordenou os dados em ordem crescente, obtendo-se assim os dados elaborados apresentados na Tabela 2.5.\n\n\n\nTabela 2.5: Número de pencas de banana maçã com empedramento (dados elaborados).\n\n\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n4\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n\n\n\n\nOrdenado os dados o Engenheiro Agrônomo examinou as 150 caixas, e contou quantas caixas tinham nenhuma penca empedrada, quantas tinham uma penca empedrada, duas pencas empedradas e assim por diante, e organizou os dados com as respectivas frequências de ocorrência na Tabela 2.6.\n\n\n\nTabela 2.6: Número de pencas de banana maçã com empedramento, CEAGESP, São Paulo, SP, 2007.3\n\n\n\n\n\n\n\n\n\n\n\nNúmero de pencas empedradas\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\n0\n38\n0,2533\n25,33\n\n\n1\n37\n0,2467\n24,67\n\n\n2\n25\n0,1667\n16,67\n\n\n3\n20\n0,1333\n13,33\n\n\n4\n16\n0,1067\n10,67\n\n\n5\n10\n0,0667\n6,67\n\n\n6\n4\n0,0266\n2,66\n\n\nTotal\n150\n1,0000\n100,00\n\n\n\n\n\n\nObserva-se pelos resultados apresentados na Tabela 2.6 que: das \\(150\\) caixas de banana inspecionadas, apenas \\(38\\) caixas, ou seja, \\(25,33\\%\\), não tinham nenhuma penca empedrada, e que \\(10,67\\%\\) tinham \\(4\\) pencas empedradas. Estes resultados poderiam estar orientando o Engenheiro Agrônomo a direcionar suas ações, no sentido de melhorar a qualidade do produto.\n\n\nContínuas: Quando os dados de uma amostra ou população estiverem representados por variáveis quantitativas contínuas, é evidente que não existem classes naturais. Apesar disso pode-se usar o recurso de agrupar os dados em classes com um determinado número de intervalos. Tais classes terão dois valores limites, isto é, um limite inferior e um limite superior. Assim, utiliza-se de uma tabela de distribuição de frequências com dados agrupados em classes com intervalos de classes, para se organizar e resumir tais variáveis.\n\nNeste casso para a construção da tabela de distribuição de frequências devem ser seguidos os seguintes passos:\n\nDeterminar o número de classes \\((K)\\): A escolha do número de classes é arbitrária, e a experiência do pesquisador com os dados é que lhe indicará quantas classes devem ser usadas. No entanto deve ser observado que, com poucas classes perde-se informação, e com muitas classes o objetivo de se resumir um conjunto de dados pode ficar prejudicado. Pode-se, também, adotar o critério baseado no número de observações “\\(n\\)”, conforme Tabela 2.7.\n\n\n\n\nTabela 2.7: Determinação do número de classes (\\(K\\)).\n\n\n\n\n\nNúmero de observações \\((n)\\)\nNúmero de classes \\((K)\\)\n\n\n\n\n\nAté \\(100\\)\n\\(\\sqrt{n}\\) (inteiro mais próximo)\n\n\n\nAcima de \\(100\\)\n\\(5\\log_{10}(n)\\) (inteiro mais próximo)\n\n\n\n\n\n\n\n\nDeterminar a amplitude de classe \\((c)\\): A amplitude de classe é definida pela diferença entre os limites superior e inferior de uma determinada classe, dada por: \\[\nc=LS_{i} - LI_{i},\n\\] para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(K\\), sendo \\(K\\) o número de classes. Porém, em termos práticos a amplitude de classe é determinada da seguinte forma: \\[\nc=\\frac{A}{K-1},\n\\] em que:\n\n\\(A\\) é amplitude total, que representa a diferença entre a maior observação e a menor observação;\n\\(K\\) é o número de classes.\n\nDeterminar o limite inferior da primeira classe \\((LI_{1ª})\\), dado por:\n\n\\[\nLI_{1ª} = \\textrm{Menor dado} - \\frac{c}{2}.\n\\]\n\nDeterminar o limite superior da primeira classe (\\(LS_{1ª}\\)), dado por:\n\n\\[\nLS_{1ª} = LI_{1ª} + c.\n\\]\n\nOs demais limites de classe são obtidos somando-se o valor de \\(c\\) até completar as \\(K\\) classes.\nDeterminar os pontos médios das classes \\((\\tilde{X}_i)\\), dado por:\n\n\\[\n\\tilde{X}_i=\\frac{LI_{iª}+LS_{iª}}{2}.\n\\]\nPosteriormente, serão determinados as frequências: absoluta \\((F_i)\\), relativa \\((Fr_i)\\) e percentual \\((Fp_i)\\), de forma similar como foi desenvolvido na tabela de distribuição de frequência simples. Em geral usa-se as seguintes notações para os intervalos de classes:\n\n\\([a;b)\\) ou \\(a \\vdash b\\).\n\nNa contagem do número de dados contidos em um intervalo de uma determinada classe (frequência absoluta), deve-se incluir o valor do limite inferior \\((a)\\) e excluir o valor do limite superior \\((b)\\) de cada classe. O valor do limite superior passa a ser contado na classe posterior.\n\nExemplo 2.4 Um Zootecnista observou os pesos ao nascer, em kg, de uma amostra de 50 bezerros da raça nelore, provenientes da Fazenda de um grande criador. Os resultados estão apresentados na Tabela 2.8.\n\n\n\nTabela 2.8: Pesos ao nascer, em kg, de 50 bezerros da raça nelore (dados brutos).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n26,8\n24,3\n23,7\n31,0\n22,2\n25,2\n29,5\n24,2\n33,0\n27,2\n\n\n\n25,9\n23,0\n25,6\n26,5\n26,0\n22,8\n31,8\n21,0\n29,3\n27,8\n\n\n\n24,1\n26,9\n24,5\n26,2\n29,8\n21,6\n27,2\n26,8\n26,9\n25,0\n\n\n\n29,6\n31,3\n22,1\n26,1\n29,2\n25,3\n26,0\n27,2\n28,1\n26,2\n\n\n\n28,5\n27,2\n28,6\n25,8\n26,5\n28,1\n24,9\n30,5\n28,7\n24,5\n\n\n\n\n\n\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#footnotes",
    "href": "cap02.html#footnotes",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "",
    "text": "Também pode ser chamada de tabela de distribuição com dados agrupados sem intervalo de classes.↩︎\nDados fictícios.↩︎\nFonte: Dados fictícios.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap03.html",
    "href": "cap03.html",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "3.1 Introdução\nNo capítulo anterior vimos como organizar um conjunto de dados através de tabelas e gráficos, mas podemos ainda tirar mais informações importantes de um conjunto de dados através das medidas de posição. As medidas de posição, ou medidas de tendência central, são medidas representativas do valor central ao redor do qual se agrupam os dados, ou seja, procuram sintetizar um conjunto de dados em um único e informativo valor.\nA média, a mediana e a moda são as três medidas de posição mais utilizadas para descrever um conjunto de dados, sejam eles populacionais ou amostrais.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#média",
    "href": "cap03.html#média",
    "title": "3  Medidas de Posição",
    "section": "3.2 Média",
    "text": "3.2 Média\n\n3.2.1 Dados Não Agrupados\nA média de uma população ou amostra é dada pela soma de todos os dados da população ou amostra, dividida pelo número de dados que a compõem.\nNo caso dos dados provenientes de uma população, a média, denotada por \\(\\mu\\), é dada pela expressão (3.1).\n\\[\n\\mu=\\frac{\\sum_{i=1}^{N}x_i}{N}.\n\\tag{3.1}\\]\nE no caso dos dados provenientes de uma amostra, a média, denotada por \\(\\bar{x}\\), é dada pela expressão (3.2).\n\\[\n\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{n}x_i}{n}.\n\\tag{3.2}\\]\nA média funciona como um ponto de equilíbrio (de balanço), e é evidente que teremos dados acima e abaixo da média, mas todos os dados estarão na média, pois todos os dados fazem parte do cálculo da média.\nA unidade da média será a mesma unidade dos dados.\n\nExemplo 3.1 Considere os dados do Exemplo 2.4. Neste caso trata-se de uma amostra. Assim, utilizando-se da expressão (3.2) tem-se que a média amostral é dada por:\n\\[\\begin{align}\n\\bar{\\text{x}} & = \\frac{21,0+21,6+22,1+...+31,3+31,8+33,0}{50} \\Rightarrow \\bar{\\text{x}}=26,6~\\textrm{kg}.\n\\end{align}\\]\n\n\n\n3.2.2 Dados Agrupados\nSe os dados estiverem agrupados em uma tabela de distribuição de frequências com intervalos de classes, a média é dada pela expressão (3.3). \\[\n\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{K}F_{i}\\tilde{X}_i}{\\sum_{i=1}^{K}F_i},\n\\tag{3.3}\\] em que: \\(\\tilde{X}_i\\) é o ponto médio da classe \\(i\\) e \\(F_i\\) é a frequência absoluta da classe \\(i\\).\n\nExemplo 3.2 Considere o Exemplo 2.4. Alternativamente pode-se acrescentar mais uma coluna na tabela de distribuição de frequências referente a: \\(F_{i}\\tilde{X}_i\\), que pode ser observado pela Tabela 3.1.\n\n\n\nTabela 3.1: Pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeso \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\\(\\mathbf{F_{i}\\tilde{X}_i}\\)\n\n\n\n\n\\(\\left[20,0;22,0\\right)\\)\n21,0\n2\n0,04\n4,0\n42,0\n\n\n\\(\\left[22,0;24,0\\right)\\)\n23,0\n5\n0,10\n10,0\n115,0\n\n\n\\(\\left[24,0;26,0\\right)\\)\n25,0\n12\n0,24\n24,0\n300,0\n\n\n\\(\\left[26,0;28,0\\right)\\)\n27,0\n16\n0,32\n32,0\n432,0\n\n\n\\(\\left[28,0;30,0\\right)\\)\n29,0\n10\n0,20\n20,0\n290,0\n\n\n\\(\\left[30,0;32,0\\right)\\)\n31,0\n4\n0,08\n8,0\n124,0\n\n\n\\(\\left[32,0;34,0\\right)\\)\n33,0\n1\n0,02\n2,0\n33,0\n\n\nTotal\n\n50\n1,00\n100,0\n1.336,0\n\n\n\n\n\n\nLogo, utilizando-se da expressão (3.3) tem-se que a média é dada por: \\[\n\\bar{\\text{x}}=\\frac{1.336,0}{50}=26,7~\\textrm{kg}.\n\\]\nObserva-se que a média para os dados não agrupados (26,6 kg) foi calculada usando os verdadeiros dados, e a média para os dados agrupados (26,7 kg) foi calculada usando os dados representados pelo ponto médio da classe \\((\\tilde{X}_i)\\). Como se observa, a média calculada com os dados agrupados foi diferente da média para os dados não agrupados. No cálculo com os dados agrupados existe um erro devido à perda de informação, porém, tal erro é mínimo e, portanto, desprezível, o que mostra a qualidade do algoritmo utilizado para agrupar os dados numa Tabela de Distribuição de Frequências.\nNeste caso o erro foi de: \\[\nErro = 26,7 – 26,6 = 0,1~\\textrm{kg}.\n\\]\n\n\n\n3.2.3 Propriedades\nA média apresenta as seguintes propriedades:\n\nA soma dos desvios \\((SD)\\) de cada dado em relação à sua média é nula: \\[\nSD=\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)=0,0.\n\\]\n\n\nExemplo 3.3 Seja uma amostra referente às alturas, em cm, de três plantas de uma variedade de milho, dada por: \\[\n182,0; 184,0; 189,0.\n\\]\nUtilizando-se da expressão 3.2 a média é dada por:\n\\[\n\\bar{\\text{x}}=\\frac{182,0+184,0+189,0}{3}=\\frac{555,0}{3}=185,0~\\textrm{cm}.\n\\]\nAssim, a soma dos desvios de cada dado em relação à média é dada por: \\[\\begin{align}\n  SD &= (182,0-185,0)+(184,0-185,0)+(189,0-185,0)\\\\\n     &= (-3,0)+(-1,0)+(4,0)=0,0.\n\\end{align}\\]\nQue é um valor nulo comparado a qualquer outro valor diferente da média.\n\n\nA média é o valor que torna mínimo a soma de quadrados dos desvios \\((SQD)\\):\n\n\\[\nSQD=\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^2.\n\\]\n\nExemplo 3.4 Considere o Exemplo 3.3, em que: \\(\\bar{x}=185,0\\) cm.\nAssim, tem-se que a soma de quadrados dos desvios \\((SQD)\\) é dada por: \\[\\begin{align*}\n  SQD &= (182,0-185,0)^2+(184,0-185,0)^2+(189,0-185,0)^2\\\\\n      &= (-3,0)^2+(-1,0)^2+(4,0)^2=9+1+16=26,0.\n\\end{align*}\\] Que é um valor mínimo comparado a qualquer outro valor diferente da média.\n\n\nSomando-se ou subtraindo-se um mesmo valor constante \\(k\\) a cada dado, a média fica acrescida ou subtraída deste valor:\n\n\\[\nx_i \\pm k \\Rightarrow \\bar{\\text{x}} \\pm k.\n\\]\n\nExemplo 3.5 Considere o Exemplo Exemplo 3.3, em que: ${}=$185,0~cm.\nSomando-se \\(k = 3,0\\) cm a cada valor da amostra tem-se: \\[\n185,0; 187,0; 192,0.\n\\]\nUtilizando-se da expressão (3.2) a nova média é dada por:\n\\[\n\\bar{\\text{x}}=\\frac{185,0+187,0+192,0}{3}=\\frac{564,0}{3}=188,0~\\textrm{cm}.\n\\]\nOu seja, é a média anterior acrescida de \\(3,0\\) cm.\n\n\nMultiplicando-se ou dividindo-se cada dado por um mesmo valor constante \\(k\\), diferente de 0, a média fica multiplicada ou dividida por este valor:\n\n\\[\nx_{i}\\times k \\Rightarrow \\bar{\\text{x}} \\times k.\n\\]\n\\[\n\\frac{x_i}{k} \\Rightarrow \\frac{\\bar{\\text{x}}}{k}\n\\]\n\nExemplo 3.6 Considere o Exemplo 3.3, em que: \\(\\bar{\\text{x}}=185,0\\) cm. Multiplicando-se cada dado por \\(k = 2\\) tem-se:\n\\[\n364,0; 368,0; 378,0.\n\\]\nA nova média é dada por: \\[\n\\bar{\\text{x}}=\\frac{364,0+368,0+378,0}{3}=370,0~\\textrm{cm}.\n\\] O que corresponde a média anterior multiplicada por 2.\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#footnotes",
    "href": "cap03.html#footnotes",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "Fonte: Dados fictícios.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap04.html",
    "href": "cap04.html",
    "title": "4  Medidas de Dispersão",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap05.html",
    "href": "cap05.html",
    "title": "5  Probabilidades",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap06.html",
    "href": "cap06.html",
    "title": "6  Distribuições de Probabilidades",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuições de Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap07.html",
    "href": "cap07.html",
    "title": "7  Amostragem",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Amostragem</span>"
    ]
  },
  {
    "objectID": "cap08.html",
    "href": "cap08.html",
    "title": "8  Distribuições de Amostragem",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuições de Amostragem</span>"
    ]
  },
  {
    "objectID": "cap09.html",
    "href": "cap09.html",
    "title": "9  Teoria da Estimação",
    "section": "",
    "text": "9.1 Introdução\nToda população é descrita por um certo modelo probabilístico \\(f(x | \\theta)\\), com parâmetro(s) \\(\\theta\\) desconhecido(s), e o interesse é obter algum tipo de informação acerca desse(s) parâmetro(s). O que se dispõe é de uma amostra, ou seja, de partes de elementos da população. A partir de uma amostra aleatória é possível obter aproximações numéricas para o(s) parâmetro(s) \\(\\theta\\) do modelo, e esse processo é chamado estimação. Assim, um dos objetivos da Estatística é obter informações sobre os parâmetros populacionais através das estimativas amostrais.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#conceitos-básicos",
    "href": "cap09.html#conceitos-básicos",
    "title": "9  Teoria da Estimação",
    "section": "9.2 Conceitos Básicos",
    "text": "9.2 Conceitos Básicos\nPara formalizar as ideias que serão apresentadas alguns conceitos são úteis.\n\n9.2.1 Parâmetro\nUm parâmetro é um valor desconhecido associado a uma característica da população, e em geral representado por letras gregas.\n\nExemplo 9.1 A média \\(\\mu\\) e a variância \\(\\sigma^2\\) de uma população são parâmetros.\n\n\n\n9.2.2 Estimador\nO estimador é a função ou expressão algébrica que estima o valor de um parâmetro populacional, baseando-se nas observações de uma amostra aleatória.\n\nExemplo 9.2  \n\n\\(\\bar{x}=\\frac{\\sum_{i=1}^{n}x_i}{n}\\) é um estimador da média populacional \\(\\mu\\);\n\\(s^2=\\frac{\\sum_{i=1}^{n}x_i^2-\\frac{\\left(\\sum_{i=1}^{n}x_i\\right)^2}{n}}{n-1}\\) é um estimador da variância populacional \\(\\sigma^2\\).\n\n\n\n\n9.2.3 Estimativa\nUma estimativa é uma aproximação numérica para um parâmetro associado a um modelo probabilístico, ou seja, é o valor obtido pelo estimador numa determinada amostra aleatória.\n\nExemplo 9.3 Numa certa variedade de milho tem-se uma estimativa da altura média desta variedade, dada por:\n\\[\n\\bar{x}=200,0~\\textrm{cm}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#tipos-de-estimativas",
    "href": "cap09.html#tipos-de-estimativas",
    "title": "9  Teoria da Estimação",
    "section": "9.3 Tipos de Estimativas",
    "text": "9.3 Tipos de Estimativas\nBasicamente existem dois processos de estimação. O primeiro deles é a chamada estimação pontual, pela qual um valor numérico é obtido através de um estimador, como sendo uma aproximação numérica para o parâmetro populacional.\n\nExemplo 9.4 Numa amostra aleatória de n elementos os valores de \\(\\bar{x}\\) e \\(s^2\\) estimam \\(\\mu\\) e \\(\\sigma^2\\), respectivamente, por ponto.\n\n\nExemplo 9.5 Seja uma amostra de 40 plantas de uma variedade de milho, em que a variável altura, apresentou uma média de \\(200,0\\) cm e um desvio padrão de \\(10,0\\) cm.\nNesta amostra a média amostral, \\(\\bar{x}=200,0\\) cm, é uma estimativa por ponto da média populacional \\(\\mu\\), e o desvio padrão amostral, \\(s = 10,0\\) cm, é uma estimativa por ponto do desvio padrão populacional \\(\\sigma\\).\n\nO segundo processo de estimação é a estimação por intervalo, no qual algum tipo de intervalo é construído, de tal maneira que se possa atribuir probabilidades de que o valor real do parâmetro esteja ali contido. Neste caso, o parâmetro populacional é estimado por dois valores, obtidos através de cálculos com os dados amostrais, que formam um intervalo, dentro do qual se espera encontrar o verdadeiro valor do parâmetro. A vantagem desse processo é que mostra a precisão da estimativa.\n\nExemplo 9.6 Considerando o exemplo anterior tem-se que a expressão: \\[\nIC_{95,0\\%}(\\mu):~[196,90~\\textrm{cm};~ 203,10~\\textrm{cm}],\n\\] é uma estimativa por intervalo para \\(\\mu\\) com uma confiança de 95,0% e um erro de 3,10 cm.\n\nAssim, a associação entre estimativas pontuais acerca de um parâmetro populacional, e o conhecimento de probabilidades de que o parâmetro esteja contido em certos intervalos, possibilitará, em geral, promover uma inferência informativa a respeito do parâmetro desconhecido.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#métodos-de-estimação-pontual",
    "href": "cap09.html#métodos-de-estimação-pontual",
    "title": "9  Teoria da Estimação",
    "section": "9.4 Métodos de Estimação Pontual",
    "text": "9.4 Métodos de Estimação Pontual\nOs métodos de obtenção de estimativas pontuais, os quais não serão discutidos em detalhes aqui, são:\n\nMétodo dos Momentos;\nMétodo dos Quadrados Mínimos;\nMétodo da Máxima Verossimilhança.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#propriedades-dos-estimadores-pontuais",
    "href": "cap09.html#propriedades-dos-estimadores-pontuais",
    "title": "9  Teoria da Estimação",
    "section": "9.5 Propriedades dos Estimadores Pontuais",
    "text": "9.5 Propriedades dos Estimadores Pontuais\nEm função da existência de vários métodos para estimação de parâmetros, é importante analisar algumas propriedades dos estimadores, que possa auxiliar na escolha de um estimador para um parâmetro em particular. Essas propriedades são:\n\nVício: Um estimador \\(\\hat{\\theta}\\) de um parâmetro \\(\\theta\\) é não viciado, ou não tendencioso, ou não viesado, se: \\[\nE(\\hat{\\theta})=\\theta.\n\\]\n\n\nExemplo 9.7 A média amostral, \\(\\bar{x} = \\sum_{i = 1}^{n}x_i / n\\), é um estimador não viciado da média populacional \\(\\mu\\), pois pode-se provar que:\n\\[\nE(\\bar{x})=\\mu.\n\\]\n\nOu seja, um estimador é não viciado se o seu valor esperado coincide com o parâmetro de interesse.\n\nExemplo 9.8 A variância amostral, \\(\\hat{\\sigma}^2 = \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 / n\\), é um estimador viciado para \\(\\sigma^2\\).\nPode ser demonstrado que:\n\\[\nE(\\hat{\\sigma}^2)=\\left(\\frac{n-1}{n}\\right) \\sigma^2.\n\\]\nPor outro lado tem-se que: \\[\nE\\left(\\frac{n}{n-1}\\hat{\\sigma}^2\\right)=\\sigma^2\n\\] Note que:\n\\[\n\\left(\\frac{n}{n-1}\\hat{\\sigma}^2\\right)=\\left(\\frac{n}{n-1}\\right)\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{x} \\right)^2}{n}=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(x_i- \\bar{x} \\right)^2=s^2.\n\\]\nLogo, \\(s^2\\) é um estimador não viciado para \\(\\sigma^2\\).\n\n\nConsistência: Um estimador \\(\\hat{\\theta}\\) é consistente se à medida que o tamanho n da amostra aumenta, seu valor esperado converge para o parâmetro de interesse, e sua variância converge para zero. Ou seja, \\(\\hat{\\theta}\\) é consistente se as duas propriedades são satisfeitas:\n\n\n\\(\\lim_{n \\to \\infty} E(\\hat{\\theta}) = \\theta\\);\n\\(\\lim_{n \\to \\infty} V(\\hat{\\theta}) = 0\\).\n\n\nEficiência: Dados dois estimadores \\(\\hat{\\theta}_1\\) e \\(\\hat{\\theta}_2\\), não viciados para um parâmetro \\(\\theta\\), diz-se que \\(\\hat{\\theta}_1\\) é mais eficiente que \\(\\hat{\\theta}_2\\) se: \\(V(\\hat{\\theta}_1)\\) &lt; \\(V(\\hat{\\theta}_2)\\). Isto é, dentre todos os estimadores não viciados de um parâmetro \\(\\theta\\), aquele que tiver menor variância é o estimador mais eficiente de \\(\\theta\\).\n\n\nExemplo 9.9 Numa amostra a média amostral \\(\\bar{x}\\) é um estimador mais eficiente da média populacional \\(\\mu\\) que a mediana \\(md\\), pois pode-se provar que: \\[\nV(\\bar{x})=\\frac{\\sigma^2}{n}~\\textrm{e}~ V(md)=\\frac{\\pi}{2}\\times \\frac{\\sigma^2}{n}.\n\\]\nLogo \\(V(\\bar{\\text{x}}) &lt; V(md)\\).\n\nNo caso de uma estimativa por intervalo, o comprimento do intervalo de confiança dá uma idéia da eficiência da estimativa.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#estimação-por-intervalo",
    "href": "cap09.html#estimação-por-intervalo",
    "title": "9  Teoria da Estimação",
    "section": "9.6 Estimação por intervalo",
    "text": "9.6 Estimação por intervalo\nOs estimadores pontuais fornecem como estimativa um único valor numérico para o parâmetro \\(\\theta\\) de interesse, associado ao modelo probabilístico \\(f(x | \\theta)\\). A inferência pode e deve ser complementada, sempre que possível, com pressuposições acerca de probabilidades de \\(\\theta\\) estarem próximos ou não de suas estimativas pontuais. Por serem variáveis aleatórias, os estimadores possuem uma distribuição de probabilidade, e levando este fato em consideração, pode-se apresentar uma estimativa mais informativa para o parâmetro de interesse, que inclua uma medida de precisão do valor obtido. Este método de estimação, denominado estimação por intervalo, incorpora à estimativa pontual do parâmetro, informações a respeito de sua variabilidade, permitindo a construção de intervalos com probabilidades conhecidas de que o valor paramétrico esteja contido nesse intervalo.\nAssim, intervalos de confiança são obtidos através da distribuição amostral de seus estimadores.\nSeja \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\) uma amostra aleatória coletada numa população descrita pelo modelo probabilístico \\(f(x | \\theta)\\). Sejam \\(T_1(x)\\) e \\(T_2(x)\\) duas estatísticas que satisfaçam: \\(T_1(x) &lt; T_2(x)\\), e também que: \\(P[T_1(x) &lt; \\theta &lt; T_2(x)]=1 - \\alpha\\).\nO intervalo aleatório: \\([T_1(x); T_2(x)]\\) é chamado de intervalo de confiança para \\(\\theta\\) com \\((1 - \\alpha)100,0\\%\\) de probabilidade. A probabilidade \\((1 - \\alpha)\\) é chamada coeficiente de confiança do intervalo. O comprimento do intervalo de confiança é dado por: \\[\\begin{align*}\n    L(x)=T_2(x) - T_1(x).\n\\end{align*}\\]\nLogo, a construção de intervalos de confiança consiste na obtenção de \\(T_1(x)\\) e \\(T_2(x)\\).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#construção-de-intervalos-de-confiança",
    "href": "cap09.html#construção-de-intervalos-de-confiança",
    "title": "9  Teoria da Estimação",
    "section": "9.7 Construção de Intervalos de Confiança",
    "text": "9.7 Construção de Intervalos de Confiança\nBasicamente os intervalos de confiança podem ser construídos utilizando a distribuição de quantidades pivotais.\nConsidere uma amostra aleatória \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\) de uma população descrita pelo modelo probabilístico \\(f(x | \\theta)\\). Uma função \\(g(x; \\theta)\\), cuja distribuição não dependa de \\(\\theta\\), é chamada de quantidade pivotal.\n\nExemplo 9.10 Considere um modelo probabilístico correspondente a uma distribuição normal de média \\(\\mu\\) e variância \\(\\sigma^2\\). Seja, \\[\nZ=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}.\n\\]\nNeste caso é \\(Z\\) uma quantidade pivotal, pois \\(Z\\) é uma variável aleatória com distribuição normal padronizada, ou seja, \\(Z\\sim N(0,0; 1,0)\\), e não depende de \\(\\mu\\) e \\(\\sigma^2\\).\n\nNas próximas seções, serão utilizados as distribuições de probabilidades e resultados, vistos no Capítulo 8, para a construção de intervalos de confiança para parâmetros populacionais de interesse.\n\n9.7.1 Intervalo de Confiança para a Média de uma Distribuição Normal\nA média estimada a partir de uma amostra aleatória, é apenas uma estimativa por ponto da verdadeira média populacional \\(\\mu\\). A média verdadeira é um parâmetro que na grande maioria das vezes é desconhecida. Entretanto, a partir do conhecimento das distribuições teóricas de \\(Z\\) e \\(t\\), pode-se construir um intervalo que deve conter a verdadeira média populacional \\(\\mu\\).\nPara a construção do intervalo de confiança para a média, tem-se as seguintes situações, descritas a seguir.\n\n\n9.7.2 Grandes Amostras ou Variância Populacional Conhecida\nO intervalo de confiança associado a um determinado nível de confiança, para a média populacional \\(\\mu\\), quando se tem grandes amostras \\((n\\geq 30)\\), ou variância populacional \\(\\sigma^2\\) conhecida, pode ser deduzido da seguinte forma.\nFoi visto no capítulo anterior de acordo com o teorema central do limite que: \\[\n\\bar{\\text{x}} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\n\\]\nLogo, na distribuição de \\(\\bar{x}\\) o valor de \\(Z\\) é obtido por: \\[\nZ=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}},\n\\tag{9.1}\\] em que \\(Z \\sim N(0,0; 1,0)\\).\nNa distribuição de \\(\\bar{x}\\) pode-se esquematizar uma probabilidade de \\((1 - \\alpha)\\), conforme Figura 9.1.\n\n\n\n\n\n\nFigura 9.1: Área correspondente a probabilidade \\(P(-Z_{\\alpha/2} &lt; Z &lt; Z_{\\alpha/2})\\).\n\n\n\nLogo, \\[\nP\\left[-Z_\\frac{\\alpha}{2} &lt; Z &lt; Z_\\frac{\\alpha}{2} \\right]=1 - \\alpha.\n\\tag{9.2}\\]\nSubstituindo (9.1) em (9.2), tem-se: \\[\nP\\left[-Z_\\frac{\\alpha}{2} &lt; \\frac{\\bar{\\text{x}}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}} &lt; Z_\\frac{\\alpha}{2} \\right]=1 - \\alpha.\n\\]\nMultiplicando cada termo da desigualdade por: \\(\\frac{\\sigma}{\\sqrt{n}}\\), obtém-se: \\[\nP\\left[-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; \\bar{\\text{x}}-\\mu &lt; Z_\\frac{\\alpha}{2}\\times \\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nSubtraindo \\(\\bar{x}\\) de cada termo da desigualdade a expressão fica: \\[\nP\\left[-\\bar{\\text{x}}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; -\\mu &lt; -\\bar{\\text{x}}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nMultiplicando cada termo da desigualdade por (-1), tem-se: \\[\nP\\left[\\bar{\\text{x}}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &gt; \\mu &gt; \\bar{\\text{x}}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nInvertendo os extremos do intervalo obtém-se a expressão (9.3), para a construção do intervalo de confiança para \\(\\mu\\) com \\((1 - \\alpha)100,0\\%\\) de probabilidade. \\[\nP\\left[\\bar{x}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; \\mu &lt; \\bar{x}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha,\n\\tag{9.3}\\] em que:\n\n\\(\\bar{x} \\pm Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}}\\) são os limites de confiança;\n\\((1 - \\alpha)100,0\\%\\) é o grau ou nível de confiança.\n\nA representação gráfica de (9.3) pode ser observada na Figura 9.2.\n\n\n\n\n\n\nFigura 9.2: Região do estimador intervalar para \\(\\mu\\) de uma população normal.\n\n\n\nNão conhecendo-se o valor de \\(\\sigma\\) (desvio padrão populacional), pode-se usar o valor de \\(s\\) (desvio padrão amostral), desde que \\(n\\geq 30\\).\n\nExemplo 9.11 Seja uma amostra de 40 plantas de uma variedade de milho, em que a variável altura, apresentou uma média de 200,0 cm e variância de 100,0 cm\\(^2\\). Construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\). Neste caso, não se conhece a variância populacional \\(\\sigma^2\\), e sim, a variância amostral \\(s^2\\). Como o tamanho da amostra é n = 40, considera-se razoável a utilização do desvio padrão amostral. Para construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\), tem-se:\n\n\\(n=40\\);\n\\(\\bar{\\text{x}}=200,0\\) cm;\n\\(s^2=100,0\\) cm\\(^2 \\Rightarrow s=\\sqrt{100,0}=10,0\\) cm;\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\). \\[\nZ_\\frac{\\alpha}{2}=Z_{0,025}=?\n\\]\n\nConsultando a Tabela A 1, tem-se que o valor de Z que deixa uma probabilidade acima dele de 0,025 é igual a 1,96. Dentro do corpo da tabela consulta-se o valor referente a 0,025, conforme esquema abaixo.\n\n\n\nLogo, \\[\nZ_{0,025}=1,96.\n\\]\nAtravés da expressão (9.3), tem-se que: \\[\n200,0-1,96\\frac{10}{\\sqrt{40}} &lt; \\mu &lt; 200,0+1,96\\frac{10}{\\sqrt{40}}\n\\] \\[\n200,0 - 3,10 &lt; \\mu &lt; 200,0 + 3,10\n\\] \\[\n\\Rightarrow IC_{0,95}(\\mu): [196,90~\\textrm{cm}; 203,10~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 95,0% a confiança, da verdadeira altura média das plantas de milho estar entre 196,90 e 203,10 cm. Do ponto de vista de amostragem isto quer dizer que, se forem retiradas várias amostras aleatórias dentro desta população, calculando-se os valores de \\(\\bar{x}\\) e \\(s\\) para cada amostra, e construindo o intervalo de confiança para \\(\\mu\\) em cada amostra, 95,0% dos intervalos conterão em seu interior o verdadeiro valor da média populacional \\(\\mu\\).\n\n\nExemplo 9.12 Considerando o Exemplo 9.11, construir um intervalo de confiança de 99,0% para a média populacional \\(\\mu\\).\nAssim, tem-se: \\[\n(1 - \\alpha)=0,99 \\Rightarrow \\alpha=0,01 \\Rightarrow \\frac{\\alpha}{2}=0,005.\n\\] \\[\nZ_\\frac{\\alpha}{2}=Z_{0,005}=?\n\\]\nConsultando a Tabela A 1, o valor de Z que deixa uma probabilidade acima dele de 0,005 (média de 0,0051 e 0,0049) é igual a 2,575 ( média de 2,57 e 2,58). Dentro do corpo da tabela consulta-se o valor referente a 0,005 ou mais próximo, conforme esquema abaixo:\n\n\n\nLogo, \\[\nZ_{0,005}=2,575.\n\\] Através da expressão (9.3), tem-se que: \\[\n200,0-2,575\\frac{10}{\\sqrt{40}} &lt; \\mu &lt; 200,0+2,575\\frac{10}{\\sqrt{40}}\n\\] \\[\n200,0 - 4,07 &lt; \\mu &lt; 200,0 + 4,07\n\\] \\[\n\\Rightarrow IC_{0,99}(\\mu): [195,93~\\textrm{cm}; 204,07~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 99,0% a confiança, da verdadeira altura média das plantas de milho estar entre 195,93 e 204,07 cm.\n\nO erro da estimativa é dado pela expressão (9.4). \\[\ne=\\bar{\\text{x}} - \\mu.\n\\tag{9.4}\\]\nO erro máximo da estimativa na construção do intervalo de confiança é dado pela expressão (9.5). \\[\ne=Z_\\frac{\\alpha}{2}\\frac{\\sigma}{\\sqrt{n}}.\n\\tag{9.5}\\]\n\nExemplo 9.13 Nos Exemplos 9.11 e 9.12, tem-se que:\n\n\\(\\alpha=5,0\\%=0,05 \\Rightarrow e=3,10\\) cm, ou seja, com 95,0% de confiança, a média, \\(\\bar{\\text{x}}=200,0\\) cm, estima a média populacional \\(\\mu\\) com um erro máximo de 3,10 cm;\n\\(\\alpha=1,0\\%=0,01 \\Rightarrow e=4,07\\) cm, ou seja, com 99,0% de confiança, a média, \\(\\bar{\\text{x}}=200,0\\) cm, estima a média populacional \\(\\mu\\) com um erro máximo de 4,07 cm.\n\nAs consequências da redução de \\(\\alpha\\) são: - O coeficiente de confiança \\((1 - \\alpha)100,0\\%\\) aumenta: \\[\n95,0\\% \\Rightarrow 99,0\\%.\n\\]\n\nO erro da estimativa aumenta:\n\n\\[\n3,10~\\textrm{cm}~\\Rightarrow~4,07~\\textrm{cm}.\n\\]\n\nO comprimento do intervalo de confiança aumenta: \\[\n[196,9~\\textrm{cm};~203,10~\\textrm{cm}]~\\Rightarrow~ [195,93~\\textrm{cm};~204,07~\\textrm{cm}].\n\\]\n\nTem-se que, a única forma de aumentar a confiança e reduzir o comprimento do intervalo, simultaneamente, é aumentando o tamanho da amostra.\n\nA partir do intervalo de confiança para a média \\(\\mu\\), pode-se dimensionar o tamanho da amostra estatisticamente para estimar a média \\(\\mu\\).\nNa abordagem estatística considerada para determinar o tamanho da amostra, o nível de precisão e o erro da estimativa são especificados antecipadamente.\nA expressão do erro máximo é dada por. \\[\ne=Z_\\frac{\\alpha}{2}\\frac{\\sigma}{\\sqrt{n}}.\n\\tag{9.6}\\]\nIsolando \\(n\\) em (9.6), obtém-se a expressão (9.7) para dimensionar o tamanho da amostra estatisticamente. \\[\nn=\\left(\\frac{Z_\\frac{\\alpha}{2}\\sigma}{e} \\right)^2.\n\\tag{9.7}\\]\n\nExemplo 9.14 No Exemplo 9.11, tem-se que:\n\nn=40;\n\\(\\bar{\\text{x}}=200,0\\) cm;\n\\(s=10,0\\) cm;\n\\(\\alpha=5,0\\%=0,05\\);\n\\(e=3,10\\) cm.\n\nQuantas plantas deverão ser examinadas num próximo estudo, para estimar \\(\\mu\\) com um erro de 2,8 cm e uma confiança de 95,0%?\nNeste caso, tem-se que:\n\n\\(e=2,8\\) cm;\n\\(\\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(Z_{0,025}=1,96\\).\n\nLogo, através da expressão (9.7), tem-se que:\n\\[\nn=\\left(\\frac{1,96(10,0)}{2,8}\\right)^2=49~\\textrm{plantas}.\n\\]\n\n\n9.7.2.1 Pequenas Amostras e Variância Populacional Desconhecida\nGeralmente não se conhece o valor da variância populacional \\(\\sigma^2\\). Foi visto que a variância populacional \\(\\sigma^2\\) pode ser estimada a partir da variância amostral \\(s^2\\). Assim, é possível construir um intervalo de confiança de \\((1 – \\alpha)100,0\\%\\) para a média populacional \\(\\mu\\), utilizando a distribuição \\(t\\) em lugar de \\(Z\\). Deste modo, é possível obter o intervalo de confiança para pequenas amostras, \\((n &lt; 30)\\), quando somente a variância amostral \\(s^2\\) é conhecida.\nNesse caso, utiliza-se da distribuição da variável \\(t\\), dada por: \\[\nt=\\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}},\n\\tag{9.8}\\] em que \\(t\\) segue uma distribuição \\(t-Student\\) com \\(\\nu = n – 1\\) graus de liberdade.\nO intervalo de confiança para \\(\\mu\\) com nível de confiança de \\((1 – \\alpha)100,0\\%\\), é dado pela expressão (9.9).\n\\[\nP\\left[\\bar{x}-t_{\\left(\\nu;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}} &lt; \\mu &lt; \\bar{x}+t_{\\left(\\nu;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\tag{9.9}\\]\nO erro máximo da estimativa é dado por: \\[\ne=t_{\\left(v;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}}\n\\]\nO tamanho da amostra para estimar a média é obtido pela expressão (9.10). \\[\nn=\\left(\\frac{t_{\\left(v;\\frac{\\alpha}{2} \\right)}s}{e} \\right)^2.\n\\tag{9.10}\\]\n\nExemplo 9.15 Seja uma amostra de 20 árvores, de uma espécie de Eucalipto pertencente a um povoamento florestal, em que a variável DAP (diâmetro à altura do peito) apresentou uma média de 18,0 cm e um desvio padrão de 2,5 cm. Construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\).\nNeste caso, tem-se:\n\n\\(n=20 \\Rightarrow v=n-1=20-1=19\\) graus de liberdade;\n\\(\\bar{x}=18,0\\) cm;\n\\(s=2,5\\) cm;\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\).\n\n\\[\nt_{\\left(v;\\frac{\\alpha}{2} \\right)}=t_{\\left(19;0,025\\right)}=?\n\\]\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930, conforme esquema abaixo:\n\n\n\nLogo, \\[\nt_{\\left(19;0,025\\right)}=2,0930.\n\\]\nAtravés da expressão (9.9), tem-se que: \\[\n18,0-2,0930\\frac{2,5}{\\sqrt{20}} &lt; \\mu &lt; 18,0+2,0930\\frac{2,5}{\\sqrt{20}}\n\\] \\[\n18,0 - 1,17 &lt; \\mu &lt; 18,0 + 1,17\n\\]\n\\[\n\\Rightarrow IC_{0,95}(\\mu):~[16,83~\\textrm{cm};~ 19,17~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 95,0% a confiança, do verdadeiro DAP médio das árvores de Eucalipto estar entre 16,83 e 19,17 cm. Do ponto de vista de amostragem isto quer dizer que, se forem retiradas várias amostras aleatórias dentro desta população, calculando-se os valores de \\(\\bar{\\text{x}}\\) e \\(s\\) para cada amostra, e construindo o intervalo de confiança para \\(\\mu\\) em cada amostra, 95,0% dos intervalos conterão em seu interior o verdadeiro valor da média populacional \\(\\mu\\).\n\n\n\n\n9.7.3 Intervalo de Confiança para a Diferença entre duas Médias Independentes\nA diferença de médias amostrais, \\(\\bar{x}_1-\\bar{x}_2\\), estima a diferença de médias populacionais, \\(\\mu_1 - \\mu_2\\), por ponto. A partir do conhecimento das distribuições teóricas \\(Z\\) e \\(t\\), pode-se construir um intervalo de confiança de \\((1 – \\alpha)100,0\\%\\) para a diferença de médias \\(\\mu_1 - \\mu_2\\).\nPara a construção do intervalo de confiança para a diferença entre duas médias independentes, tem-se as seguintes situações, descritas a seguir.\n\n9.7.3.1 Grandes Amostras ou Variâncias Populacionais Conhecidas\nO intervalo de confiança associado a um determinado nível de confiança, para a diferença entre duas médias, \\(\\mu_1 - \\mu_2\\), quando se tem grandes amostras, \\(n_1\\) e \\(n_2 \\geq 30\\), ou variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), conhecidas, é dado pela expressão (9.11).\n\\[\nP\\left[(\\bar{x}_{1}-\\bar{x}_{2})-Z_\\frac{\\alpha}{2}\\sqrt{\\frac{\\sigma_{1}^2}{n_1}+\\frac{\\sigma_{2}^2}{n_2}} &lt; (\\mu_1 - \\mu_2) &lt;\\right.\n\\] \\[\n\\left.(\\bar{x}_{1}-\\bar{x}_{2})+Z_\\frac{\\alpha}{2}\\sqrt{\\frac{\\sigma_{1}^2}{n_1}+\\frac{\\sigma_{2}^2}{n_2}}\\right]=1 - \\alpha.\n\\tag{9.11}\\]\nNão se conhecendo \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) pode-se usar \\(s_{1}^2\\) e \\(s_{2}^2\\), desde que \\(n_1\\) e \\(n_2 \\geq 30\\).\n\nExemplo 9.16 Sejam:\n\n\\(X_1:\\) Peso de suínos da raça 1, em kg;\n\n\n\\(X_2:\\) Peso de suínos da raça 2, em kg.\n\nEm que:\n\n\\(X_1 \\sim N(\\mu_1; 166,0)\\)\n\n\n\\(X_2 \\sim N(\\mu_2; 127,0)\\)\n\nSe da população de suínos da raça 1 e da raça 2, são retiradas amostras de tamanhos: \\(n_1 = 10\\) e \\(n_2 = 11\\), respectivamente, obtendo-se: \\(\\bar{x}_{1}=110,0\\) kg e \\(\\bar{x}_{2}=107,0\\) kg. Construir um intervalo com 95,0% de confiança para a diferença de médias das duas raças.\nTem-se então que:\n\n\\(\\sigma_{1}^2=166,0\\) Kg\\(^2\\) e \\(\\sigma_{2}^2=127,0\\) Kg\\(^2\\);\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=110,0 - 107,0 = 3,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025 \\Rightarrow Z_{0,025}=1,96\\) (Tabela A 1).\n\nAtravés da expressão (9.11), tem-se que:\n\\[\n3,0-1,96\\sqrt{\\frac{166,0}{10}+\\frac{127,0}{11}} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n3,0+1,96\\sqrt{\\frac{166,0}{10}+\\frac{127,0}{11}}\n\\]\n\\[\n3,0-10,4 &lt; (\\mu_1 - \\mu_2) &lt; 3,0+10,4.\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-7,4 kg; 13,4 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -7,4 e 13,4 kg. Como o intervalo de confiança abrange o zero, pode-se concluir que o peso médio da raça 1 não difere do peso médio raça 2. Caso o intervalo de confiança não tivesse abrangido o zero, concluiria-se que as médias difeririam entre si.\n\n\n\n9.7.3.2 Pequenas Amostras e Variâncias Populacionais Desconhecidas\nO intervalo de confiança associado a um determinado nível de confiança, para a diferença entre duas médias, \\(\\mu_1 - \\mu_2\\), quando se tem pequenas amostras, \\(n_1 &lt; 30\\) e \\(n_2 &lt; 30\\), e variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), desconhecidas, pode ser determinado considerando as seguintes situações:\n\nVariâncias Populacionais Iguais: Neste caso, para saber se as variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), são iguais, deve-se fazer primeiro o Teste F, o qual será visto com detalhes no Capítulo 10.\n\nDessa forma, um intervalo de confiança de \\((1 - \\alpha)100,0\\%\\), para a diferença de médias, \\(\\mu_1 - \\mu_2\\), pode ser construído utilizando a distribuição \\(t\\), e é dado pela expressão (9.12).\n\\[\nP\\left[(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{s_{p}^2\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)} &lt; (\\mu_1 - \\mu_2) &lt; \\right.\n\\] \\[\n\\left.(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{s_{p}^2\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)} \\right]=1 - \\alpha,\n\\tag{9.12}\\]\nem que:\n\n\\(s_{p}^2=\\frac{(n_{1}-1)s_{1}^2+(n_{2}-1)s_{2}^2}{n_{1}+n_{2}-2}\\) (variância ponderada);\n\\(t_{\\left(\\nu; \\frac{\\alpha}{2}\\right)}\\) é o valor tabelado de \\(t\\), para: \\(\\nu=n_{1}+n_{2} -2\\) graus de liberdade, que deixa uma probabilidade acima dele de \\(\\frac{\\alpha}{2}\\).\n\n\nExemplo 9.17  \nSejam:\n\n\\(X_1:\\) Peso de suínos da raça 1, em kg;\n\n\n\\(X_2:\\) Peso de suínos da raça 2, em kg.\n\nSe da população de suínos da raça 1 e da raça 2, são retiradas amostras de tamanhos: \\(n_1 = 10\\) e \\(n_2 = 11\\), respectivamente, obtendo-se: \\(\\bar{x}_{1}=112,0\\) kg e \\(s_{1}^2=156,0\\) kg\\(^2\\); \\(\\bar{x}_{2}=105,0\\) kg e \\(s_{2}^2=165,0\\) kg\\(^2\\).\nConsiderando que, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) são iguais, construir um intervalo de confiança de 95,0% de confiança para a diferença de médias das duas raças.\nTem-se então que:\n\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=112,0 - 105,0 = 7,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(s_{p}^2=\\frac{(n_{1}-1)s_{1}^2+(n_{2}-1)s_{2}^2}{n_{1}+n_{2}-2}=\\frac{(10-1)156,0+(11-1)165,0}{10+11-2}=160,74\\) kg\\(^2\\);\n\\(v=n_{1}+n_{2} -2=10+11-2=19\\) graus de liberdade.\n\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930.\nLogo,\n\n\\(t_{\\left(v;\\frac{\\alpha}{2}\\right)}=t_{\\left(19; 0,025\\right)}=2,0930\\).\n\nAtravés da expressão (9.12), tem-se que:\n\\[\n7,0-2,0930\\sqrt{160,74\\left(\\frac{1}{10}+\\frac{1}{11} \\right)} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n7,0+2,0930\\sqrt{160,74\\left(\\frac{1}{10}+\\frac{1}{11} \\right)}\n\\]\n\\[\n7,0-11,60 &lt; (\\mu_1 - \\mu_2) &lt; 7,0+11,60.\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-4,60 kg; 18,60 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -4,60 e 18,60 kg. Pode-se concluir que, as duas raças de suínos não diferem entre si com relação ao peso médio, pois o intervalo de confiança abrange o zero.\n\n\nVariâncias Populacionais Diferentes:\n\nNeste caso, também deve-se fazer primeiro o Teste F para verificar se as variâncias são diferentes.\nO intervalo de confiança de \\((1 - \\alpha)100,0\\%\\), para a diferença de médias, \\(\\mu_1 - \\mu_2\\), é dado pela expressão 9.13. \\[\nP\\left[(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)} &lt; (\\mu_1 - \\mu_2) &lt; \\right.\n\\] \\[\n\\left.(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)} \\right]=1 - \\alpha,\n\\tag{9.13}\\] em que: \\(t_{\\left(\\nu; \\frac{\\alpha}{2}\\right)}\\) é o valor tabelado de \\(t\\) com \\(\\nu\\) graus de liberdade que deixa uma probabilidade acima dele de \\(\\frac{\\alpha}{2}\\), sendo “\\(\\nu\\)” dado pela expressão (9.14).\n\\[\n\\nu=\\frac{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_{1}^2}{n_1}\\right)^2}{n_{1}-1}+\\frac{\\left(\\frac{s_{2}^2}{n_2}\\right)^2}{n_{2}-1}},\n\\tag{9.14}\\] conhecida como Fórmula de Satterthwaite.\n\nExemplo 9.18 Considerando o Exemplo 9.17, e supondo que \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) sejam estatisticamente diferentes, construir um intervalo de confiança de 95,0% de confiança para a diferença de médias das duas raças.\nAssim, tem-se que:\n\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=112,0 - 105,0 = 7,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(\\nu=\\frac{\\left(\\frac{156,0}{10}+\\frac{165,0}{11}\\right)^2}{\\frac{\\left(\\frac{156,0}{10}\\right)^2}{10-1}+\\frac{\\left(\\frac{165,0}{11}\\right)^2}{11-1}}=19\\) graus de liberdade.\n\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930. Logo,\n\n\\(t_{\\left(v;\\frac{\\alpha}{2}\\right)}=t_{(19; 0,025)}=2,0930\\).\n\n Através de (9.13), tem-se que:\n\\[\n7,0-2,0930\\sqrt{\\left(\\frac{156,0}{10}+\\frac{165,0}{11} \\right)} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n7,0+2,0930\\sqrt{\\left(\\frac{156,0}{10}+\\frac{165,0}{11} \\right)}\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-4,58 kg; 18,58 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -4,58 e 18,58 kg. Pode-se concluir que, as duas raças de suínos não diferem entre si com relação ao peso médio, pois o intervalo de confiança abrange o zero. Considere a Tabela 9.1.\n\n\n\n\n9.7.4 Intervalo de Confiança para a Média em Amostras Dependentes\nA análise em amostras dependentes é apropriada quando a variável é medida antes e depois, por exemplo, peso de suínos antes e depois de serem submetidos a uma dieta com uma ração especial.\n\n\n\nTabela 9.1: Amostras dependentes.\n\n\n\n\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap10.html",
    "href": "cap10.html",
    "title": "10  Teoria da Decisão",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Teoria da Decisão</span>"
    ]
  },
  {
    "objectID": "cap11.html",
    "href": "cap11.html",
    "title": "11  Correlação e Regressão Linear Simples",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlação e Regressão Linear Simples</span>"
    ]
  },
  {
    "objectID": "tabelas.html",
    "href": "tabelas.html",
    "title": "Tabelas",
    "section": "",
    "text": "Tabela A 1: Distribuição normal padronizada. Probabilidades do valor de \\(Z\\) estar entre 0,0 e o valor de \\(Z\\) padronizado \\((Z_c)\\) – \\(P(0,0 &lt; Z &lt; Z_c)\\). Para valores negativos de \\(Z\\) as probabilidades são obtidas por simetria.    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbf{Z_c}\\)\n0,00\n0,01\n0,02\n0,03\n0,04\n0,05\n0,06\n0,07\n0,08\n0,09\n\n\n\n\n0,0\n0,0000\n0,0040\n0,0080\n0,0120\n0,0160\n0,0199\n0,0239\n0,0279\n0,0319\n0,0359\n\n\n0,1\n0,0398\n0,0438\n0,0478\n0,0517\n0,0557\n0,0596\n0,0636\n0,0675\n0,0714\n0,0753\n\n\n0,2\n0,0793\n0,0832\n0,0871\n0,0910\n0,0948\n0,0987\n0,1026\n0,1064\n0,1103\n0,1141\n\n\n0,3\n0,1179\n0,1217\n0,1255\n0,1293\n0,1331\n0,1368\n0,1406\n0,1443\n0,1480\n0,1517\n\n\n0,4\n0,1554\n0,1591\n0,1628\n0,1664\n0,1700\n0,1736\n0,1772\n0,1808\n0,1844\n0,1879\n\n\n0,5\n0,1915\n0,1950\n0,1985\n0,2019\n0,2054\n0,2088\n0,2123\n0,2157\n0,2190\n0,2224\n\n\n0,6\n0,2257\n0,2291\n0,2324\n0,2357\n0,2389\n0,2422\n0,2454\n0,2486\n0,2517\n0,2549\n\n\n0,7\n0,2580\n0,2611\n0,2642\n0,2673\n0,2704\n0,2734\n0,2764\n0,2794\n0,2823\n0,2852\n\n\n0,8\n0,2881\n0,2910\n0,2939\n0,2967\n0,2995\n0,3023\n0,3051\n0,3078\n0,3106\n0,3133\n\n\n0,9\n0,3159\n0,3186\n0,3212\n0,3238\n0,3264\n0,3289\n0,3315\n0,3340\n0,3365\n0,3389\n\n\n1,0\n0,3413\n0,3438\n0,3461\n0,3485\n0,3508\n0,3531\n0,3554\n0,3577\n0,3599\n0,3621\n\n\n1,1\n0,3643\n0,3665\n0,3686\n0,3708\n0,3729\n0,3749\n0,3770\n0,3790\n0,3810\n0,3830\n\n\n1,2\n0,3849\n0,3869\n0,3888\n0,3907\n0,3925\n0,3944\n0,3962\n0,3980\n0,3997\n0,4015\n\n\n1,3\n0,4032\n0,4049\n0,4066\n0,4082\n0,4099\n0,4115\n0,4131\n0,4147\n0,4162\n0,4177\n\n\n1,4\n0,4192\n0,4207\n0,4222\n0,4236\n0,4251\n0,4265\n0,4279\n0,4292\n0,4306\n0,4319\n\n\n1,5\n0,4332\n0,4345\n0,4357\n0,4370\n0,4382\n0,4394\n0,4406\n0,4418\n0,4429\n0,4441\n\n\n1,6\n0,4452\n0,4463\n0,4474\n0,4484\n0,4495\n0,4505\n0,4515\n0,4525\n0,4535\n0,4545\n\n\n1,7\n0,4554\n0,4564\n0,4573\n0,4582\n0,4591\n0,4599\n0,4608\n0,4616\n0,4625\n0,4633\n\n\n1,8\n0,4641\n0,4649\n0,4656\n0,4664\n0,4671\n0,4678\n0,4686\n0,4693\n0,4699\n0,4706\n\n\n1,9\n0,4713\n0,4719\n0,4726\n0,4732\n0,4738\n0,4744\n0,4750\n0,4756\n0,4761\n0,4767\n\n\n2,0\n0,4772\n0,4778\n0,4783\n0,4788\n0,4793\n0,4798\n0,4803\n0,4808\n0,4812\n0,4817\n\n\n2,1\n0,4821\n0,4826\n0,4830\n0,4834\n0,4838\n0,4842\n0,4846\n0,4850\n0,4854\n0,4857\n\n\n2,2\n0,4861\n0,4864\n0,4868\n0,4871\n0,4875\n0,4878\n0,4881\n0,4884\n0,4887\n0,4890\n\n\n2,3\n0,4893\n0,4896\n0,4898\n0,4901\n0,4904\n0,4906\n0,4909\n0,4911\n0,4913\n0,4916\n\n\n2,4\n0,4918\n0,4920\n0,4922\n0,4925\n0,4927\n0,4929\n0,4931\n0,4932\n0,4934\n0,4936\n\n\n2,5\n0,4938\n0,4940\n0,4941\n0,4943\n0,4945\n0,4946\n0,4948\n0,4949\n0,4951\n0,4952\n\n\n2,6\n0,4953\n0,4955\n0,4956\n0,4957\n0,4959\n0,4960\n0,4961\n0,4962\n0,4963\n0,4964\n\n\n2,7\n0,4965\n0,4966\n0,4967\n0,4968\n0,4969\n0,4970\n0,4971\n0,4972\n0,4973\n0,4974\n\n\n2,8\n0,4974\n0,4975\n0,4976\n0,4977\n0,4977\n0,4978\n0,4979\n0,4979\n0,4980\n0,4981\n\n\n2,9\n0,4981\n0,4982\n0,4982\n0,4983\n0,4984\n0,4984\n0,4985\n0,4985\n0,4986\n0,4986\n\n\n3,0\n0,4987\n0,4987\n0,4987\n0,4988\n0,4988\n0,4989\n0,4989\n0,4989\n0,4990\n0,4990\n\n\n3,1\n0,4990\n0,4991\n0,4991\n0,4991\n0,4992\n0,4992\n0,4992\n0,4992\n0,4993\n0,4993\n\n\n3,2\n0,4993\n0,4993\n0,4994\n0,4994\n0,4994\n0,4994\n0,4994\n0,4995\n0,4995\n0,4995\n\n\n3,3\n0,4995\n0,4995\n0,4995\n0,4996\n0,4996\n0,4996\n0,4996\n0,4996\n0,4996\n0,4997\n\n\n3,4\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4998\n\n\n3,5\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n\n\n3,6\n0,4998\n0,4998\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,7\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,8\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,9\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n\n\n\n\n\n\n\n\n\nTabela A 2: Distribuição normal padronizada. Probabilidades do valor de \\(Z\\) ser maior que o de valor de \\(Z\\) padronizado \\((Z_c)\\) ser igual a \\(\\alpha\\). \\(P(Z &gt; Z_{c}) = \\alpha\\). Para valores negativos de \\(Z\\) as probabilidades são obtidas por simetria. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbf{Z_c}\\)\n0,00\n0,01\n0,02\n0,03\n0,04\n0,05\n0,06\n0,07\n0,08\n0,09\n\n\n\n\n0,0\n0,5000\n0,4960\n0,4920\n0,4880\n0,4840\n0,4801\n0,4761\n0,4721\n0,4681\n0,4641\n\n\n0,1\n0,4602\n0,4562\n0,4522\n0,4483\n0,4443\n0,4404\n0,4364\n0,4325\n0,4286\n0,4247\n\n\n0,2\n0,4207\n0,4168\n0,4129\n0,409\n0,4052\n0,4013\n0,3974\n0,3936\n0,3897\n0,3859\n\n\n0,3\n0,3821\n0,3783\n0,3745\n0,3707\n0,3669\n0,3632\n0,3594\n0,3557\n0,352\n0,3483\n\n\n0,4\n0,3446\n0,3409\n0,3372\n0,3336\n0,33\n0,3264\n0,3228\n0,3192\n0,3156\n0,3121\n\n\n0,5\n0,3085\n0,305\n0,3015\n0,2981\n0,2946\n0,2912\n0,2877\n0,2843\n0,281\n0,2776\n\n\n0,6\n0,2743\n0,2709\n0,2676\n0,2643\n0,2611\n0,2578\n0,2546\n0,2514\n0,2483\n0,2451\n\n\n0,7\n0,242\n0,2389\n0,2358\n0,2327\n0,2296\n0,2266\n0,2236\n0,2206\n0,2177\n0,2148\n\n\n0,8\n0,2119\n0,209\n0,2061\n0,2033\n0,2005\n0,1977\n0,1949\n0,1922\n0,1894\n0,1867\n\n\n0,9\n0,1841\n0,1814\n0,1788\n0,1762\n0,1736\n0,1711\n0,1685\n0,1660\n0,1635\n0,1611\n\n\n1,0\n0,1587\n0,1562\n0,1539\n0,1515\n0,1492\n0,1469\n0,1446\n0,1423\n0,1401\n0,1379\n\n\n1,1\n0,1357\n0,1335\n0,1314\n0,1292\n0,1271\n0,1251\n0,1230\n0,1210\n0,1190\n0,1170\n\n\n1,2\n0,1151\n0,1131\n0,1112\n0,1093\n0,1075\n0,1056\n0,1038\n0,1020\n0,1003\n0,0985\n\n\n1,3\n0,0968\n0,0951\n0,0934\n0,0918\n0,0901\n0,0885\n0,0869\n0,0853\n0,0838\n0,0823\n\n\n1,4\n0,0808\n0,0793\n0,0778\n0,0764\n0,0749\n0,0735\n0,0721\n0,0708\n0,0694\n0,0681\n\n\n1,5\n0,0668\n0,0655\n0,0643\n0,063\n0,0618\n0,0606\n0,0594\n0,0582\n0,0571\n0,0559\n\n\n1,6\n0,0548\n0,0537\n0,0526\n0,0516\n0,0505\n0,0495\n0,0485\n0,0475\n0,0465\n0,0455\n\n\n1,7\n0,0446\n0,0436\n0,0427\n0,0418\n0,0409\n0,0401\n0,0392\n0,0384\n0,0375\n0,0367\n\n\n1,8\n0,0359\n0,0351\n0,0344\n0,0336\n0,0329\n0,0322\n0,0314\n0,0307\n0,0301\n0,0294\n\n\n1,9\n0,0287\n0,0281\n0,0274\n0,0268\n0,0262\n0,0256\n0,0250\n0,0244\n0,0239\n0,0233\n\n\n2,0\n0,0228\n0,0222\n0,0217\n0,0212\n0,0207\n0,0202\n0,0197\n0,0192\n0,0188\n0,0183\n\n\n2,1\n0,0179\n0,0174\n0,0170\n0,0166\n0,0162\n0,0158\n0,0154\n0,015\n0,0146\n0,0143\n\n\n2,2\n0,0139\n0,0136\n0,0132\n0,0129\n0,0125\n0,0122\n0,0119\n0,0116\n0,0113\n0,011\n\n\n2,3\n0,0107\n0,0104\n0,0102\n0,0099\n0,0096\n0,0094\n0,0091\n0,0089\n0,0087\n0,0084\n\n\n2,4\n0,0082\n0,0080\n0,0078\n0,0075\n0,0073\n0,0071\n0,0069\n0,0068\n0,0066\n0,0064\n\n\n2,5\n0,0062\n0,0060\n0,0059\n0,0057\n0,0055\n0,0054\n0,0052\n0,0051\n0,0049\n0,0048\n\n\n2,6\n0,0047\n0,0045\n0,0044\n0,0043\n0,0041\n0,0040\n0,0039\n0,0038\n0,0037\n0,0036\n\n\n2,7\n0,0035\n0,0034\n0,0033\n0,0032\n0,0031\n0,0030\n0,0029\n0,0028\n0,0027\n0,0026\n\n\n2,8\n0,0026\n0,0025\n0,0024\n0,0023\n0,0023\n0,0022\n0,0021\n0,0021\n0,0020\n0,0019\n\n\n2,9\n0,0019\n0,0018\n0,0018\n0,0017\n0,0016\n0,0016\n0,0015\n0,0015\n0,0014\n0,0014\n\n\n3,0\n0,0013\n0,0013\n0,0013\n0,0012\n0,0012\n0,0011\n0,0011\n0,0011\n0,0010\n0,0010\n\n\n3,1\n0,0010\n0,0009\n0,0009\n0,0009\n0,0008\n0,0008\n0,0008\n0,0008\n0,0007\n0,0007\n\n\n3,2\n0,0007\n0,0007\n0,0006\n0,0006\n0,0006\n0,0006\n0,0006\n0,0005\n0,0005\n0,0005\n\n\n3,3\n0,0005\n0,0005\n0,0005\n0,0004\n0,0004\n0,0004\n0,0004\n0,0004\n0,0004\n0,0003\n\n\n3,4\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0002\n\n\n3,5\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n\n\n3,6\n0,0002\n0,0002\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,7\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,8\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,9\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n\n\n\n\n\n\n\n\n\nTabela A 3: Distribuição \\(t-Student\\). Valores de \\(t_{(\\nu; \\alpha)}\\), tal que: \\(P(t &gt; t_{(\\nu; \\alpha)}) = \\alpha\\). Para valores negativos de \\(t_{(\\nu; \\alpha)}\\) os valores de \\(\\alpha\\) são os mesmos, apenas sendo visualizado para o lado esquerdo do gráfico da distribuição \\(t-Student\\), por questão de simetria. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\nu\\)/\\(\\alpha\\)\n10,00%\n5,00%\n2,50%\n1,00%\n0,50%\n0,25%\n0,10%\n0,05%\n\n\n\n\n1\n3,0777\n6,3137\n12,7062\n31,8210\n63,6559\n127,3211\n318,2888\n636,5776\n\n\n2\n1,8856\n2,9200\n4,3027\n6,9645\n9,9250\n14,0892\n22,3285\n31,5998\n\n\n3\n1,6377\n2,3534\n3,1824\n4,5407\n5,8408\n7,4532\n10,2143\n12,9244\n\n\n4\n1,5332\n2,1318\n2,7765\n3,7469\n4,6041\n5,5975\n7,1729\n8,6101\n\n\n5\n1,4759\n2,0150\n2,5706\n3,3649\n4,0321\n4,7733\n5,8935\n6,8685\n\n\n6\n1,4398\n1,9432\n2,4469\n3,1427\n3,7074\n4,3168\n5,2075\n5,9587\n\n\n7\n1,4149\n1,8946\n2,3646\n2,9979\n3,4995\n4,0294\n4,7853\n5,4081\n\n\n8\n1,3968\n1,8595\n2,3060\n2,8965\n3,3554\n3,8325\n4,5008\n5,0414\n\n\n9\n1,3830\n1,8331\n2,2622\n2,8214\n3,2498\n3,6896\n4,2969\n4,7809\n\n\n10\n1,3722\n1,8125\n2,2281\n2,7638\n3,1693\n3,5814\n4,1437\n4,5868\n\n\n11\n1,3634\n1,7959\n2,2010\n2,7181\n3,1058\n3,4966\n4,0248\n4,4369\n\n\n12\n1,3562\n1,7823\n2,1788\n2,6810\n3,0545\n3,4284\n3,9296\n4,3178\n\n\n13\n1,3502\n1,7709\n2,1604\n2,6503\n3,0123\n3,3725\n3,8520\n4,2209\n\n\n14\n1,3450\n1,7613\n2,1448\n2,6245\n2,9768\n3,3257\n3,7874\n4,1403\n\n\n15\n1,3406\n1,7531\n2,1315\n2,6025\n2,9467\n3,2860\n3,7329\n4,0728\n\n\n16\n1,3368\n1,7459\n2,1199\n2,5835\n2,9208\n3,2520\n3,6861\n4,0149\n\n\n17\n1,3334\n1,7396\n2,1098\n2,5669\n2,8982\n3,2224\n3,6458\n3,9651\n\n\n18\n1,3304\n1,7341\n2,1009\n2,5524\n2,8784\n3,1966\n3,6105\n3,9217\n\n\n19\n1,3277\n1,7291\n2,0930\n2,5395\n2,8609\n3,1737\n3,5793\n3,8833\n\n\n20\n1,3253\n1,7247\n2,0860\n2,5280\n2,8453\n3,1534\n3,5518\n3,8496\n\n\n21\n1,3232\n1,7207\n2,0796\n2,5176\n2,8314\n3,1352\n3,5271\n3,8193\n\n\n22\n1,3212\n1,7171\n2,0739\n2,5083\n2,8188\n3,1188\n3,5050\n3,7922\n\n\n23\n1,3195\n1,7139\n2,0687\n2,4999\n2,8073\n3,1040\n3,4850\n3,7676\n\n\n24\n1,3178\n1,7109\n2,0639\n2,4922\n2,7970\n3,0905\n3,4668\n3,7454\n\n\n25\n1,3163\n1,7081\n2,0595\n2,4851\n2,7874\n3,0782\n3,4502\n3,7251\n\n\n26\n1,3150\n1,7056\n2,0555\n2,4786\n2,7787\n3,0669\n3,4350\n3,7067\n\n\n27\n1,3137\n1,7033\n2,0518\n2,4727\n2,7707\n3,0565\n3,4210\n3,6895\n\n\n28\n1,3125\n1,7011\n2,0484\n2,4671\n2,7633\n3,0470\n3,4082\n3,6739\n\n\n29\n1,3114\n1,6991\n2,0452\n2,4620\n2,7564\n3,0380\n3,3963\n3,6595\n\n\n30\n1,3104\n1,6973\n2,0423\n2,4573\n2,7500\n3,0298\n3,3852\n3,6460\n\n\n31\n1,3095\n1,6955\n2,0395\n2,4528\n2,7440\n3,0221\n3,3749\n3,6335\n\n\n32\n1,3086\n1,6939\n2,0369\n2,4487\n2,7385\n3,0149\n3,3653\n3,6218\n\n\n33\n1,3077\n1,6924\n2,0345\n2,4448\n2,7333\n3,0082\n3,3563\n3,6109\n\n\n34\n1,3070\n1,6909\n2,0322\n2,4411\n2,7284\n3,0020\n3,3480\n3,6007\n\n\n35\n1,3062\n1,6896\n2,0301\n2,4377\n2,7238\n2,9961\n3,3400\n3,5911\n\n\n36\n1,3055\n1,6883\n2,0281\n2,4345\n2,7195\n2,9905\n3,3326\n3,5821\n\n\n37\n1,3049\n1,6871\n2,0262\n2,4314\n2,7154\n2,9853\n3,3256\n3,5737\n\n\n38\n1,3042\n1,6860\n2,0244\n2,4286\n2,7116\n2,9803\n3,3190\n3,5657\n\n\n39\n1,3036\n1,6849\n2,0227\n2,4258\n2,7079\n2,9756\n3,3127\n3,5581\n\n\n40\n1,3031\n1,6839\n2,0211\n2,4233\n2,7045\n2,9712\n3,3069\n3,5510\n\n\n50\n1,2987\n1,6759\n2,0086\n2,4033\n2,6778\n2,9370\n3,2614\n3,4960\n\n\n60\n1,2958\n1,6706\n2,0003\n2,3901\n2,6603\n2,9146\n3,2317\n3,4602\n\n\n120\n1,2886\n1,6576\n1,9799\n2,3578\n2,6174\n2,8599\n3,1595\n3,3734\n\n\n200\n1,2858\n1,6525\n1,9719\n2,3451\n2,6006\n2,8385\n3,1315\n3,3398\n\n\n400\n1,2837\n1,6487\n1,9659\n2,3357\n2,5882\n2,8227\n3,1108\n3,3151\n\n\n600\n1,2830\n1,6474\n1,9639\n2,3326\n2,5841\n2,8175\n3,1039\n3,3068\n\n\n\\(\\infty\\)\n1,2816\n1,6449\n1,9600\n2,3264\n2,5759\n2,8071\n3,0903\n3,2906\n\n\n\n\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Tabelas"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação\nAgrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos\nAgrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem.\nSão Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à\nInferência Estatística. 2. ed. São\nPaulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental\nDesigns. 2. ed. New York: John Wiley & Sons,\n2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo:\nSaraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso\nIntrodutório. 3. ed. São Paulo: EDUSP, 2008. p.\n256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis.\n3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias.\n3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de\nProbabilidade e Estatística. 7. ed.\nSão Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística.\n2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of\nExperiments. 9. ed. New Jersey: Wiley, 2019. p.\n752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada\ne Probabilidade para Engenheiros. 7.\ned. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the\nTheory of Statistics. New York: John\nWiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística.\nSão Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística\nExperimental. 15. ed. Piracicaba: FEALQ, 2022. p.\n451\n\n\nSILVA, N. N. Amostragem Probabilística. 3.\ned. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de\nRegressão Linear e\nNão-Linear. Brasília: EMBRAPA, 1998.\np. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of\nstatistics: A biometrical approach. 2. ed. New York:\nMcGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Referências"
    ]
  }
]