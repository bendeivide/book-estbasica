[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estatística Básica aplicada às Ciências Agrárias",
    "section": "",
    "text": "Bem-vindo\nEsse é um livro digital intitulado “Estatística Básica aplicada às Ciências Agrárias”, com o selo Democratizando Conhecimento (DC). Este livro é um convite à leitura para as bases da Estatística Básica, apresentando de forma aplicada os conceitos tão importantes para a área da ciência de uma forma geral. Todos os exemplos são aplicados às Ciências Agrárias.   O número de leitores que acessaram esse livro: \n\n\n \n\n\n\nLivro físico\n\n\nISBN\n\nISBN (Digital): 978-65-01-05500-8\nISBN (Físico): 978-65-01-05508-4\n\n\n\nLicença\n\n\n\n\n\nEste trabalho está sob a Licença Creative Commons - Atribuição-NãoComercial 4.0 Internacional.\n\n\n\n\n\n\n\nUsamos também a filosofia de trabalho com o Selo Democratizando Conhecimento (DC), que pode ser acessada em https://bendeivide.github.io/dc/. O leitor é livre para compartilhar, redistribuir, transformar ou adaptar esta obra, desde que não venha a utilizá-la em nenhuma atividade de propósito comercial. Por fim, a única exigência é a atribuição dos créditos aos autores da obra.\n\n\n \n\n\nComo citar\n\nComo citar essa obra (Impressa):\n\nCUSTÓDIO, T. C.; BATISTA, B. D. O.. Estatística Básica Aplicada às Ciências Agrárias. Ouro Branco, MG: [s.n.]. 2024. 336 p. ISBN 978-65-01-05508-4.\n\nComo citar essa obra (Digital):\n\nCUSTÓDIO, T. C.; BATISTA, B. D. O.. Estatística Básica Aplicada às Ciências Agrárias. Ouro Branco, MG: [s.n.]. 2024. ISBN 978-65-01-05500-8. Disponível em: https://bendeivide. github.io/book-estbasica/. Acesso em: 10 de junho de 2024.\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "cap01.html",
    "href": "cap01.html",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "",
    "text": "1.1 Introdução\nEm todo processo produtivo do setor agropecuário constantemente se busca a melhoria da qualidade de seus produtos e serviços. Uma porção significativa deste esforço de melhoria da qualidade será comandada por profissionais das ciências agrárias, pois esses profissionais projetam e desenvolvem novos sistemas e processos de produção, sendo também aqueles que melhoram os sistemas de produção existentes.\nNas diferentes áreas das ciências agrárias frequentemente trabalha-se com um grande volume de dados, sendo necessário dar um tratamento matemático a esses dados. Assim surge a Ciência Estatística, pois seus métodos são uma importante ferramenta nessas atividades, porque eles proveem os profissionais envolvidos com métodos descritivos e analíticos, para lidar com a variabilidade nos dados observados.\nPara o entendimento da Estatística se faz necessário que uma série de termos, definições e apresentação de alguns teoremas sejam apresentados e compreendidos. Assim, ao longo de todo o livro será realizado uma abordagem de todas essas informações, sem se estender ao rigor matemático, para que de forma prática a base necessária para o conhecimento da Estatística seja acessível a todos os níveis de aprendizagem dentro das ciências agrárias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#defgerais",
    "href": "cap01.html#defgerais",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "1.2 Definições Gerais",
    "text": "1.2 Definições Gerais\nA seguir são apresentados alguns termos que serão empregados no decorrer deste livro.\n\n1.2.1 Estatística\nEstatística pode ser definida como sendo um conjunto de técnicas que permite: coletar, organizar, analisar e interpretar dados oriundos de estudos ou experimentos, realizados em qualquer área do conhecimento.\n\nExemplo 1.1 Seja uma área cultivada com algodão em que se mede a altura de vinte plantas.\n\nColeta:\n\n1ª planta: \\(1,0\\) m;\n2ª planta: \\(1,5\\) m;\n3ª planta: \\(1,3\\) m;\n\\(\\qquad\\vdots\\)\n20ª planta: \\(0,8\\) m.\n\nOrganização: Tabelas e gráficos.\nAnálise: Qual é a altura média?\nInterpretação: Por que tão baixa (ou tão alta) essa altura média?\n\n\n\n\n1.2.2 População\nUm conjunto de elementos com pelo menos uma característica em comum é chamado de população. Corresponde, portanto, ao grande conjunto de dados que contém a característica que se deseja descrever.\n\nExemplo 1.2  \n\nPlantas de uma determinada cultura;\nAnimais de um rebanho;\nÁrvores de um povoamento florestal;\nTratores de uma região produtora de grãos;\netc.\n\n\nO tamanho da população, ou seja, o número de elementos que a compõem, é representado pela letra maiúscula “\\(N\\)”.\n\n\n1.2.3 Censo\nUm estudo envolvendo todos os elementos de uma população é denominado censo.\n\nExemplo 1.3  \n\nLevantamento de dados referentes a situação sanitária do rebanho bovino leiteiro da região Sul de Minas Gerais;\nContagem do número de máquinas agrícolas nas propriedades rurais de uma determinada região;\nLevantamento sócio-econômico das famílias de uma comunidade rural, de uma determinada região produtora de cana-de-açúcar;\netc.\n\n\n\n\n1.2.4 Amostra\nEm muitos casos na execução de uma pesquisa é impossível avaliar todos os elementos de uma população, isto por problemas de custo e/ou tempo. Quando este é o caso, conhece-se a população a partir do estudo de uma parte dela, chamada amostra. Assim amostra é um subconjunto de elementos que pertence a uma população.\n\nExemplo 1.4  \n\n30 plantas de uma determinada cultura;\n100 bovinos leiteiros da região sul de Minas Gerais;\n20 pés de café de uma lavoura;\n200 árvores de um povoamento florestal;\n15 tratores de uma região produtora de grãos;\netc.\n\n\nO tamanho da amostra, isto é, o número de elementos que a compõem, é representado pela letra minúscula “\\(n\\)”.\n\n\n1.2.5 Variável\nUma variável é a característica pela qual deseja-se que a população seja descrita. Pode assumir diferentes valores de elemento para elemento.\nSão usadas as seguintes notações para variável: \\(X\\), \\(Y\\), \\(Z\\), etc. (letras maiúsculas).\n\nExemplo 1.5  \n\n\\(X\\): Peso, em kg, de bovinos da raça nelore.\n\n\nAs variáveis podem ser qualitativas ou quantitativas.\n\n1.2.5.1 Variável Qualitativa\nAs variáveis qualitativas correspondem a atributos ou categorias. Subdivididas em:\n\nVariável Qualitativa Nominal: Quando os atributos não são passíveis de ordenação.\n\n\nExemplo 1.6  \n\n\\(X\\): Culturas predominantes numa região: milho, cana, soja, etc;\n\\(Y\\): Atividades exercidas pelos produtores rurais de uma determinada região: pecuária leiteira, avicultura, suinocultura, produção de hortaliças, etc.\n\n\n\nVariável Qualitativa Ordinal: Quando os atributos são passíveis de ordenação.\n\n\nExemplo 1.7  \n\n\\(X\\): Graus de ataque de insetos numa lavoura: baixo, médio, alto;\n\\(Y\\): Índice de tecnificação adotado pelos agricultores de uma determinada região: baixo, médio, alto;\n\n\n\n\n1.2.5.2 Variável Quantitativa\nAs variáveis quantitativas correspondem a números resultantes de contagens ou medidas. Podem ser:\n\nVariável Quantitativa Discreta: São próprias de dados de contagem, isto é, estão definidas em um conjunto enumerável de valores.\n\n\nExemplo 1.8  \n\n\\(X\\): Número de ovos depositados por um inseto nas folhas de uma cultura: \\(5\\), \\(3\\), \\(10\\), etc;\n\\(Y\\): Número de tratores nas propriedades rurais de uma região: \\(1\\), \\(2\\), \\(0\\), \\(3\\), \\(1\\), etc;\n\\(Z\\): Número de animais infectados pela febre aftosa em fazendas leiteiras de uma região produtora de leite: \\(4\\), \\(2\\), \\(6\\), \\(5\\), etc.\n\n\n\nVariável Quantitativa Contínua: São aquelas em que as realizações resultam de uma medida, e que podem assumir qualquer valor real dentro de um intervalo de valores.\n\n\nExemplo 1.9  \n\n\\(X\\): Altura dos pés de algodão: 1,0 m; 1,5 m; 0,8 m; etc;\n\\(Y\\): Pesos de bezerras da raça holandesa de uma fazenda produtora de leite: 32,0 kg; 28,0 kg; 26,0 kg; etc.\n\n\n\n\n\n1.2.6 Dado\nDado é a realização de uma variável, ou seja, é o valor registrado para um elemento em particular. As notações utilizadas para o dado são: \\(x\\), \\(y\\), \\(z\\), etc. (letras minúsculas).\n\nExemplo 1.10 Considere a variável:\n\n\\(X\\): Peso, em kg, de bovinos da raça nelore.\n\nPode-se ter, por exemplo, os seguintes dados:\n\n\\(x_1 = 322,0\\) kg;\n\\(x_2 = 335,0\\) kg;\n\\(x_3 = 318,0\\) kg;\netc.\n\n\n\n\n1.2.7 Divisão da Estatística\nA Estatística pode ser dividida basicamente em duas partes:\n\nEstatística Descritiva: É utilizada na fase inicial da análise, ou seja, quando se tem um primeiro contato com os dados, onde se objetiva tirar conclusões de modo informal e direto de características de interesse. Pode ser definida como sendo um conjunto de técnicas para descrever e resumir um conjunto de dados, sejam eles amostrais ou populacionais.\nInferência Estatística: É um conjunto de técnicas responsáveis pela análise e interpretação dos dados, obtidos a partir de uma amostra, que possibilita a extrapolação dos resultados para toda a população de interesse.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#tecsom",
    "href": "cap01.html#tecsom",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "1.3 Técnicas de Somatório",
    "text": "1.3 Técnicas de Somatório\nEm estatística frequentemente trabalha-se com variáveis quantitativas, e nos próximos capítulos aparecerão diversas expressões que envolverão cálculos de somas, somas de termos ao quadrado, produtos de duas variáveis, e para isso é necessário uma simplificação da notação. Assim, é usual representar somas por um operador chamado somatório, que é representado pela letra grega sigma maiúscula (\\(\\Sigma\\)).\nPor exemplo, a soma: \\[\\begin{align*}\n  x_1 + x_2 + x_3 + x_4 + x_5,\n\\end{align*}\\] pode ser representada em notação de somatório da seguinte forma: \\[\\begin{align*}\n  \\sum_{i=1}^{5}x_i,\n\\end{align*}\\] ou seja, corresponde à soma dos termos \\(x_i\\) onde o índice \\(i\\) varia de \\(1\\) a \\(5\\).\n\n1.3.1 Propriedades\nSejam \\(X\\), \\(Y\\) e \\(Z\\) variáveis quantitativas, e sejam \\(a\\) e \\(b\\) valores constantes. Assim o operador somatório apresenta as seguintes propriedades, dadas por:\n\n\\(\\sum_{i=1}^{n}a=a+a+\\ldots+a=n a\\);\n\\(\\sum_{i=1}^{n}ax_{i}=ax_{1}+ax_{2}+ \\ldots +ax_{n}=a(x_{1}+x_{2}+\\ldots+x_{n})=a\\sum_{i=1}^{n}x_i\\);\n\\(\\sum_{i=1}^{n}(a+bx_{i})=\\sum_{i=1}^{n}a+\\sum_{i=1}^{n}bx_{i}=na+b\\sum_{i=1}^{n}x_i\\);\n\\(\\sum_{i=1}^{n}(x_{i}+y_{i}+z_{i})=\\sum_{i=1}^{n}x_i+\\sum_{i=1}^{n}y_i+\\sum_{i=1}^{n}z_i\\);\n\\(x_1y_1+x_2y_2+ \\ldots +x_ny_n=\\sum_{i=1}^{n}x_{i}y_{i}\\).\n\n\nExemplo 1.11 Sejam os seguintes conjuntos de dados: \\[\\begin{align*}\n    X = \\left\\{ 1, 3, 2, 0 \\right\\} \\textrm{ e } Y = \\left\\{ 0, 2, 2, 1 \\right\\}.\n\\end{align*}\\] Assim, pode-se obter os seguintes somatórios:\n\n\\(\\sum_{i=1}^{4}x_i=x_1+x_2+x_3+x_4=1+3+2+0=6\\);\n\\(\\sum_{j=1}^{4}y_j=y_1+y_2+y_3+y_4=0+2+2+1=5\\);\n\\(\\sum_{i=2}^{4}x_i=x_2+x_3+x_4=3+2+0=5\\);\n\\(\\sum_{j=2}^{4}y_j=y_2+y_3+y_4=2+2+1=5\\);\n\\(\\sum_{i=1}^{4}x_{i}^{2}=x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}=1^2+3^2+2^2+0^2=14\\);\n\\(\\sum_{j=1}^{4}y_{j}^{2}=y_{1}^{2}+y_{2}^{2}+y_{3}^{2}+y_{4}^{2}=0^2+2^2+2^2+1^2=9\\);\n\\(\\left(\\sum_{i=1}^{4}x_i \\right)^2=6^2=36\\);\n\\(\\left(\\sum_{j=1}^{4}y_j \\right)^2=5^2=25\\);\n\\(\\sum_{i=1}^{4}4x_i=4\\sum_{i=1}^{4}x_i=4(6)=24\\);\n\\(\\sum_{j=1}^{4}3y_j=3\\sum_{j=1}^{4}y_j=3(5)=15\\);\n\\(\\sum_{i=1,j=1}^{n}x_iy_j=x_1y_1+x_2y_2+x_3y_3+x_4y_4=1(0)+3(2)+2(2)+0(1)=10\\);\n\\(\\sum_{i=1,j=1}^{n}x_iy_j+\\sum_{i=1}^{4}x_{i}^{2}+\\sum_{i=1}^{4}y_{i}^{2}=10+14+9=33\\);\n\\(\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{4}x_i}{n}=\\frac{6}{4}=1,5\\);\n\\(\\bar{\\text{y}}=\\frac{\\sum_{j=1}^{4}y_j}{n}=\\frac{5}{4}=1,25\\).\n\n\n\nExemplo 1.12 Expressando as seguintes somas usando notação de somatório, tem-se:\n\n\\(y_1+y_2+y_3+\\cdots+y_{15}=\\sum_{i=1}^{15}y_i\\);\n\\(x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+\\cdots+x_{n}^{2}=\\sum_{i=1}^{n}x_{i}^{2}\\);\n\\(z_{1}^{1}+z_{3}^{2}+z_{5}^{3}+\\cdots+z_{59}^{30}=\\sum_{i=1}^{30}z_{2i-1}^{i}\\);\n\\(logx_1+logx_2+logx_3+\\cdots+logx_{12}=\\sum_{i=1}^{12}logx_i\\);\n\\((x_{1}-1)+(x_{2}^{2}-2^2)^2+(x_{3}^{3}-3^3)^3+\\cdots+(x_{n}^{n}-n^n)^n=\\sum_{i=1}^{n}(x_{i}^{i}-i^i)^i\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap01.html#exprop",
    "href": "cap01.html#exprop",
    "title": "1  Definições Gerais e Técnicas de Somatório",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 1.1 Apresente um exemplo para cada tipo de variável e inclua um possível valor (dado) para cada uma delas.\n\nQualitativa nominal;\nQualitativa ordinal;\nQuantitativa discreta;\nQuantitativa contínua.\n\n\n\nExercício 1.2 Considere as seguintes situações:\n\nUma cooperativa agrícola deseja realizar uma pesquisa com o objetivo de caracterizar as propriedades de seus cooperados. Como forma de obter essas informações foram distribuídos questionários para todos os seus associados, por meio do qual procurou-se avaliar: o nível de tecnificação adotado (baixo, médio ou alto), a atividade predominante (café, milho, leite, etc.), o número de empregados em cada propriedade;\nUm pesquisador necessita obter algumas informações a respeito de uma determinada cultura no Sul de Minas Gerais. Para tanto visita 50 propriedades e faz uma avaliação referentes: ao tamanho da área plantada com a cultura (ha), a produção obtida (kg), as principais pragas e doenças.\n\nPergunta-se:\n\nQual é a população em estudo;\nEm qual dos casos utilizou-se de uma amostra para realizar o estudo;\nQuais foram as variáveis estudadas em cada caso;\nClassifique as variáveis quanto a sua natureza.\n\n\n\nExercício 1.3 Sabendo-se que:\n\n\\(\\sum_{i=1}^{4}x_i=16\\);\n\\(\\sum_{i=1}^{4}x_i^2=84\\);\n\\(\\sum_{i=1}^{4}x_i^3=496\\);\n\\(\\sum_{i=1}^{4}y_i=20\\);\n\\(\\sum_{i=1}^{4}x_{i}y_{i}=100\\).\n\nDetermine o valor numérico das seguintes expressões:\n\n\\(\\sum_{i=1}^{4}\\left(x_{i}^{3}-25 \\right)\\);\n\\(\\sum_{i=1}^{4}\\left(3x_{i}-15 \\right)^3\\);\n\\(\\sum_{i=1}^{4}\\left(6x_{i}+8 \\right)^2\\);\n\\(\\sum_{i=1}^{4}\\left(12x_{i}-26 \\right)\\left(5y_{i}+10 \\right)\\).\n\n\n\nExercício 1.4 Em um estudo com a cultura da batata obteve-se os seguintes resultados:\n\n\n\n\\(\\mathbf{X}\\)\n\\(\\mathbf{Y}\\)\n\n\n\n\n\n0,5\n10,0\n\n\n\n1,0\n14,0\n\n\n\n1,5\n15,0\n\n\n\n2,0\n18,0\n\n\n\n2,5\n20,0\n\n\n\n3,0\n22,0\n\n\n\n3,5\n22,0\n\n\n\n\nEm que:\n\nX é o nível de irrigação, em mm/dia;\nY é a produtividade, em t/ha.\n\nCalcule:\n\n\\(\\sum_{i=1}^{7}x_i\\);\n\\(\\sum_{i=1}^{7}y_i\\);\n\\(\\sum_{i=1}^{7}x_{i}^{2}\\);\n\\(\\sum_{i=1}^{7}y_{i}^{2}\\);\n\\(\\left(\\sum_{i=1}^{7}x_i \\right)^2\\);\n\\(\\left(\\sum_{i=1}^{7}y_i\\right)^2\\);\n\\(\\sum_{i=1}^{7}x_{1}y_{i}\\);\n\\(\\sum_{i=1}^{7}x_i\\sum_{i=1}^{7}y_i\\);\n\\(\\sum_{i=1}^{7}x_i+\\sum_{i=1}^{7}y_i\\);\n\\(\\sum_{i=1}^{7}\\left(x_{i}+y_{i} \\right)\\).\n\n\n\nExercício 1.5 Prove algebricamente as seguintes igualdades:\n\n\\(\\sum_{i=1}^{n}\\left(x_{i}- \\bar{\\text{x}} \\right)=0\\), onde: \\(\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{n}x_i}{n}\\);\n\\(\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^2}{n-1}=\\frac{\\sum_{i=1}^{n}x_i^2-\\frac{\\left(\\sum_{i=1}^{n}x_i\\right)^2}{n}}{n-1}\\).\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais e Técnicas de Somatório</span>"
    ]
  },
  {
    "objectID": "cap02.html",
    "href": "cap02.html",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "",
    "text": "2.1 Introdução\nO material básico com que o pesquisador trabalha são os dados provenientes de variáveis, sendo que a coleta destes é o passo inicial na avaliação estatística de uma pesquisa. Os dados da forma como foram coletados representam os dados brutos, e sempre se apresentam desordenados. Os dados colocados em ordem crescente ou decrescente representam os dados elaborados.\nO passo seguinte é sintetizar os valores que uma ou mais variáveis podem assumir, para que se tenha uma visão global da variação dessa ou dessas variáveis. Inicialmente esses valores são apresentados em tabelas e gráficos, que irão nos fornecer rápidas e seguras informações a respeito das variáveis em estudo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#reptab",
    "href": "cap02.html#reptab",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.2 Representação Tabular",
    "text": "2.2 Representação Tabular\nUma tabela é um quadro que resume um conjunto de dados. Segundo Crespo (2009), uma tabela pode ser dividida em duas partes: principais e secundárias. As partes principais são:\n\nCorpo: Conjunto de linhas e colunas que contêm informações sobre a variável em estudo.\nCabeçalho: Parte superior da tabela que especifica o conteúdo das colunas.\nColuna indicadora: Parte da tabela que especifica o conteúdo das linhas.\nLinhas: Retas imaginárias que facilitam a leitura no sentido horizontal, de dados que se inscrevem nos seus cruzamentos com as colunas.\nCasa ou célula: Espaço destinado a um só valor.\n\nAs partes secundárias são:\n\nTítulo: Conjunto de informações as mais completas possíveis. Deve responder as seguintes perguntas: O quê? Quando? Onde?, relativas à variável estudada.\nRodapé: É um espaço na parte inferior da tabela utilizado para colocar informações necessárias referentes aos dados.\nFonte: É a indicação da entidade responsável pela elaboração da tabela. Deve ser colocada no rodapé, no final da tabela. Esse procedimento garante a honestidade científica e serve como indicativo para posteriores consultas.\nNotas: Também podem ser colocadas no rodapé, depois da fonte, de forma sintética. As notas têm caráter geral, referindo-se à totalidade da tabela. Devem ser enumeradas em algarismos romanos, quando existirem duas ou mais.\nChamadas: As chamadas têm caráter particular, referindo-se a um item específico da tabela. São enumeradas em algarismos arábicos, entre parênteses.\n\nA seguir será abordado o Exemplo 2.1 para se observar o desenvolvimento de uma tabela.\n\nExemplo 2.1 Considere o exemplo de tabela a seguir, que representa a produção de grãos, em ordem decrescente da quantidade produzida, segundo os principais produtos agrícolas, Brasil, 2005.\n\n\n\n2.2.1 Tabela de distribuição de frequências\nUm das maneiras de se organizar e resumir um conjunto de dados é através de uma tabela de distribuição de frequências, sendo que estas permitem identificar características de interesse dos dados sob análise. Essas tabelas podem ser de dois tipos:\n\ntabela de distribuição de frequências simples1: Os dados são agrupados sem intervalos de classes com as respectivas frequências de ocorrência.\nTabela de Distribuição de Frequências com dados agrupados em intervalos de classes: Os dados são agrupados em intervalos de classes com as respectivas frequências de ocorrência.\n\nNa Tabela de Distribuição de Frequências, podem ser identificadas as seguintes frequências:\n\nAbsoluta \\((F_i)\\)}: Número de dados ocorridos em cada nível ou categoria da variável sob estudo. A soma das frequências absolutas corresponde ao total de dados (tamanho da amostra ou população);\nRelativa \\((Fr_i)\\)}: Obtida pela divisão da frequência absoluta pelo número total de dados;\nPercentual \\((Fp_i)\\)}: Frequência relativa multiplicada por 100;\nFrequência acumulada para baixo \\((Fc\\downarrow)\\)}: Mostra quantos dados são menores que um determinado valor;\nFrequência acumulada para cima \\((Fc\\uparrow)\\)}: Mostra quantos dados são maiores que um determinado valor.\n\nPara se organizar um conjunto de dados em uma tabela de distribuição de frequências, primeiro deve-se conhecer qual é o tipo de informação que se está trabalhando, isto é, que tipo de variável correspondem os dados coletados, se qualitativos ou quantitativos.\n\n2.2.1.1 Variáveis qualitativas\nNo caso de variáveis qualitativas, nominal ou ordinal, utiliza-se de uma tabela de distribuição de frequências simples para se organizar e resumir tais variáveis, sendo apresentado o Exemplo 2.2 a seguir.\n\nExemplo 2.2 Um Engenheiro Agrônomo conduziu um estudo com o objetivo de se conhecer o nível de tecnificação (baixo, médio ou alto), adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais. Foi avaliada uma amostra de 50 produtores rurais e os resultados estão apresentados na Tabela 2.1.\n\n\n\nTabela 2.1: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007 (dados brutos).\n\n\n\n\n\nBaixo\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nAlto\nMédio\nAlto\nMédio\n\n\nAlto\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nMédio\nBaixo\nMédio\nMédio\n\n\nMédio\nMédio\nMédio\nMédio\nBaixo\n\n\nMédio\nBaixo\nMédio\nMédio\nMédio\n\n\nAlto\nBaixo\nAlto\nMédio\nMédio\n\n\nBaixo\nMédio\nMédio\nBaixo\nAlto\n\n\nBaixo\nAlto\nMédio\nMédio\nMédio\n\n\nMédio\nMédio\nBaixo\nMédio\nMédio\n\n\n\n\n\n\nO próximo passo é ordenar os dados pelo nível de tecnificação (baixo, médio e alto), obtendo-se os dados elaborados dispostos na Tabela 2.2.\n\n\n\nTabela 2.2: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007 (dados elaborados).\n\n\n\n\n\nBaixo\nBaixo\nMédio\nMédio\nMédio\n\n\nBaixo\nBaixo\nMédio\nMédio\nAlto\n\n\nBaixo\nBaixo\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\nBaixo\nMédio\nMédio\nMédio\nAlto\n\n\n\n\n\n\nA seguir conta-se o número de produtores rurais com nível de tecnificação baixo, médio e alto, ou seja, a frequência absoluta, e organiza-se os dados em uma tabela, dividida em classes (baixo, médio e alto) com as respectivas frequências de ocorrência. Os resultados estão apresentados na Tabela 2.3.\n\n\n\nTabela 2.3: Nível de tecnificação adotado pelos produtores rurais da região do Alto Rio Grande, sul de Minas Gerais, 2007.2\n\n\n\n\n\n\n\n\n\n\n\nNível de Tecnificação\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\nBaixo\n13\n0,26\n26,0\n\n\nMédio\n28\n0,56\n56,0\n\n\nAlto\n9\n0,18\n18,0\n\n\nTotal\n50\n1,00\n100,0\n\n\n\n\n\n\nObservando os resultados da Tabela 2.3, tem-se que 56,0% dos produtores rurais adotam em suas propriedades um nível médio de tecnologia, porém apenas 18,0% empregam altas tecnologias, e 26,0% utilizam-se de baixas tecnologias de produção. Esses resultados pode orientar melhor os trabalhos dos Extensionistas que trabalham na região.\n\n\n\n2.2.1.2 Variáveis quantitativas\n\nDiscretas: Se os dados de uma amostra ou população estiverem representados por variáveis quantitativas discretas, eles estarão naturalmente classificados, isto é, separados em grupos distintas. Para se ter uma ideia do modo como os dados se distribuem, basta escrever em uma coluna os valores da variável discreta estudada em ordem crescente e, assinalar em outra coluna paralela, o número de vezes em que cada um desses valores foi observado, isto é, a frequência absoluta de cada valor. Neste caso utiliza-se de uma tabela de distribuição de frequências simples para se organizar e resumir tais variáveis, sendo apresentado no Exemplo 2.3.\n\n\nExemplo 2.3 Um Engenheiro Agrônomo examinou um lote de 150 caixas de banana maçã, escolhidos aleatoriamente num carregamento de 10.000 caixas, no CEAGESP de São Paulo, SP, anotando o número de pencas com empedramento. Os dados estão apresentados na Tabela 2.4.\n\n\n\nTabela 2.4: Número de pencas de banana maçã com empedramento (dados brutos).\n\n\n\n\n\n2\n3\n1\n1\n0\n0\n2\n2\n3\n5\n\n\n\n4\n0\n4\n0\n1\n1\n0\n6\n5\n0\n\n\n\n1\n1\n0\n4\n0\n0\n5\n0\n0\n2\n\n\n\n0\n4\n5\n0\n4\n0\n2\n1\n1\n1\n\n\n\n2\n0\n0\n1\n0\n4\n0\n5\n0\n0\n\n\n\n0\n5\n0\n4\n1\n0\n1\n0\n2\n1\n\n\n\n0\n1\n1\n0\n2\n5\n0\n2\n0\n0\n\n\n\n3\n5\n0\n1\n0\n0\n1\n4\n3\n3\n\n\n\n2\n0\n4\n0\n3\n4\n0\n0\n1\n1\n\n\n\n0\n2\n1\n3\n2\n1\n2\n3\n1\n0\n\n\n\n1\n5\n2\n2\n1\n2\n1\n1\n2\n3\n\n\n\n3\n2\n6\n1\n5\n3\n2\n1\n1\n1\n\n\n\n6\n2\n2\n4\n1\n4\n1\n6\n3\n4\n\n\n\n1\n4\n1\n3\n3\n1\n3\n2\n4\n1\n\n\n\n3\n1\n3\n2\n2\n3\n2\n3\n4\n3\n\n\n\n\n\n\n\nApós coletar os dados o Engenheiro Agrônomo ordenou os dados em ordem crescente, obtendo-se assim os dados elaborados apresentados na Tabela 2.5.\n\n\n\nTabela 2.5: Número de pencas de banana maçã com empedramento (dados elaborados).\n\n\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n4\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n0\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n2\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n5\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n0\n0\n1\n1\n1\n2\n3\n3\n4\n6\n\n\n\n\n\n\n\nOrdenado os dados o Engenheiro Agrônomo examinou as 150 caixas, e contou quantas caixas tinham nenhuma penca empedrada, quantas tinham uma penca empedrada, duas pencas empedradas e assim por diante, e organizou os dados com as respectivas frequências de ocorrência na Tabela 2.6.\n\n\n\nTabela 2.6: Número de pencas de banana maçã com empedramento, CEAGESP, São Paulo, SP, 2007.3\n\n\n\n\n\n\n\n\n\n\n\nNúmero de pencas empedradas\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\n0\n38\n0,2533\n25,33\n\n\n1\n37\n0,2467\n24,67\n\n\n2\n25\n0,1667\n16,67\n\n\n3\n20\n0,1333\n13,33\n\n\n4\n16\n0,1067\n10,67\n\n\n5\n10\n0,0667\n6,67\n\n\n6\n4\n0,0266\n2,66\n\n\nTotal\n150\n1,0000\n100,00\n\n\n\n\n\n\nObserva-se pelos resultados apresentados na Tabela 2.6 que: das \\(150\\) caixas de banana inspecionadas, apenas \\(38\\) caixas, ou seja, \\(25,33\\%\\), não tinham nenhuma penca empedrada, e que \\(10,67\\%\\) tinham \\(4\\) pencas empedradas. Estes resultados poderiam estar orientando o Engenheiro Agrônomo a direcionar suas ações, no sentido de melhorar a qualidade do produto.\n\n\nContínuas: Quando os dados de uma amostra ou população estiverem representados por variáveis quantitativas contínuas, é evidente que não existem classes naturais. Apesar disso pode-se usar o recurso de agrupar os dados em classes com um determinado número de intervalos. Tais classes terão dois valores limites, isto é, um limite inferior e um limite superior. Assim, utiliza-se de uma tabela de distribuição de frequências com dados agrupados em classes com intervalos de classes, para se organizar e resumir tais variáveis.\n\nNeste casso para a construção da tabela de distribuição de frequências devem ser seguidos os seguintes passos:\n\nDeterminar o número de classes \\((K)\\): A escolha do número de classes é arbitrária, e a experiência do pesquisador com os dados é que lhe indicará quantas classes devem ser usadas. No entanto deve ser observado que, com poucas classes perde-se informação, e com muitas classes o objetivo de se resumir um conjunto de dados pode ficar prejudicado. Pode-se, também, adotar o critério baseado no número de observações “\\(n\\)”, conforme Tabela 2.7.\n\n\n\n\nTabela 2.7: Determinação do número de classes (\\(K\\)).\n\n\n\n\n\nNúmero de observações \\((n)\\)\nNúmero de classes \\((K)\\)\n\n\n\n\n\nAté \\(100\\)\n\\(\\sqrt{n}\\) (inteiro mais próximo)\n\n\n\nAcima de \\(100\\)\n\\(5\\log_{10}(n)\\) (inteiro mais próximo)\n\n\n\n\n\n\n\n\nDeterminar a amplitude de classe \\((c)\\): A amplitude de classe é definida pela diferença entre os limites superior e inferior de uma determinada classe, dada por: \\[\nc=LS_{i} - LI_{i},\n\\] para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(K\\), sendo \\(K\\) o número de classes. Porém, em termos práticos a amplitude de classe é determinada da seguinte forma: \\[\nc=\\frac{A}{K-1},\n\\] em que:\n\n\\(A\\) é amplitude total, que representa a diferença entre a maior observação e a menor observação;\n\\(K\\) é o número de classes.\n\nDeterminar o limite inferior da primeira classe \\((LI_{1ª})\\), dado por:\n\n\\[\nLI_{1ª} = \\textrm{Menor dado} - \\frac{c}{2}.\n\\]\n\nDeterminar o limite superior da primeira classe (\\(LS_{1ª}\\)), dado por:\n\n\\[\nLS_{1ª} = LI_{1ª} + c.\n\\]\n\nOs demais limites de classe são obtidos somando-se o valor de \\(c\\) até completar as \\(K\\) classes.\nDeterminar os pontos médios das classes \\((\\tilde{X}_i)\\), dado por:\n\n\\[\n\\tilde{X}_i=\\frac{LI_{iª}+LS_{iª}}{2}.\n\\]\nPosteriormente, serão determinados as frequências: absoluta \\((F_i)\\), relativa \\((Fr_i)\\) e percentual \\((Fp_i)\\), de forma similar como foi desenvolvido na tabela de distribuição de frequência simples. Em geral usa-se as seguintes notações para os intervalos de classes:\n\n\\([a;b)\\) ou \\(a \\vdash b\\).\n\nNa contagem do número de dados contidos em um intervalo de uma determinada classe (frequência absoluta), deve-se incluir o valor do limite inferior \\((a)\\) e excluir o valor do limite superior \\((b)\\) de cada classe. O valor do limite superior passa a ser contado na classe posterior.\n\nExemplo 2.4 Um Zootecnista observou os pesos ao nascer, em kg, de uma amostra de 50 bezerros da raça nelore, provenientes da Fazenda de um grande criador. Os resultados estão apresentados na Tabela 2.8.\n\n\n\nTabela 2.8: Pesos ao nascer, em kg, de 50 bezerros da raça nelore (dados brutos).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n26,8\n24,3\n23,7\n31,0\n22,2\n25,2\n29,5\n24,2\n33,0\n27,2\n\n\n\n25,9\n23,0\n25,6\n26,5\n26,0\n22,8\n31,8\n21,0\n29,3\n27,8\n\n\n\n24,1\n26,9\n24,5\n26,2\n29,8\n21,6\n27,2\n26,8\n26,9\n25,0\n\n\n\n29,6\n31,3\n22,1\n26,1\n29,2\n25,3\n26,0\n27,2\n28,1\n26,2\n\n\n\n28,5\n27,2\n28,6\n25,8\n26,5\n28,1\n24,9\n30,5\n28,7\n24,5\n\n\n\n\n\n\n\nOs dados foram colocados em ordem crescente e estão apresentados na Tabela 2.9.\n\n\n\nTabela 2.9: Pesos ao nascer, em kg, de 50 bezerros da raça nelore (dados elaborados).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n21,0\n23,0\n24,5\n25,3\n26,0\n26,5\n27,2\n28,1\n29,2\n30,5\n\n\n21,6\n23,7\n24,5\n25,6\n26,1\n26,8\n27,2\n28,1\n29,3\n31,0\n\n\n22,1\n24,1\n24,9\n25,8\n26,2\n26,8\n27,2\n28,5\n29,5\n31,3\n\n\n22,2\n24,2\n25,0\n25,9\n26,2\n26,9\n27,2\n28,6\n29,6\n31,8\n\n\n22,8\n24,3\n25,2\n26,0\n26,5\n26,9\n27,8\n28,7\n29,8\n33,0\n\n\n\n\n\n\nPara a construção da Tabela de Distribuição de Frequências devem ser seguidos os passos descritos anteriormente, obtendo-se os seguintes resultados:\n\nNúmero de classes \\((K)\\): \\[\nK=\\sqrt{n}=\\sqrt{50}=7,0711 \\Rightarrow K=7~\\textrm{classes}.\n\\]\nAmplitude de classe \\((c)\\): \\[\\begin{align*}\nc &= \\frac{A}{K-1}\\\\\n  &=\\frac{\\textrm{Maior dado} - \\textrm{Menor dado}}{K-1}\\\\\n  &= \\frac{33,0-21,0}{7-1}\\\\\n  &=\\frac{12}{6}\\\\\n  &=2,0~\\textrm{kg}.\n\\end{align*}\\]\nLimite inferior da primeira classe (\\(LI_{1ª}\\)): \\[\\begin{align*}\nLI_{1ª} &= \\textrm{Menor dado}-\\frac{c}{2}\\\\\n     &= 21,0-\\frac{2,0}{2}\\\\\n     &=20,0~\\textrm{kg}.\n\\end{align*}\\]\nLimite superior da primeira classe (\\(LS_{1ª}\\)): \\[\\begin{align*}\nLS_{1ª} &= LI_{1ª}+c\\\\\n     &= 20,0+2,0 = 22,0~\\textrm{kg}.\n\\end{align*}\\]\nDemais limites:\n\nOs demais limites dos intervalos de classe são obtidos somando-se o valor de \\(c\\) até completar as \\(K\\) classes.\n\n1ª classe: \\(20,0\\) a \\(22,0\\) kg;  2ª classe: \\(22,0\\) a \\(24,0\\) kg;  3ª classe: \\(24,0\\) a \\(26,0\\) kg;  4ª classe: \\(26,0\\) a \\(28,0\\) kg;  5ª classe: \\(28,0\\) a \\(30,0\\) kg;  6ª classe: \\(30,0\\) a \\(32,0\\) kg;  7ª classe: \\(32,0\\) a \\(34,0\\) kg.\n\n\nTabela de distribuição de frequências:\n\nObtidos os intervalos de classes são contados o número de dados que estão contidos em cada intervalo, ou seja, a frequência absoluta \\((F_i)\\). São determinados também as frequências relativa \\((Fr_i)\\) e percentual \\((Fp_i)\\) de cada classe, e o ponto médio de classe \\((\\tilde{X}_i)\\).\nE assim, constrói-se a tabela de distribuição de frequências, conforme a Tabela Tabela 2.10.\n\n\n\nTabela 2.10: Pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.4\n\n\n\n\n\n\n\n\n\n\n\n\nPeso \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\n\\(\\left[20,0 \\right. ; \\left. 22,0\\right)\\)\n21,0\n2\n0,04\n4,0\n\n\n\\(\\left[22,0 \\right. ; \\left. 24,0\\right)\\)\n23,0\n5\n0,10\n10,0\n\n\n\\(\\left[24,0 \\right. ; \\left. 26,0\\right)\\)\n25,0\n12\n0,24\n24,0\n\n\n\\(\\left[ 26,0 \\right. ; \\left. 28,0\\right)\\)\n27,0\n16\n0,32\n32,0\n\n\n\\(\\left[28,0 \\right. ; \\left. 30,0\\right)\\)\n29,0\n10\n0,20\n20,0\n\n\n\\(\\left[30,0 \\right. ; \\left. 32,0\\right)\\)\n31,0\n4\n0,08\n8,0\n\n\n\\(\\left[32,0 \\right. ; \\left. 34,0\\right)\\)\n33,0\n1\n0,02\n2,0\n\n\nTotal\n\n50\n1,00\n100,0\n\n\n\n\n\n\nObtida a tabela de distribuição de frequências pode-se descrever o modelo de variação dos dados, através de uma análise superficial da distribuição dos dados. Observa-se, por exemplo, através da tabela acima que:\n\n76,0% dos bezerros da raça nelore têm pesos ao nascer entre 24,0 e 30,0 kg (24,0 + 32,0 + 20,0);\n14,0% estão abaixo de 24,0 kg (4,0 + 10,0);\n10,0% estão acima de 30,0 kg (8,0 + 2,0).\n\nAs frequências acumuladas para baixo e para cima estão apresentadas nas Tabelas 2.11 e 2.12, respectivamente.\n\n\n\nTabela 2.11: Frequências acumuladas para baixo dos pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.\n\n\n\n\n\nPeso \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{Fc\\downarrow}\\)\n\n\n\n\nMenores que 20,0\n0\n\n\nMenores que 22,0\n2\n\n\nMenores que 24,0\n7\n\n\nMenores que 26,0\n19\n\n\nMenores que 28,0\n35\n\n\nMenores que 30,0\n45\n\n\nMenores que 32,0\n49\n\n\nMenores que 34,0\n50\n\n\n\n\n\n\nPor exemplo, menores que \\(26,04\\) kg: \\(2 + 5 + 12 = 19\\).\n\n\n\nTabela 2.12: Frequências acumuladas para cima dos pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.\n\n\n\n\n\n \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{Fc\\uparrow}\\)\n\n\n\n\n20,0 ou mais\n50\n\n\n22,0 ou mais\n48\n\n\n24,0 ou mais\n43\n\n\n26,0 ou mais\n31\n\n\n28,0 ou mais\n15\n\n\n30,0 ou mais\n5\n\n\n32,0 ou mais\n1\n\n\n34,0 ou mais\n0\n\n\n\n\n\n\nPor exemplo, \\(28,0\\) kg ou mais: \\(10 + 4 + 1 = 15\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#repgraf",
    "href": "cap02.html#repgraf",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.3 Representação Gráfica",
    "text": "2.3 Representação Gráfica\nNum trabalho de descrição e apresentação de dados, os gráficos podem ser considerados como uma continuação das tabelas. A sua função é a de transmitir uma ideia visual do comportamento de um conjunto de dados. Para tal são utilizados diversos formatos gráficos de acordo com o problema a ser descrito, ou até mesmo de acordo com a preferência do apresentador. Os gráficos têm a vantagem de facilitar a compreensão do fenômeno em estudo que se queira descrever, permitindo a interpretação rápida das suas principais características.\n\n2.3.1 Variáveis Qualitativas\nNo caso de variáveis qualitativas, nominal ou ordinal, existem vários tipos de gráficos para descrevê-las, mas apresentaremos apenas dois tipos: gráficos em de setores (pizza).\n\nConsiderando o Exemplo 2.2, os gráficos de barras e de setores para os dados estão representados nas Figuras 2.1 e 2.2, respectivamente.\n\n\n\n\n\n\nFigura 2.1: Gráfico de barras para o nível de tecnificação adotado pelos produtores rurais, da região do Alto Rio Grande, sul de Minas Gerais, 2007.\n\n\n\n\n\n\n\n\n\nFigura 2.2: Gráfico de setores para o nível de tecnificação adotado pelos produtores rurais, da região do Alto Rio Grande, sul de Minas Gerais, 2007.\n\n\n\n\n\n\n2.3.2 Variáveis Quantitativas\nPara variáveis quantitativas, discretas ou contínuas, existem vários tipos de gráficos, mas abordaremos aqui os mais simples e utilizados.\n\n2.3.2.1 Discretas\nNo caso de variáveis quantitativas discretas pode-se utilizar o gráfico de barras para descrevê-las.\n\nExemplo 2.5 Considerando o Exemplo 2.3, o gráfico de barras para os dados está representado pela Figura 2.3.\n\n\n\n\n\n\nFigura 2.3: Gráfico de barras do número de pencas de banana maçã com empedramento, CEAGESP, São Paulo, SP, 2007.\n\n\n\n\n\n\n2.3.2.2 Contínuas\nNo caso de variáveis contínuas a tabela de distribuição de frequências pode ser representada graficamente através de:\n\nHistograma: Representa um gráfico formado por retângulos, cujas bases são proporcionais às amplitudes de classe, e as alturas proporcionais às frequências das classes. As frequências podem ser: absoluta \\((F_i)\\), relativa \\((Fr_i)\\) ou percentual \\((Fp_i)\\).\n\nCaracterísticas do histograma:\n\nA área de um histograma é proporcional à soma das frequências;\nAo empregar as frequências relativas, obtém-se um gráfico de área unitária;\nPara comparar duas distribuições de frequências, deve-se fazê-lo pelo histograma utilizando-se as frequências relativas ou percentuais.\n\n\nPolígono de Frequências:\n\nÉ um gráfico em linha. Para a construção do polígono de frequências, os pontos médios das classes nos topos do retângulos do histograma são unidos por linhas. O polígono começa e termina nos pontos médios das classes anterior à primeira e posterior à ultima, respectivamente.\n\nOgivas:\n\nÉ o polígono de frequências utilizando as frequências acumuladas para baixo ou para cima.\n\nExemplo 2.6 Para o Exemplo 2.4, tem-se o seguinte histograma e polígono de frequências para os dados, apresentados na Figura 2.4.\n\n\n\n\n\n\nFigura 2.4: Histograma e polígono de frequências da distribuição dos pesos ao nascer, em kg, de \\(50\\) bezerros da raça nelore, Fazenda XX, 2007.\n\n\n\nA Figura 2.5 apresenta o gráfico (ogivas) das frequências acumuladas para cima e para baixo.\n\n\n\n\n\n\nFigura 2.5: Representação gráfica das distribuições acumuladas (ogivas) dos pesos ao nascer, em kg, de \\(50\\) bezerros da raça nelore, Fazenda XX, 2007.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#clasdistdados",
    "href": "cap02.html#clasdistdados",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.4 Classificação da Distribuição dos Dados",
    "text": "2.4 Classificação da Distribuição dos Dados\nNo caso de variáveis quantitativas contínuas, a forma do polígono de frequências permite classificar a distribuição dos dados quanto a simetria em:\n\nSimétrica;\nAssimétrica à direita ou assimetria positiva;\nAssimétrica à esquerda ou assimetria negativa.\n\nPara tanto deve-se comparar a forma do Polígono de Frequências com as seguintes curvas, chamadas Curvas de Frequências, conforme Figura 2.6.\n\n\n\n\n\n\nFigura 2.6: Classificação da simetria da distribuição dos dados.\n\n\n\n\nExemplo 2.7 No Exemplo 2.6, segundo a forma do polígono de frequência, a distribuição é simétrica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#gramosfolhas",
    "href": "cap02.html#gramosfolhas",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.5 Gráfico de Ramo e Folhas",
    "text": "2.5 Gráfico de Ramo e Folhas\nFoi visto que a forma do polígono de frequências dá uma ideia da forma da distribuição da variável sob estudo. Um procedimento alternativo para resumir um conjunto de dados, com o objetivo de se obter uma ideia da forma de sua distribuição, é o gráfico de Ramo e Folhas. Uma vantagem deste diagrama é que não se perde, ou perde-se pouca informação sobre os dados em si.\nNa construção do gráfico de Ramo e Folhas a ideia básica é dividir cada observação em duas partes: a primeira, chamada de ramo, é colocada à esquerda de uma linha vertical, e a segunda, a folha, é colocada à direita. No gráfico de Ramo e Folhas observa-se que um ramo com muitas folhas significa maior incidência daquele ramo.\n\nExemplo 2.8 Considerando o Exemplo 2.4, tem-se o seguinte gráfico de Ramo e Folhas, conforme Figura 2.7.\n\n\n\n\n\n\nFigura 2.7: Pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.\n\n\n\nPor exemplo, para os pesos 21,0 e 21,6: o 21 é o ramo e o 0 e 6 são as folhas.\nAlgumas informações que se obtêm deste ramo-e-folhas são:\n\nOs valores estão concentrados entre 24,1 e 29,8;\nUm valor mais ou menos típico para este conjunto de dados poderia ser, por exemplo, 26,0;\nA distribuição dos dados é simétrica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#hiptabas",
    "href": "cap02.html#hiptabas",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "2.6 Hipótese Tabular Básica",
    "text": "2.6 Hipótese Tabular Básica\nNos cálculos estatísticos para dados de variáveis quantitativas contínuas, dispostas em uma tabela de distribuição de frequências com intervalos de classes, todos os dados contidos em uma determinada classe serão considerados iguais ao ponto médio da classe \\(\\tilde{X}_i\\). Uma vez agrupada as observações nas classes, perde-se a informação individual de cada dado. Dessa forma, como será visto mais adiante, que não é possível o cálculo de medidas descritivas, como por exemplo, a média ou quaisquer outros tipos de medidas que dependam dos dados individualmente. Assim, a teoria da Hipótese Tabular Básica afirma que, usar o ponto médio para representar as observações de cada classe, representa o menor erro possível do que substituí-los por qualquer outro valor específico.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#exprop",
    "href": "cap02.html#exprop",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 2.1 As distribuições das durações de alimentos em dois processos de conservação (A e B), em dias, estão representadas pelos histogramas, Figura 2.8.\n\n\n\n\n\n\nFigura 2.8: Histograma do tempo de duração de alimentos, em dias, em dois processos de conservação de alimentos.\n\n\n\n\nClassifique a distribuição dos dados dos dois processos de conservação de alimentos quanto à simetria.\nNo processo A qual a porcentagem de duração menor que 58 dias?\nNo processo B qual a proporção de duração de no mínimo 55 dias?\nNo processo A quantos duraram pelo menos 54 dias porém menos de 60 dias?\n\n\n\nExercício 2.2 Em um estudo referente as atividades predominantes em 20 propriedades de um município, observou-se as seguintes atividades:\n\n\n\nCafé\nFeijão\nCafé\nSoja\n\n\nCafé\nMilho\nFeijão\nMilho\n\n\nMilho\nMilho\nSoja\nSoja\n\n\nLeite\nLeite\nMilho\nCafé\n\n\n\n\nClassifique a variável;\nConstrua uma tabela de distribuição de frequências com as frequências: absoluta, relativa e percentual;\nFaça a representação gráfica por meio dos gráficos de colunas e de setores;\nQual a porcentagem de propriedades que cultivam predominantemente café em suas propriedades.\n\n\n\nExercício 2.3 Os dados a seguir referem-se a produção diária de leite, em litros, de 20 vacas da raça holandesa, de um rebanho pertencente ao Núcleo de Criadores de Gado Holandês do Sul de Minas Gerais.\n\n\n\n20,6\n16,2\n26,6\n22,2\n14,4\n\n\n18,4\n20,6\n23,4\n22,0\n15,8\n\n\n25,2\n21,8\n20,8\n19,2\n18,4\n\n\n14,2\n27,0\n21,4\n20,6\n16,2\n\n\n\n\nClassifique a variável;\nConstrua uma tabela de distribuição de frequências com as frequências: absoluta, relativa e percentual;\nConstrua o histograma e o polígono de frequências;\nObtenha as distribuições de frequência acumuladas para cima e para baixo;\nClassifique a distribuição quanto à simetria;\nConstrua o gráfico de Ramo e Folhas.\n\n\n\nExercício 2.4 Considere os dados da seguinte tabela de distribuição de frequências, apresentados na Tabela 2.13.\n\n\n\nTabela 2.13: Área, em ha, de 755 propriedades rurais de um município do Estado de Minas Gerais, 2007.5\n\n\n\n\n\nÁrea \\(\\mathbf{(ha)}\\)\n\\(\\mathbf{F_i}\\)\n\n\n\n\nAbaixo de 60,0\n386\n\n\n\\(\\left[60,0 \\right. ; \\left. 150,0 \\right)\\)\n237\n\n\n\\(\\left[150,0 \\right. ; \\left. 250,0 \\right)\\)\n62\n\n\n\\(\\left[250,0 \\right. ; \\left. 400,0 \\right)\\)\n43\n\n\n\\(\\left[400,0 \\right. ; \\left. 600,0 \\right)\\)\n18\n\n\n\\(\\left[600,0 \\right. ; \\left. 900,0 \\right)\\)\n7\n\n\n900,0 ou mais\n2\n\n\nTotal\n755\n\n\n\n\n\n\n\nQuantas propriedades têm área abaixo de 120 ha;\nQual a porcentagem de propriedades com área acima de 300 ha.\n\n\n\nExercício 2.5 Para estudar a produtividade de um canavial, demarcaram-se nele em vários pontos escolhidos ao acaso, 50 pequenas áreas de 100 \\(\\textrm{m}^2\\) cada, cuja produção foi pesada. Os resultados obtidos, em kg, estão apresentados na seguinte tabela de distribuição de frequências:\n\n\n\nTabela 2.14: Produção de cana-de-açúcar, em kg, por áreas de 100 \\(\\textrm{m}^2\\) de um canavial, Fazenda XX, 2007.6\n\n\n\n\n\n\n\n\n\n\n\n\nProdução \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\n\n\n\n\\(\\left[624,0 \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n0,02\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n10,0\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n13\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n7\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left.\\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n0,10\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left.\\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n3\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\\(\\left[\\rule{10mm}{.2pt} \\right. ; \\left. \\rule{10mm}{.2pt}\\right)\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n2,0\n\n\nTotal\n\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\\(\\rule{10mm}{.2pt}\\)\n\n\n\n\n\n\n\nComplete a tabela de distribuição de frequências considerando que a maior observação foi 954,0 kg;\nConstrua o histograma e o polígono de frequências e classifique a distribuição dos dados quanto à simetria;\nQual a porcentagem de áreas de 100 \\(\\textrm{m}^2\\) avaliadas produziram menos de 844,0 kg de cana-de-açúcar;\nQual a proporção de áreas de 100 \\(\\textrm{m}^2\\) avaliadas produziram no mínimo 800,0 kg de cana-de-açúcar;\nQuantas áreas de 100 \\(\\textrm{m}^2\\) avaliadas produziram pelo menos 712,0 kg, porém menos de 888,0 kg de cana-de-açúcar.\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#footnotes",
    "href": "cap02.html#footnotes",
    "title": "2  Coleta, Organização e Apresentação de Dados",
    "section": "",
    "text": "Também pode ser chamada de tabela de distribuição com dados agrupados sem intervalo de classes.↩︎\nFonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, Organização e Apresentação de Dados</span>"
    ]
  },
  {
    "objectID": "cap03.html",
    "href": "cap03.html",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "3.1 Introdução\nNo capítulo anterior vimos como organizar um conjunto de dados através de tabelas e gráficos, mas podemos ainda tirar mais informações importantes de um conjunto de dados através das medidas de posição. As medidas de posição, ou medidas de tendência central, são medidas representativas do valor central ao redor do qual se agrupam os dados, ou seja, procuram sintetizar um conjunto de dados em um único e informativo valor.\nA média, a mediana e a moda são as três medidas de posição mais utilizadas para descrever um conjunto de dados, sejam eles populacionais ou amostrais.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#media",
    "href": "cap03.html#media",
    "title": "3  Medidas de Posição",
    "section": "3.2 Média",
    "text": "3.2 Média\n\n3.2.1 Dados Não Agrupados\nA média de uma população ou amostra é dada pela soma de todos os dados da população ou amostra, dividida pelo número de dados que a compõem.\nNo caso dos dados provenientes de uma população, a média, denotada por \\(\\mu\\), é dada pela expressão (3.1).\n\\[\n\\mu=\\frac{\\sum_{i=1}^{N}x_i}{N}.\n\\tag{3.1}\\]\nE no caso dos dados provenientes de uma amostra, a média, denotada por \\(\\bar{x}\\), é dada pela expressão (3.2).\n\\[\n\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{n}x_i}{n}.\n\\tag{3.2}\\]\nA média funciona como um ponto de equilíbrio (de balanço), e é evidente que teremos dados acima e abaixo da média, mas todos os dados estarão na média, pois todos os dados fazem parte do cálculo da média.\nA unidade da média será a mesma unidade dos dados.\n\nExemplo 3.1 Considere os dados do Exemplo 2.4. Neste caso trata-se de uma amostra. Assim, utilizando-se da expressão (3.2) tem-se que a média amostral é dada por:\n\\[\\begin{align}\n\\bar{\\text{x}} & = \\frac{21,0+21,6+22,1+...+31,3+31,8+33,0}{50} \\Rightarrow \\bar{\\text{x}}=26,6~\\textrm{kg}.\n\\end{align}\\]\n\n\n\n3.2.2 Dados Agrupados\nSe os dados estiverem agrupados em uma tabela de distribuição de frequências com intervalos de classes, a média é dada pela expressão (3.3). \\[\n\\bar{\\text{x}}=\\frac{\\sum_{i=1}^{K}F_{i}\\tilde{X}_i}{\\sum_{i=1}^{K}F_i},\n\\tag{3.3}\\] em que: \\(\\tilde{X}_i\\) é o ponto médio da classe \\(i\\) e \\(F_i\\) é a frequência absoluta da classe \\(i\\).\n\nExemplo 3.2 Considere o Exemplo 2.4. Alternativamente pode-se acrescentar mais uma coluna na tabela de distribuição de frequências referente a: \\(F_{i}\\tilde{X}_i\\), que pode ser observado pela Tabela 3.1.\n\n\n\nTabela 3.1: Pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeso \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\\(\\mathbf{F_{i}\\tilde{X}_i}\\)\n\n\n\n\n\\(\\left[20,0;22,0\\right)\\)\n21,0\n2\n0,04\n4,0\n42,0\n\n\n\\(\\left[22,0;24,0\\right)\\)\n23,0\n5\n0,10\n10,0\n115,0\n\n\n\\(\\left[24,0;26,0\\right)\\)\n25,0\n12\n0,24\n24,0\n300,0\n\n\n\\(\\left[26,0;28,0\\right)\\)\n27,0\n16\n0,32\n32,0\n432,0\n\n\n\\(\\left[28,0;30,0\\right)\\)\n29,0\n10\n0,20\n20,0\n290,0\n\n\n\\(\\left[30,0;32,0\\right)\\)\n31,0\n4\n0,08\n8,0\n124,0\n\n\n\\(\\left[32,0;34,0\\right)\\)\n33,0\n1\n0,02\n2,0\n33,0\n\n\nTotal\n\n50\n1,00\n100,0\n1.336,0\n\n\n\n\n\n\nLogo, utilizando-se da expressão (3.3) tem-se que a média é dada por: \\[\n\\bar{\\text{x}}=\\frac{1.336,0}{50}=26,7~\\textrm{kg}.\n\\]\nObserva-se que a média para os dados não agrupados (26,6 kg) foi calculada usando os verdadeiros dados, e a média para os dados agrupados (26,7 kg) foi calculada usando os dados representados pelo ponto médio da classe \\((\\tilde{X}_i)\\). Como se observa, a média calculada com os dados agrupados foi diferente da média para os dados não agrupados. No cálculo com os dados agrupados existe um erro devido à perda de informação, porém, tal erro é mínimo e, portanto, desprezível, o que mostra a qualidade do algoritmo utilizado para agrupar os dados numa Tabela de Distribuição de Frequências.\nNeste caso o erro foi de: \\[\nErro = 26,7 – 26,6 = 0,1~\\textrm{kg}.\n\\]\n\n\n\n3.2.3 Propriedades\nA média apresenta as seguintes propriedades:\n\nA soma dos desvios \\((SD)\\) de cada dado em relação à sua média é nula: \\[\nSD=\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)=0,0.\n\\]\n\n\nExemplo 3.3 Seja uma amostra referente às alturas, em cm, de três plantas de uma variedade de milho, dada por: \\[\n182,0; 184,0; 189,0.\n\\]\nUtilizando-se da expressão 3.2 a média é dada por:\n\\[\n\\bar{\\text{x}}=\\frac{182,0+184,0+189,0}{3}=\\frac{555,0}{3}=185,0~\\textrm{cm}.\n\\]\nAssim, a soma dos desvios de cada dado em relação à média é dada por: \\[\\begin{align}\n  SD &= (182,0-185,0)+(184,0-185,0)+(189,0-185,0)\\\\\n     &= (-3,0)+(-1,0)+(4,0)=0,0.\n\\end{align}\\]\nQue é um valor nulo comparado a qualquer outro valor diferente da média.\n\n\nA média é o valor que torna mínimo a soma de quadrados dos desvios \\((SQD)\\):\n\n\\[\nSQD=\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^2.\n\\]\n\nExemplo 3.4 Considere o Exemplo 3.3, em que: \\(\\bar{x}=185,0\\) cm.\nAssim, tem-se que a soma de quadrados dos desvios \\((SQD)\\) é dada por: \\[\\begin{align*}\n  SQD &= (182,0-185,0)^2+(184,0-185,0)^2+(189,0-185,0)^2\\\\\n      &= (-3,0)^2+(-1,0)^2+(4,0)^2=9+1+16=26,0.\n\\end{align*}\\] Que é um valor mínimo comparado a qualquer outro valor diferente da média.\n\n\nSomando-se ou subtraindo-se um mesmo valor constante \\(k\\) a cada dado, a média fica acrescida ou subtraída deste valor:\n\n\\[\nx_i \\pm k \\Rightarrow \\bar{\\text{x}} \\pm k.\n\\]\n\nExemplo 3.5 Considere o Exemplo 3.3, em que: \\(\\bar{x}=185,0\\) cm.\nSomando-se \\(k = 3,0\\) cm a cada valor da amostra tem-se: \\[\n185,0; 187,0; 192,0.\n\\]\nUtilizando-se da expressão (3.2) a nova média é dada por:\n\\[\n\\bar{\\text{x}}=\\frac{185,0+187,0+192,0}{3}=\\frac{564,0}{3}=188,0~\\textrm{cm}.\n\\]\nOu seja, é a média anterior acrescida de \\(3,0\\) cm.\n\n\nMultiplicando-se ou dividindo-se cada dado por um mesmo valor constante \\(k\\), diferente de 0, a média fica multiplicada ou dividida por este valor:\n\n\\[\nx_{i}\\times k \\Rightarrow \\bar{\\text{x}} \\times k.\n\\]\n\\[\n\\frac{x_i}{k} \\Rightarrow \\frac{\\bar{\\text{x}}}{k}\n\\]\n\nExemplo 3.6 Considere o Exemplo 3.3, em que: \\(\\bar{\\text{x}}=185,0\\) cm. Multiplicando-se cada dado por \\(k = 2\\) tem-se:\n\\[\n364,0; 368,0; 378,0.\n\\]\nA nova média é dada por: \\[\n\\bar{\\text{x}}=\\frac{364,0+368,0+378,0}{3}=370,0~\\textrm{cm}.\n\\] O que corresponde a média anterior multiplicada por 2.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#mediana",
    "href": "cap03.html#mediana",
    "title": "3  Medidas de Posição",
    "section": "3.3 Mediana",
    "text": "3.3 Mediana\nA mediana é o valor central de um conjunto dados, isto é, divide os dados ordenados ascendente ou descendentemente em partes iguais, ou seja, 50,0% dos dados estão acima e 50,0% estão abaixo deste valor. A mediana tem a mesma unidade dos dados.\n\n3.3.1 Dados Não Agrupados\nNeste caso os dados precisam primeiro serem ordenados de forma crescente ou decrescente.\nA mediana no caso de uma amostra, sendo denotada por \\(md\\), é expressa da seguinte forma:\n\nSe \\(n\\) for par a mediana é dada pela expressão (3.4). \\[\nmd = \\frac{x_{\\left(\\frac{n}{2}\\right)}+x_{\\left(\\frac{n+2}{2}\\right)}}{2};\n\\tag{3.4}\\]\nSe \\(n\\) for impar a mediana é dada pela expressão (3.5). \\[\nmd=x_{\\left(\\frac{n+1}{2}\\right)}.\n\\tag{3.5}\\]\n\n\nExemplo 3.7 Considere uma amostra referente às alturas, em cm, de sete plantas de uma variedade de milho, dada por: \\[\n185,0; 182,0; 189,0; 182,0; 184,0; 188,0; 187,0.\n\\] Para o cálculo da mediana os dados foram ordenados de forma crescente: \\[\n182,0; 182,0; 184,0; 185,0; 187,0; 188,0; 189,0.\n\\] Neste caso \\(n\\) = 7 (ímpar). Utilizando-se da expressão (3.5) tem-se que a mediana é dada por: \\[\nmd=x_{\\left(\\frac{7+1}{2}\\right)}=x_{(4)},\n\\] ou seja, corresponde ao 4º dado. Logo, a mediana é igual a \\(185,0\\) cm.\n\n\nExemplo 3.8 Seja uma amostra referente aos pesos, em kg, de oito leitões da raça Large White, dada por: \\[\n38,2; 40,4; 38,5; 38,2; 37,4; 39,6; 40,1; 40,1.\n\\]\nPara o cálculo da mediana os dados foram ordenados de forma crescente: \\[\n37,4; 38,2; 38,2; 38,5; 39,6; 40,1; 40,1; 40,4\n\\]\nTem-se que \\(n\\) = 8 (par). Utilizando-se da expressão (3.4) tem-se que a mediana é dada por: \\[\nmd=\\frac{x_{\\left(\\frac{8}{2}\\right)}+x_{\\left(\\frac{8+2}{2}\\right)}}{2}=\\frac{x_{(4)}+x_{(5)}}{2},\n\\] ou seja, é a média entre o 4º e o 5º dado, dada por: \\[\nmd=\\frac{38,5+39,6}{2}=$39,05~\\textrm{kg}.\n\\]\n\n\nExemplo 3.9 Seja o Exemplo 2.4, e considerando os dados ordenados de forma crescente.\nNeste caso tem-se que \\(n\\) = 50 (par). Utilizando-se da expressão (3.4) tem-se que a mediana é dada por: \\[\nmd=\\frac{x_{\\left(\\frac{50}{2}\\right)}+x_{\\left(\\frac{50+2}{2}\\right)}}{2}=\\frac{x_{(25)}+x_{(26)}}{2},\n\\] ou seja, é a média entre o 25º e o 26º dado, dada por: \\[\nmd=\\frac{26,5+26,5}{2}=26,5~\\textrm{kg}.\n\\]\n\n\n\n3.3.2 Dados Agrupados\nSe os dados estiverem agrupados em uma Tabela de Distribuição de Frequências com intervalos de classes, a mediana é dada pela expressão (3.6),\n\\[\nmd=LI_{md}+\\left[\\frac{\\frac{n}{2}-F_{A}}{F_{md}}\\right]c_{md},\n\\tag{3.6}\\] em que:\n\n\\(LI_{md}\\) é o limite inferior da classe mediana;\n\\(F_A\\) é a frequência acumulada anterior à classe mediana;\n\\(F_{md}\\) é a frequência absoluta da classe mediana;\n\\(c_{md}\\) é a amplitude da classe mediana.\n\nA classe mediana é a classe que contém o dado: \\(x_{\\left(\\frac{n}{2}\\right)}\\) (se \\(n\\) for par), ou \\(x_{\\left(\\frac{n+1}{2}\\right)}\\) (se \\(n\\) for impar), na Tabela de Distribuição de Frequências.\n\nExemplo 3.10 Considere o Exemplo 2.4. A classe mediana é: \\[\nx_{\\left(\\frac{n}{2}\\right)}=x_{\\left(\\frac{50}{2}\\right)}=x_{(25)}=25º~\\textrm{valor}.\n\\]\nConta-se as freqüências absolutas até abranger o 25º valor. Neste caso tem-se: 2 + 5 + 12 + 16, ou seja, a 4ª classe, isto é, \\([26,0; 28,0)\\).\nAssim, tem-se que:\n\n\\(LI_{md}=26,0\\) kg;\n\\(F_A=2+5+12=19\\);\n\\(F_{md}=164\\) ;\n\\(c_{md}=2,0\\) kg.\n\nUtilizando-se da expressão (3.6) tem-se que a mediana é dada por:\n\\[\nmd=26,0+\\left[\\frac{\\frac{50}{2}-19}{16}\\right]2,0=26,75~\\textrm{kg}.\n\\] Tem-se que a diferença entre os dois valores (26,5 kg e 26,75 kg) se deve ao erro de agrupamento.\n\n\n\n3.3.3 Propriedades\nA mediana apresenta as seguintes propriedades:\n\n\\(\\sum_{i=1}^{n}|x_i-md|\\) é um valor mínimo se comparado com qualquer outra expressão da forma: \\(\\sum_{i=1}^{n}|x_i-k|\\) (sendo \\(k\\) um valor qualquer);\nSomando-se ou subtraindo-se um mesmo valor constante à cada dado, a mediana fica acrescida ou subtraída deste valor;\nMultiplicando-se ou dividindo-se cada dado por uma mesmo valor constante, diferente de 0, a mediana fica multiplicada ou dividida por este valor.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#moda",
    "href": "cap03.html#moda",
    "title": "3  Medidas de Posição",
    "section": "3.4 Moda",
    "text": "3.4 Moda\nA moda de um conjunto de dados é o valor mais frequente, sendo denotada por \\(mo\\). Um conjunto de dados pode ter mais de uma moda, ou também, pode não ter moda. A moda tem a mesma unidade dos dados.\n\n3.4.1 Dados Não Agrupados\nDeve-se primeiro ordenar os dados de forma crescente ou decrescente, e em seguida contar o valor que ocorre mais vezes no conjunto de dados, ou seja, o valor mais frequente.\n\nExemplo 3.11 Considere uma amostra referente às alturas, em cm, de sete plantas de uma variedade de milho, dada por: \\[\n185,0; 182,0; 189,0; 182,0; 184,0; 188,0; 187,0.\n\\]\nPara o cálculo da moda os dados foram ordenados de forma crescente: \\[\n182,0; 182,0; 184,0; 185,0; 187,0; 188,0; 189,0,\n\\] então, \\[\nmo=182,0~\\textrm{cm (conjunto unimodal)}.\n\\]\n\n\nExemplo 3.12 Seja uma amostra referente aos pesos, em kg, de oito leitões da raça Large White, dada por: \\[\n38,2; 40,4; 38,5; 38,2; 37,4; 39,6; 40,1; 40,1.\n\\]\nPara o cálculo da moda os dados foram ordenados de forma crescente: \\[\n37,4; 38,2; 38,2; 38,5; 39,6; 40,1; 40,1; 40,4.\n\\] Portanto, \\[\nmo=38,2\\textrm{e}~40,1~\\textrm{kg (conjunto bimodal)}.\n\\]\n\n\nExemplo 3.13 Seja uma amostra de cinco vacas leiteiras da raça holandesa, referentes a produção diária de leite, em kg,dada por: \\[\n19,8; 18,2; 20,1; 20,9; 19,5.\n\\] Para o cálculo da moda os dados foram ordenados de forma crescente: \\[\n18,2; 19,5; 19,8; 20,1; 20,9.\n\\] Neste caso a moda não existe (conjunto amodal).\n\n\nExemplo 3.14 Considere o Exemplo 2.4, e considerando os dados ordenados de forma crescente, tem-se que a moda é dada por: \\[\nmo = 27,2~\\textrm{kg}.\n\\]\n\n\nExemplo 3.15 Quando os dados estiverem agrupados em uma Tabela de Distribuição de Frequências com intervalos de classes, a moda se localiza na classe de maior frequência (classe modal), e é dada pela expressão (3.7), \\[\nmo=LI_{mo}+\\left(\\frac{\\Delta_1}{\\Delta_1+\\Delta_2}\\right) c_{mo},\n\\tag{3.7}\\] em que:\n\n\\(LI_{mo}\\) é o limite inferior da classe modal;\n\\(\\Delta_1\\) é a diferença entre a freqüência absoluta da classe modal e a classe anterior;\n\\(\\Delta_2\\) é a diferença entre a freqüência absoluta da classe modal e a classe posterior;\n\\(c_{mo}\\) é a amplitude da classe modal.\n\n\n\nExemplo 3.16 Considerando o Exemplo 2.4, para o cálculo da moda tem-se:\n\nClasse Modal: [26,0 ; 28,0);\n\\(LI_{mo}= 26,0\\) kg;\n\\(\\Delta_1\\)=16-12=4;\n\\(\\Delta_2\\)=16-10=6;\n\\(c_{mo}=2,0\\) kg.\n\nUtilizando-se da expressão (3.7) tem-se que a moda é dada por: \\[\nmo=26,0+\\left(\\frac{4}{4+6}\\right) 2,0=26,8~\\textrm{kg}.\n\\]\nA diferença entre os dois valores (\\(27,2\\) kg e \\(26,8\\) kg) se deve ao erro de agrupamento.\n\n\n\n3.4.2 Propriedades\nA moda apresenta as seguintes propriedades:\n\nSomando-se ou subtraindo-se uma mesmo valor constante a cada dado, a moda fica acrescida ou subtraída deste valor;\nMultiplicando-se ou dividindo-se cada dado por uma mesmo valor constante, diferente de 0, a moda fica multiplicada ou dividida por este valor.\n\nA média, a mediana e a moda apresentam as seguintes vantagens e desvantagens.\n\nVantagens:\n\nMédia: tratável matematicamente;\nMediana: não é influenciada por valores extremos;\nModa: não é influenciada por valores extremos.\n\nDesvantagens:\n\nMédia: é influenciada por valores extremos;\nMediana: não é matematicamente tratável;\nModa: não é matematicamente tratável.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#medpos_natdist",
    "href": "cap03.html#medpos_natdist",
    "title": "3  Medidas de Posição",
    "section": "3.5 Medidas de Posição e Natureza da Distribuição",
    "text": "3.5 Medidas de Posição e Natureza da Distribuição\nA exemplo do polígono de frequências, a determinação das medidas de posição também permite discutir sobre a simetria da distribuição dos dados. E assim, conforme a Figura 3.1, pode-se observar a relação das medidas de posição com a natureza da distribuição.\n\n\n\n\n\n\nFigura 3.1: Classificação da simetria dos dados baseados nas medidas de posição.\n\n\n\n\nExemplo 3.17 No Exemplo 2.4 tem-se:\n\n\\(\\bar{x}=26,70\\) kg;\n\\(md=26,75\\) kg;\n\\(mo=26,80\\) kg.\n\nLogo, a distribuição é simétrica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#quantis",
    "href": "cap03.html#quantis",
    "title": "3  Medidas de Posição",
    "section": "3.6 Quantis",
    "text": "3.6 Quantis\nDe um modo geral, pode-se definir uma medida, chamada quantil de ordem \\(p\\) ou \\(p-quantil\\), representada por \\(q(p)\\), sendo \\(p\\) uma proporção \\((0,0 &lt; p &lt; 1,0)\\), de tal forma que 100\\(p\\)% dos dados são menores do que \\(q(p)\\).\nOs quantis mais empregados são:\n\nQuartis: Dividem os dados ordenados em ordem crescente em quatro partes iguais, sendo que: 25% dos dados serão inferiores ao primeiro quartil, 50% inferiores ao segundo quartil, que é a mediana, e 75% dos dados serão inferiores e 25% superiores ao terceiro quartil.\nDecis: Dividem os dados ordenados em ordem crescente em dez partes iguais.\nPercentis: Dividem os dados ordenados em ordem crescente em cem partes iguais.\n\n\nExemplo 3.18  \n\n\\(q(0,25): 1º\\) Quartil = \\(25º\\) Percentil;\n\\(q(0,50): 2º\\) Quartil = Mediana = \\(5º\\) Decil = \\(50º\\) Percentil;\n\\(q(0,75): 3º\\) Quartil = \\(75º\\) Percentil;\n\\(q(0,40): 4º\\) Decil;\n\\(q(0,95): 95º\\) Percentil.\n\n\nSegundo Bussab e Morettin (2010), o quantil de ordem \\(p\\) é definido pela expressão 3.8.\n\\[\n    q(p)=\\begin{cases}\n        x_{(i)} & \\textrm{se } p = p_i, i=1,2,\\ldots,n\\\\\n        (1-f_i)q(p_i)+f_iq(p_{i+1}) & \\textrm{se  } p_i&lt;p&lt;p_{i+1};\\\\\n        x_1 & \\textrm{se } p&lt;p_1;\\\\\n        X_n & \\textrm{se } p&gt;p_n,\n    \\end{cases}\n\\tag{3.8}\\] em que:\n\n\\(p_{i}=\\frac{i-0,5}{n}\\);\n\\(f_i=\\frac{p-p_i}{p_{i+1}-p_i}\\).\n\n\nExemplo 3.19 Considere o Exemplo 2.4, e usando a expressão 3.8. podem-se calcular, por exemplo, os seguintes quantis:\n\n\\(q(0,1)\\);\n\\(q(0,2)\\);\n\\(q(0,5)\\);\n\\(q(0,75)\\).\n\nAssumindo: \\[\np_{i}=\\frac{i-0,5}{n},\n\\] então segue que:\n\n\\(p_1=\\frac{1-0,5}{50}=0,01\\);\n\\(p_2=\\frac{2-0,5}{50}=0,03\\);\n\\(p_3=\\frac{3-0,5}{50}=0,05\\);\n\\(p_4=\\frac{4-0,5}{50}=0,07\\);\n\\(p_5=\\frac{5-0,5}{50}=0,09\\);\n\\(p_6=\\frac{6-0,5}{50}=0,11\\);\n\\(p_7=\\frac{7-0,5}{50}=0,13\\);\n\\(p_8=\\frac{8-0,5}{50}=0,15\\);\n\\(p_9=\\frac{9-0,5}{50}=0,17\\);\n\\(p_{10}=\\frac{10-0,5}{50}=0,19\\);\n\\(p_{11}=\\frac{11-0,5}{50}=0,21\\);\n\\(p_{12}=\\frac{12-0,5}{50}=0,23\\);\n\\(p_{13}=\\frac{13-0,5}{50}=0,25\\);\n\\(\\qquad\\vdots\\)\n\\(p_{25}=\\frac{25-0,5}{50}=0,49\\);\n\\(p_{26}=\\frac{26-0,5}{50}=0,51\\);\n\\(\\qquad\\vdots\\)\n\\(p_{37}=\\frac{37-0,5}{50}=0,73\\);\n\\(p_{38}=\\frac{38-0,5}{50}=0,75\\);\n\\(p_{39}=\\frac{39-0,5}{50}=0,77\\);\n\\(\\qquad\\vdots\\)\n\\(p_{49}=\\frac{49-0,5}{50}=0,97\\);\n\\(p_{50}=\\frac{50-0,5}{50}=0,99\\).\n\n\n\\(q(0,1)=?\\) \\[\np_5&lt;0,1&lt;p_6 \\Rightarrow 0,09&lt;0,1&lt;0,11.\n\\] \\[\nf_i=\\frac{(p-p_i)}{(p_{i+1})-(p_i)}=\\frac{0,1-0,09}{0,11-0,09}=0,5.\n\\]\n\n\\[\nq(p)=(1-f_i)q(p_i)+f_{i}q(p_{i+1}).\n\\]\n\\[\nq(0,1)=(1 – 0,5)q(p_5)+0,5q(p_6)=0,5(22,8) + 0,5(23,0)=$ 22,9~\\textrm{kg}.\n\\]\n\n\\(q(0,2)=?\\)\n\n\\[\np_{10}&lt;0,2&lt;p_{11} \\Rightarrow 0,19&lt;0,2&lt;0,21.\n\\]\n\\[\nf_i=\\frac{(p-p_i)}{(p_{i+1})-(p_i)}=\\frac{0,2-0,19}{0,21-0,19}=0,5.\n\\]\n\\[\nq(p)=(1-f_i)q(p_i)+f_{i}q(p_{i+1}).\n\\]\n\\[\nq(0,2)=(1 – 0,5)q(p_{10})+0,5q(p_{11})=0,5(24,3) + 0,5(24,5)= 24,4~\\textrm{kg}.\n\\]\n\n\\(q(0,5)=?\\)\n\n\\[\np_{25}&lt;0,5&lt;p_{26} \\Rightarrow 0,49&lt;0,5&lt;0,51.\n\\]\n\\[\nf_i=\\frac{(p-p_i)}{(p_{i+1})-(p_i)}=\\frac{0,5-0,49}{0,51-0,14}=0,5.\n\\]\n\\[\nq(p)=(1-f_i)q(p_i)+f_{i}q(p_{i+1}).\n\\]\n\\[\nq(0,5)=(1 – 0,5)q(p_{25})+0,5q(p_{26})=0,5(26,3) + 0,5(26,5)= 26,5~\\textrm{kg}.\n\\]\n\n\\(q(0,75)=?\\)\n\n\\[\nq(0,75)=q(p_{38})=x_{38}=28,5~\\textrm{kg}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#esq5num",
    "href": "cap03.html#esq5num",
    "title": "3  Medidas de Posição",
    "section": "3.7 Esquema dos Cinco Números",
    "text": "3.7 Esquema dos Cinco Números\nO esquema dos cinco números são utilizados para se ter uma idéia da simetria da distribuição dos dados. A idéia é obter os cinco valores:\n\n\\(x_1 \\Rightarrow\\) menor valor;\n\\(q_1 \\Rightarrow q(0,25)\\);\n\\(q_2 \\Rightarrow q(0,50)\\);\n\\(q_3 \\Rightarrow q(0,75)\\);\n\\(x_n \\Rightarrow\\) maior valor.\n\nPara uma distribuição simétrica, ou aproximadamente simétrica, deve-se ter:\n\n\\(q_2-x_1 \\cong x_n - q_2\\);\n\\(q_2 - q_1 \\cong q_3 - q_2\\);\n\\(q_1 - x_1 \\cong x_n - q_3\\);\ndistâncias entre a mediana e \\(q_1\\), \\(q_3\\) menores do que distâncias entre os extremos e \\(q_1\\) e \\(q_3\\).\n\n\nExemplo 3.20 No exm-cont tem-se que:\n\n\\(x_1=21,0\\) kg;\n\\(q_1=q(0,25)=24,9\\) kg;\n\\(q_2=q(0,50)=26,5\\) kg;\n\\(q_3=q(0,75)=28,5\\) kg;\n\n\\(x_n=33,0\\) kg.\n\nPelos resultados conclui-se que a distribuição é aproximadamente simétrica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#exprop",
    "href": "cap03.html#exprop",
    "title": "3  Medidas de Posição",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 3.1 Um Engenheiro Agrônomo interessado em estudar a produtividade de um canavial, demarcou nele em vários pontos escolhidos ao acaso, 10 pequenas áreas de 100 \\(\\textrm{m}^2\\) cada, cuja produção foi pesada. Os resultados obtidos, em kg, foram os seguintes: \\[\n650,0;  850,0;  710,0;  920,0;  780,0;  820,0;  900,0;  780,0;  740,0;  950,0.\n\\]\nCalcule a média, a mediana e a moda, da produção de cana-de-açúcar por área de 100 \\(\\textrm{m}^2\\).\n\n\nExercício 3.2 Em relação ao estudo do problema anterior o Engenheiro Agrônomo achou que a variabilidade dos dados era muito grande, e que apenas 10 áreas de 100 \\(\\textrm{m}^2\\) não representaram bem a produtividade do canavial. Assim ele avaliou no lugar de 10 uma amostra de 50 áreas de 100 \\(\\textrm{m}^2\\), seguindo a mesma metodologia explicada no problema anterior. Os resultados obtidos, em kg, são apresentados na Tabela 3.2.\n\n\n\n\nTabela 3.2: Produção de cana-de-açúcar, em kg, por áreas de 100 \\(\\textrm{m}^2\\), Fazenda XX, 20072.\n\n\n\n\n\n\n\n\n\n\nProdução \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\n\n\n\n\\(\\left[624,0  \\right. ;\\left. 668,0  \\right)\\)\n646,0\n1\n\n\n\\(\\left[668,0  \\right. ;\\left. 712,0  \\right)\\)\n690,0\n5\n\n\n\\(\\left[712,0  \\right. ;\\left. 756,0  \\right)\\)\n734,0\n15\n\n\n\\(\\left[756,0 \\right. ;\\left. 800,0 \\right)\\)\n778,0\n13\n\n\n\\(\\left[800,0  \\right. ;\\left. 844,0  \\right)\\)\n822,0\n7\n\n\n\\(\\left[844,0  \\right. ;\\left. 888,0  \\right)\\)\n866,0\n5\n\n\n\\(\\left[888,0  \\right. ;\\left. 932,0  \\right)\\)\n910,0\n3\n\n\n\\(\\left[932,0  \\right. ;\\left. 976,0  \\right)\\)\n954,0\n1\n\n\nTotal\n\n50\n\n\n\n\n\n\n\nCalcule a média, a mediana e a moda da produção de cana-de-açúcar por área de 100 \\(\\textrm{m}^2\\);\nApós registrada a produção de cada uma das 50 áreas de 100 \\(\\textrm{m}^2\\), o Engenheiro Agrônomo descobriu um erro sistemático na pesagem da cana-de-açúcar. Para obter a pesagem certa ele determinou que em cada um dos 50 dados obtidos deveria ser acrescido 6,0 kg, e depois o resultado deveria ser multiplicado por 0,9. Qual o valor correto da média, da mediana e da moda?\n\n\n\nExercício 3.3 Os pesos, em kg, de 6 novilhos nelore foram os seguintes: \\[\n184,0;  193,0;  198,0;  204,0;  196,0;  207,0.\n\\]\n\nCalcule a média dos pesos;\nQual foi o desvio do \\(2º\\) animal em relação à média. Explique o que ele significa;\n\nMostre que a soma dos desvios em relação à média é nula;\nTransforme os dados para arrobas. Calcule a média em arrobas partindo daquela obtida em (a);\nAdicione 20,0 kg em cada dado e encontre a média. Confronte o resultado com o obtido em (a). Qual a propriedade envolvida;\nCalcule a soma de quadrados dos desvios em relação à média e a 196,0. Discuta os resultados e tire conclusões.\n\n\n\nExercício 3.4 Um agricultor da região Sul de Goiás plantou três lavouras de milho, utilizando sementes de três diferentes empresas produtoras de sementes. Por amostragem ele avaliou a produtividade, em t/ha, de cada uma delas, no ano de 2006, obtendo os seguintes resultados:\n\n\n\n\n\n\n\n\nEmpresa\nÁrea plantada \\(\\mathbf{(ha)}\\)\nProdutividade \\(\\mathbf{(t/ha)}\\)\n\n\n\n\n1\n200,0\n5,6\n\n\n12\n600,0\n5,9\n\n\n3\n1.000,0\n6,5\n\n\n\nO agricultor solicitou a um Engenheiro Agrônomo que trabalha na região, para calcular a produtividade média de milho de sua propriedade. Após análise dos dados, o Engenheiro respondeu ao agricultor que sua produtividade média de milho foi de 6,0 t/ha. Você concorda ou não com a afirmativa do Engenheiro Agrônomo?\n\n\nExercício 3.5 Os ganhos de peso, em kg, de 60 novilhos da raça guzerá, mantidos numa pastagem em determinado período foram os seguintes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n36,0\n45,0\n60,0\n39,0\n57,0\n32,0\n39,0\n40,0\n63,0\n37,0\n\n\n42,0\n42,0\n44,0\n30,0\n47,0\n39,0\n15,0\n39,0\n25,0\n39,0\n\n\n57,0\n48,0\n44,0\n37,0\n44,0\n38,0\n21,0\n56,0\n52,0\n50,0\n\n\n31,0\n34,0\n36,0\n38,0\n43,0\n24,0\n38,0\n41,0\n46,0\n42,0\n\n\n28,0\n31,0\n32,0\n49,0\n39,0\n19,0\n49,0\n39,0\n42,0\n43,0\n\n\n20,0\n58,0\n34,0\n56,0\n35,0\n50,0\n27,0\n36,0\n40,0\n37,0\n\n\n\n\nCalcule a média, a mediana e a moda do ganho de peso, em kg;\nCalcule os seguintes quantis:\n\n\\(q(0,10)\\);\n\\(q(0,20)\\);\n\\(q(0,25)\\);\n\\(q(0,50)\\);\n\\(q(0,75)\\);\n\\(q(0,80)\\).\n\nDetermine o esquema dos cinco números e discuta sobre a simetria da distribuição dos dados.\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nBUSSAB, W. O.; MORETTIN, P. A. Estatística Básica. 6. ed. São Paulo: Saraiva, 2010. p. 526\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#footnotes",
    "href": "cap03.html#footnotes",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "Fonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap04.html",
    "href": "cap04.html",
    "title": "4  Medidas de Dispersão",
    "section": "",
    "text": "4.1 Introdução\nO resumo de um conjunto de dados através de uma medida de posição, como por exemplo, a média, não revela toda a informação sobre a dispersão desse conjunto de dados. Por exemplo, considere o Exemplo 4.1.\nAs medidas de posição são de tendência central e não informam sobre a variabilidade dos dados. Assim, faz-se necessário a utilização de uma medida que sumarizem a variabilidade de um conjunto de dados, e que permita, por exemplo, comparar diferentes conjuntos de dados baseando-se em algum critério.\nAs medidas de dispersão, também conhecida como medidas de variabilidade, são medidas que indicam o grau de afastamento de um conjunto de dados ao redor de um valor central, e são necessárias para junto com a média, representar bem um conjunto de dados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#introd",
    "href": "cap04.html#introd",
    "title": "4  Medidas de Dispersão",
    "section": "",
    "text": "Exemplo 4.1 Sejam três amostras referentes às alturas, em cm, de três variedades de milho, dadas por:\n\nVariedade A: 185,0; 185,0; 185,0;\nVariedade B: 182,0; 184,0; 189,0;\nVariedade C: 176,0; 180,0; 199,0.\n\nUtilizando-se da expressão (3.6) tem-se que a média para as três variedades são dadas por:\n\nVariedade A:\n\n\\[\n\\bar{\\text{x}}=\\frac{185,0+185,0+185,0}{3}=185,0~\\textrm{cm}.\n\\]\n\nVariedade B:\n\n\\[\n\\bar{\\text{x}}=\\frac{182,0+184,0+189,0}{3}=185,0~\\textrm{cm}.\n\\]\n\nVariedade C: \\[\n\\bar{\\text{x}}=\\frac{176,0+180,0+199,0}{3}=185,0~\\textrm{cm}.\n\\]\n\nBaseando-se apenas na média as três variedades são consideradas como de mesma altura.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#amptotal",
    "href": "cap04.html#amptotal",
    "title": "4  Medidas de Dispersão",
    "section": "4.2 Amplitude Total",
    "text": "4.2 Amplitude Total\nUma das formas mais simples de se medir a dispersão (variabilidade) de um conjunto de dados, é através da amplitude total. Define-se amplitude total como sendo a diferença entre o maior e o menor valor observado de um conjunto de dados dada pela expressão (4.1). \\[\nA=\\textrm{Maior dado} - \\textrm{Menor dado}.\n\\tag{4.1}\\]\nPara dados agrupados em uma tabela de distribuição de frequências com intervalos de classes, a amplitude total é a diferença entre os pontos médios da última \\((\\tilde{X}_K)\\) e da primeira classe \\((\\tilde{X}_1)\\), dada pela expressão (4.2). \\[\nA=\\tilde{X}_{K}-\\tilde{X}_{1}.\n\\tag{4.2}\\]\n\nExemplo 4.2 Para o Exemplo 4.1 e utilizando-se da expressão (4.1) tem-se:\n\nVariedade A:\n\n\\[\nA=185,0-185,0=0,0~cm.\n\\]\n\nVariedade B:\n\n\\[\nA=189,0-182,0=7,0~\\textrm{cm}.\n\\]\n\nVariedade C:\n\n\\[\nA=199,0-176,0=23,0~\\textrm{cm}.\n\\]\n\n\nExemplo 4.3 Considerando o Exemplo 2.4 e utilizando-se da expressão (4.1) tem-se:\n\\[\nA=33,0-21,0=12,0~\\textrm{kg}.\n\\]\n\nApesar de ser uma medida fácil de ser calculada, a amplitude total não é muito usada para expressar a variabilidade de um conjunto de dados, pois baseia-se em apenas em dois dados, não considerando a totalidade dos dados do conjunto. Assim, faz-se necessário a apresentação de outras medidas que possam expressar a variabilidade de um conjunto de dados, que reflitam as diferenças de todos os dados do conjunto.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#vardp",
    "href": "cap04.html#vardp",
    "title": "4  Medidas de Dispersão",
    "section": "4.3 Variância e Desvio Padrão",
    "text": "4.3 Variância e Desvio Padrão\nOutra medida de dispersão amplamente usada para medir a variabilidade de um conjunto de dados é a variância. A variância mede a dispersão de um conjunto de dados em relação à sua média, e indica, o quanto em média, os dados se desviam em relação à média.\nA variância permite, também, comparar a variabilidade entre conjuntos de dados que possuam a mesma média e a mesma unidade. Quanto menor for a variância, menos variável é o conjunto de dados.\n\n4.3.1 Dados Não Agrupados\nNo caso de uma população, a variância é definida pela razão entre a soma de quadrados dos desvios de cada dado em relação à sua média, e o número total de dados, dada pela expressão (4.3). \\[\n\\begin{align}\n     \\sigma^2=\\frac{\\sum_{i=1}^{N}\\left(x_i-\\mu\\right)^2}{N}.\n\\end{align}\n\\tag{4.3}\\] E no caso de uma amostra, a variância é dada pela expressão (4.4). \\[\n\\begin{align}\n    s^2=\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^2}{n-1}.\n\\end{align}\n\\tag{4.4}\\]\nDesenvolvendo a soma de quadrados de (4.4), pode-se reescrever \\(s^2\\) através da expressão (4.5). \\[\n\\begin{align}\n    s^2=\\frac{\\sum_{i=1}^{n}x_i^2-\\frac{\\left(\\sum_{i=1}^{n}x_i\\right)^2}{n}}{n-1}.\n\\end{align}\n\\tag{4.5}\\]\nA variância é expressa na unidade dos dados ao quadrado .\n\nExemplo 4.4 Considerando o Exemplo 4.1 e utilizando-se da expressão (4.4), tem-se:\n\nVariedade A: \\[\\begin{align*}\ns^2 & = \\frac{\\left(185,0-185,0\\right)^2+\\left(185,0-185,0\\right)^2+\\left(185,0-185,0\\right)^2}{3-1}\\\\\n& = \\frac{\\left(0,0\\right)^2+\\left(0,0\\right)^2+\\left(0,0\\right)^2}{2}\\\\\n& = 0,0~\\textrm{cm}^2.\n\\end{align*}\\]\n\nQue também pode ser calculada por (4.5): \\[\\begin{align*}\n  s^2 & =\\frac{185,0^2+185,0^2+185,0^2-\\frac{\\left(185,0+185,0+185,0\\right)^2}{3}}{3-1}\\\\\n  & = \\frac{102.675,0-102.675,0}{2}\\\\\n  & = 0,0~\\textrm{cm}^2.\n\\end{align*}\\]\n\nVariedade B: \\[\\begin{align*}\ns^2 & = \\frac{\\left(182,0-185,0\\right)^2+\\left(184,0-185,0\\right)^2+\\left(189,0-185,0\\right)^2}{3-1}\\\\\n& = \\frac{\\left(-3,0\\right)^2+\\left(-1,0\\right)^2+\\left(4,0\\right)^2}{2}\\\\\n& = 13,0~\\textrm{cm}^2.\n\\end{align*}\\] Que também pode ser calculada por (4.5): \\[\\begin{align*}\ns^2 & = \\frac{182,0^2+184,0^2+189,0^2-\\frac{\\left(182,0+184,0+189,0\\right)^2}{3}}{3-1}\\\\\n& = \\frac{102.701,0-102.675,0}{2}\\\\\n& = 13,0~\\textrm{cm}^2.\n\\end{align*}\\]\nVariedade C: \\[\\begin{align*}\ns^2 & = \\frac{\\left(176,0-185,0\\right)^2+\\left(180,0-185,0\\right)^2+\\left(199,0-185,0\\right)^2}{3-1}\\\\\n& = \\frac{\\left(-9,0\\right)^2+\\left(-5,0\\right)^2+\\left(14,0\\right)^2}{2}\\\\\n& = 151,0~\\textrm{cm}^2.\n\\end{align*}\\] Que também pode ser calculada por (4.5): \\[\\begin{align*}\ns^2 & = \\frac{176,0^2+180,0^2+199,0^2-\\frac{\\left(176,0+180,0+199,0\\right)^2}{3}}{3-1}\\\\\n& = \\frac{102.977,0-102.675,0}{2}\\\\\n& = 151,0~\\textrm{cm}^2.\n\\end{align*}\\]\n\nObserva-se que a variedade C tem variância maior que as variedades A e B, indicando que seus dados dispersam mais em torno da média.\n\n\nExemplo 4.5 Considerando os dados do Exemplo 2.4 e utilizando-se da expressão (4.5), tem-se: \\[\\begin{align*}\n  s^2 & = \\frac{21,0^2+21,6^2+\\cdots+31,8^2+33,0^2-\\frac{\\left(21,0+21,6+\\cdots+31,8+33,0\\right)^2}{50}}{50-1}\\\\\n  & = \\frac{35.745,1-\\frac{\\left(1.330,2\\right)^2}{50}}{49}\\\\\n  & = 7,2747~\\textrm{kg}^2.\n\\end{align*}\\]\n\nSendo a variância uma medida expressa na unidade dos dados ao quadrado, isto pode trazer problemas do ponto de vista de interpretação. Logo, faz-se necessário o uso de uma outra medida que retorne os dados para sua unidade original. Assim, tem-se o desvio padrão que é a raiz quadrada positiva da variância.\nNo caso de uma população, o desvio padrão é dado por (4.6). \\[\n\\begin{align}\n    \\sigma=\\sqrt{\\sigma^2}.\n\\end{align}\n\\tag{4.6}\\]\nE no caso de uma amostra, o desvio padrão é dado por (4.7). \\[\n\\begin{align}\n   s=\\sqrt{s^2}.\n\\end{align}\n\\tag{4.7}\\]\nO desvio padrão, indica, em média, qual será o erro (desvio) cometido ao tentar substituir cada dado pela média.\n\nExemplo 4.6 No Exemplo 4.1 e utilizando-se de (4.7) , tem-se:\n\nVariedade A: \\[\ns=\\sqrt{0,0}=0,0~\\textrm{cm}.\n\\]\nVariedade B:\n\n\\[\ns=\\sqrt{13,0}=3,6~\\textrm{cm}.\n\\]\n\nVariedade C:\n\n\\[\ns=\\sqrt{151,0}=12,3~\\textrm{cm}.\n\\]\n\n\nExemplo 4.7  \nConsiderando os dados do Exemplo 2.4 e utilizando-se da expressão (4.7), tem-se:\n\n\n\n4.3.2 Dados Agrupados\nSe os dados estiverem agrupados em uma Tabela de Distribuição de Frequências com intervalos de classes, a variância é dada pela expressão (4.8). \\[\n\\begin{align}\n    s^2=\\frac{\\sum_{i=1}^{k}F_{i}\\tilde{X}_{i}^{2}-\\frac{\\left(\\sum_{i=1}^{K}F_{i}\\tilde{X}_{i}\\right)^2}{\\sum_{i=1}^{k}F_i}}{\\left(\\sum_{i=1}^{K}F_i\\right)-1},\n\\end{align}\n\\tag{4.8}\\] em que: \\(\\tilde{X}_i\\) é o ponto médio da classe \\(i\\), e \\(F_i\\) é a frequência absoluta da classe \\(i\\).\n\nExemplo 4.8 Considerando os dados do Exemplo 2.4. Alternativamente pode-se acrescentar mais duas colunas na tabela de distribuição de frequências referentes a: \\(F_{i}\\tilde{X}_i\\) e \\(F_{i}\\tilde{X}_{i}^{2}\\), apresentada na Tabela 4.1.\n\n\n\nTabela 4.1: Pesos ao nascer, em kg, de 50 bezerros da raça nelore, Fazenda XX, 2007.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeso \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\\(\\mathbf{Fr_i}\\)\n\\(\\mathbf{Fp_i(\\%)}\\)\n\\(\\mathbf{F_{i}\\tilde{X}_i}\\)\n\\(\\mathbf{F_{i}\\tilde{X}_{i}^{2}}\\)\n\n\n\n\n\\(\\left[20,0  \\right. ;\\left. 22,0  \\right)\\)\n21,0\n2\n0,04\n4,0\n42,0\n882,0\n\n\n\\(\\left[22,0  \\right. ;\\left. 24,0  \\right)\\)\n23,0\n5\n0,10\n10,0\n115,0\n2.645,0\n\n\n\\(\\left[24,0  \\right. ;\\left. 26,0  \\right)\\)\n25,0\n12\n0,24\n24,0\n300,0\n7.500,0\n\n\n\\(\\left[26,0 \\right. ;\\left. 28,0 \\right)\\)\n27,0\n16\n0,32\n32,0\n432,0\n11.664,0\n\n\n\\(\\left[28,0  \\right. ;\\left. 30,0  \\right)\\)\n29,0\n10\n0,20\n20,0\n290,0\n8.410,0\n\n\n\\(\\left[30,0  \\right. ;\\left. 32,0  \\right)\\)\n31,0\n4\n0,08\n8,0\n124,0\n3.844,0\n\n\n\\(\\left[32,0  \\right. ;\\left. 34,0  \\right)\\)\n33,0\n1\n0,02\n2,0\n33,0\n1.089,0\n\n\nTotal\n-\n50\n1,00\n100,0\n1.336,0\n36.034,0\n\n\n\n\n\n\nUtilizando-se da expressão (4.8), tem-se que a variância é dada por: \\[\\begin{align*}\n    s^2 &= \\frac{36.034,0-\\frac{\\left(1.336,2\\right)^2}{50}}{50-1}\\\\\n    &= 6,86~\\textrm{kg}^2.\n\\end{align*}\\]\nConsequentemente, o desvio padrão calculado através de (4.7) é dado por:\n\\[\ns=\\sqrt{6,86}=2,62~\\textrm{kg}.\n\\]\nA diferença entre os dois valores (2,6972 kg e 2,62 kg) se deve ao erro de agrupamento.\n\n\n\n4.3.3 Propriedades\nA variância e o desvio padrão apresentam as seguintes propriedades.\n\nSomando-se ou subtraindo-se um mesmo valor constante \\(k\\) a cada dado, a variância e o desvio padrão não se alteram.\n\n\nExemplo 4.9 Considere o Exemplo 3.3, em que a variância foi calculada através de (4.5), e o desvio padrão por (4.7), e são dados por: \\(s^2=13,0~\\textrm{cm}^2\\) e \\(s=3,6~\\textrm{cm}\\).\nSomando \\(k = 4\\) a cada dado, tem-se: \\[\n186,0; 188,0; 193,0.\n\\]\nCalculando a nova variância através de (4.5), tem-se: \\[\\begin{align*}\n  s^2 &= \\frac{186,0^2+188,0^2+193,0^2-\\frac{\\left(186,0+188,0+193,0\\right)^2}{3}}{3-1}\\\\\n  &=\\frac{107.189,0-107.163,0}{2}\\\\\n  &= 13,0~\\textrm{cm}^2\n\\end{align*}\\]\nCalculando o novo desvio padrão por (4.7), tem-se: \\[\ns=\\sqrt{13,0}=3,6~\\textrm{cm}.\n\\]\nComo se observa, a variância e o desvio padrão não se alteraram.\n\n\nMultiplicando-se ou dividindo-se cada dado por uma mesmo valor constante \\(k\\), diferente de zero, a variância fica multiplicada ou dividida por este valor ao quadrado \\((k^2)\\), e o desvio padrão fica multiplicado ou dividido por este valor \\((k)\\).\n\n\nExemplo 4.10 Considere o Exemplo 3.3, em que a variância foi calculado através de (4.5), e o desvio padrão por (4.7), e são dados por: \\(s^2=13,0~\\textrm{cm}^2\\) e \\(s=3,6~\\textrm{cm}\\).\nMultiplicando todos os dados por \\(k = 2\\), tem-se: \\[\n364,0; 368,0; 378,0.\n\\]\nCalculando a nova variância através de (4.5), tem-se: \\[\\begin{align*}\n  s^2 &= \\frac{364,0^2+368,0^2+378,0^2-\\frac{\\left(364,0+368,0+378,0\\right)^2}{3}}{3-1}\\\\\n  &= \\frac{410.804,0-410.700,0}{2}\\\\\n  &= 52,0~\\textrm{cm}^2\n\\end{align*}\\]\nCalculando o novo desvio padrão por (4.7), tem-se:\n\\[\ns=\\sqrt{52,0}=7,2~\\textrm{cm}.\n\\]\nLogo, tem-se que:\n\\[\ns^2=(2)^2 \\times 13,0=52,0~\\textrm{cm}^2$ e $s=(2) \\times 3,6=7,2~\\textrm{cm}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#cv",
    "href": "cap04.html#cv",
    "title": "4  Medidas de Dispersão",
    "section": "4.4 Coeficiente de Variação",
    "text": "4.4 Coeficiente de Variação\nO coeficiente de variação é uma medida de dispersão relativa, que expressa o desvio padrão em termos da média de forma percentual.\nNo caso de uma população, o coeficiente de variação é dado por (4.9). \\[\n\\begin{align}\n    CV=\\frac{\\sigma}{\\mu} \\times 100,\n\\end{align}\n\\tag{4.9}\\] sendo: \\(\\mu\\) e \\(\\sigma\\), a média e o desvio padrão populacional, respectivamente.\nConsiderando uma amostra, o coeficiente de variação é dado por (4.10). \\[\n\\begin{align}\n    cv=\\frac{s}{\\bar{\\text{x}}} \\times 100,\n\\end{align}\n\\tag{4.10}\\] sendo: \\(\\bar{x}\\) e \\(s\\), a média e o desvio padrão amostral, respectivamente.\nO coeficiente de variação é usado para comparar a variabilidade de dois ou mais conjuntos de dados, que possuam diferentes unidades e/ou diferentes médias.\n\nExemplo 4.11 Para o Exemplo 2.4 e utilizando-se a expressão (4.10), tem-se:\n\\[\ncv=\\frac{2,6972}{26,6} \\times 100=10,14\\%.\n\\]\n\n\nExemplo 4.12 Sejam as alturas, em cm, de plantas de duas variedades de soja (A e B), em que a média e o desvio padrão são: \\[\\begin{align*}\n    \\textrm{Variedade A}~\\begin{cases}\n         \\bar{\\text{x}}= 48,5~\\textrm{cm};\\\\\n        s=4,9~\\textrm{cm}.\n    \\end{cases}\n\\end{align*}\\]\n\\[\\begin{align*}\n    \\textrm{Variedade B}~\\begin{cases}\n         \\bar{\\text{x}}=63,2~\\textrm{cm};\\\\\n        s=5,3~\\textrm{cm}.\n    \\end{cases}\n\\end{align*}\\]\nQual das duas variedades de soja tem uma maior variabilidade com relação à altura, A ou B?\nEmbora as unidades sejam as mesmas, tem-se que neste caso as médias das duas variedades com relação a altura são diferentes, e assim, compara-se pelo coeficiente de variação.\nAssim, calculando o coeficiente de variação para as variedades A e B através de (4.10), tem-se:\n\nVariedade A:\n\n\\[\ncv=\\frac{4,9}{48,5} \\times 100=10,10\\%.\n\\] - Variedade B: \\[\ncv=\\frac{5,3}{63,2} \\times 100=8,39\\%.\n\\] Logo, a variedade A tem altura mais variável do que a variedade B, pois seu coeficiente de variação foi maior.\n\n\nExemplo 4.13 Considere uma amostra de 10 plantas de certa variedade de soja, onde se mediu a altura e a produção, dados por:\n\\[\\begin{align*}\n    \\textrm{Altura}~\\begin{cases}\n         \\bar{\\text{x}} = 59,2~\\textrm{cm};\\\\\n        s=6,1~\\textrm{cm}.\n    \\end{cases}\n\\end{align*}\\]\n\\[\\begin{align*}\n    \\textrm{Produção}~\\begin{cases}\n         \\bar{\\text{x}}=10,1~\\textrm{g/vagem};\\\\\n        s=1,4~\\textrm{g/vagem}.\n    \\end{cases}\n\\end{align*}\\]\nQuem possui uma maior maior variabilidade, a altura ou a produção?\nNeste caso tem-se que as unidades das variáveis são diferentes, e assim compara-se pelo coeficiente de variação.\nAssim, calculando o coeficiente de variação para as variáveis através de (4.10), tem-se:\n\nAltura:\n\n\\[\ncv=\\frac{6,1}{59,2} \\times 100=10,30\\%.\n\\]\n\nProdução:\n\n\\[\ncv=\\frac{1,4}{10,1}\\times 100=13,86\\%.\n\\] Logo, a produção desta variedade de soja é mais variável do que a altura, pois seu coeficiente de variação foi maior.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#epmedia",
    "href": "cap04.html#epmedia",
    "title": "4  Medidas de Dispersão",
    "section": "4.5 Erro Padrão da Média",
    "text": "4.5 Erro Padrão da Média\nO erro padrão da média é uma medida de dispersão que dá uma ideia da precisão com que a média populacional \\(\\mu\\) foi estimada, sendo obtida pela expressão (4.11). \\[\n\\begin{align}\n    s(\\bar{\\text{x}})=\\frac{s}{\\sqrt{n}},\n\\end{align}\n\\tag{4.11}\\] em que: \\(s\\) é o desvio padrão amostral, e \\(n\\) o tamanho amostral.\n\nExemplo 4.14 Seja uma lavoura de milho, onde se avaliou uma amostra de 30 plantas, referentes a altura, em cm, encontrando os seguintes resultados:\n\\[\\begin{align*}\n    \\textrm{Altura}~\\begin{cases}\n         \\bar{\\text{x}}=208,0~\\textrm{cm};\\\\\n        s=12,0~\\textrm{cm}.\n    \\end{cases}\n\\end{align*}\\]\nO erro padrão da média calculado através de (4.11), é dado por:\n\\[\ns(\\bar{\\text{x}})=\\frac{12,0}{\\sqrt{30}}=2,2~\\textrm{cm}.\n\\]\nEste resultado quer dizer que a média populacional \\(\\mu\\) foi estimada com um erro de 2,2 cm.\n\nTem-se de modo geral que, quanto menor for o erro padrão mais precisa será a estimativa da média populacional \\(\\mu\\).\nO erro padrão é diretamente proporcional ao desvio padrão da amostra, ou seja:\n\\[\n\\uparrow s \\Rightarrow \\uparrow s(\\bar{\\text{x}});\n\\]\n\\[\\downarrow s \\Rightarrow \\downarrow s(\\bar{\\text{x}}).\n\\]\nO erro padrão é inversamente proporcional ao tamanho da amostra, isto é:\n\\[\n\\uparrow n \\Rightarrow \\downarrow s(\\bar{\\text{x}});\n\\]\n\\[\n\\downarrow n \\Rightarrow \\uparrow s(\\bar{\\text{x}}).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#asscurt",
    "href": "cap04.html#asscurt",
    "title": "4  Medidas de Dispersão",
    "section": "4.6 Medidas de Assimetria e de Curtose",
    "text": "4.6 Medidas de Assimetria e de Curtose\nFoi visto no Capítulo 2 que, a forma do polígono de frequências permite classificar a distribuição de frequências quanto a simetria. Viu-se também que as medidas de posição e dispersão, fornecem importantes informações sobre o comportamento de um conjunto de dados. É possível, ainda, fornecer algumas informações adicionais, de maneira a completar o diagnóstico de um conjunto de dados.\n\n4.6.1 Coeficiente de Assimetria\nAs medidas de dispersão conseguem captar o desvio em torno de um valor central, mas não conseguem transmitir a ideia do formato deste desvio. Assim, surge o conceito de simetria, que é o comportamento de uma curva a ambos os lados de um eixo de simetria.\nO coeficiente de assimetria mede o grau de desvio de uma curva no sentido horizontal, ou seja, quantifica o distanciamento de um conjunto de dados em relação à simetria, e é dado pela expressão (4.12). \\[\n\\begin{align}\n    a_3=\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^3}{ns^3}.\n\\end{align}\n\\tag{4.12}\\] O valor de \\(a_3\\) pode ser:\n\nPositivo: sendo a assimetria à direita (assimetria positiva), Figura 4.1;\nNegativo: sendo a assimetria à esquerda (assimetria negativa), Figura 4.1;\nZero: apresentando uma simetria perfeita (distribuição simétrica), Figura 4.1.\n\n\n\n\n\n\n\nFigura 4.1: Classificação da distribuição quanto a simetria.\n\n\n\n\nExemplo 4.15 Considere o Exemplo 2.4. Neste exemplo a média e o desvio padrão são: \\(26,6\\) kg e \\(2,6972\\) kg, respectivamente.\nO coeficiente de assimetria calculado através de ( 4.12), é dado por: \\[\\begin{align*}\n    a_3 &= \\frac{(21,0-21,6)^3+(21,6-21,6)^3+\\dots+(33,0-21,6)^3}{50(2,6972)^3}\\\\\n        &= \\frac{126,5540}{981,0914}=0,1290.\n\\end{align*}\\]\nEste valor indica uma leve assimetria à direita.\n\n\n\n4.6.2 Coeficiente de Curtose\nO conceito de curtose busca identificar se a curva que representa uma distribuição de frequências, apresenta uma forma achatada ou alongada.\nO coeficiente de curtose mede o grau de achatamento de uma curva, tendo a curva normal como referência, e é dado pela expressão (4.13). \\[\n\\begin{align}\n    a_4=\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{\\text{x}} \\right)^4}{ns^4}.\n\\end{align}\n\\tag{4.13}\\] O valor de \\(a_4\\) pode ser:\n\nMaior que 3: onde a curva apresenta um pico elevado, chamada de leptocúrtica, Figura 4.2.\nMenor que 3: sendo a curva achatada, denominada de platicúrtica, Figura 4.2.\nIgual a 3: apresentado uma curva intermediária, chamada de mesocúrtica, Figura 4.2.\n\n\n\n\n\n\n\nFigura 4.2: Classificação da distribuição quanto a curtose.\n\n\n\n\nExemplo 4.16 Considere o Exemplo 2.4. A média e o desvio padrão são: 26,6~kg e 2,6972~kg, respectivamente.\nCalculando o coeficiente de curtose através de (4.13), tem-se:\n\\[\na_4=\\frac{(21,0-21,6)^4+(21,6-21,6)^4+\\dots+(31,8-21,6)^4+(33,0-21,6)^4}{50(2,6972)^4}\n\\]\n\\[\na_4=\\frac{6.922,9210}{2.646,1997}=2,6162.\n\\]\nIndicando uma curva com um formato aproximadamente mesocúrtica.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#boxplot",
    "href": "cap04.html#boxplot",
    "title": "4  Medidas de Dispersão",
    "section": "4.7 Gráfico Box-Plots",
    "text": "4.7 Gráfico Box-Plots\nAs informações representadas pelo esquema dos cinco números, vistos no Capítulo 3, podem ser representadas graficamente num diagrama, chamado de Box-Plot. O Box-Plot é um gráfico que tem por objetivo apresentar várias informações sobre o comportamento de um conjunto de dados, tais como: posição, dispersão, simetria e dados discrepantes.\nNeste tipo de gráfico considera-se um retângulo em que a mediana (2º Quartil), é representada pela parte central do retângulo, e os quartis inferior (1º Quartil) e superior (3º Quartil), pelas linhas à esquerda e à direita, que delimitam o retângulo, respectivamente, conforme a Figura 4.3. A posição da mediana, central ou mais próxima a um dos quartis, indica a presença ou não de assimetria nos dados.\n\n\n\n\n\n\nFigura 4.3: Gráfico boxplot.\n\n\n\nA dispersão dos dados é dada por (4.14). \\[\n\\begin{align}\n    d_q=q(0,75)–q(0,25).\n\\end{align}\n\\tag{4.14}\\]\nA partir do lado direito do retângulo, segue uma linha horizontal para a direita, que não exceda o limite superior, dado por (4.15). \\[\n\\begin{align}\n    LS=q(0,75)+(1,5)d_q.\n\\end{align}\n\\tag{4.15}\\] E a partir do lado esquerdo do retângulo, segue uma linha horizontal para a esquerda, que não exceda o limite inferior, dado por (4.16). \\[\n\\begin{align}\n    LI=q(0,25)–(1,5)d_q.\n\\end{align}\n\\tag{4.16}\\] Os valores que estiverem compreendidos entre esses dois limites, são chamados de valores adjacentes. As observações que estiverem fora desses limites (esquerda ou direita), serão chamadas de dados discrepantes, e representadas por um círculo (o).\n\nExemplo 4.17 Considerando o Exemplo 2.4, tem-se o seguinte gráfico Box-Plot apresentado na Figura 4.4.\n\n\n\n\n\n\nFigura 4.4: Gráfico de Box-Plot dos pesos ao nascer, em kg, de \\(50\\) bezerros da raça nelore.\n\n\n\nObserva-se pelo gráfico Box-Plot acima que, a distribuição é aproximadamente simétrica, e que a distribuição não apresenta valores discrepantes.\n\nUma outra característica é que este gráfico pode ser apresentado tanto na vertical quanto na horizontal.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#exprop",
    "href": "cap04.html#exprop",
    "title": "4  Medidas de Dispersão",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 4.1 Para comparar quatro variedades de alfafa (A, B, C, D), um Zootecnista conduziu um experimento em blocos casualizados com seis repetições. Os rendimentos de massa verde, em kg/parcela, foram os seguintes:\n\n\n\nTRATAMENTOS/BLOCOS\n1\n2\n3\n4\n5\n6\n\n\n\n\nA\n56,8\n57,2\n57,5\n55,4\n56,0\n57,9\n\n\nB\n53,5\n54,3\n53,8\n54,7\n53,3\n52,6\n\n\nC\n54,0\n53,5\n52,8\n54,2\n53,6\n54,1\n\n\nD\n54,5\n54,5\n54,5\n54,5\n54,5\n54,5\n\n\n\n\nCalcule a amplitude total para o tratamento A;\nCalcule a variância para o tratamento D;\nQual tratamento é mais variável, o B ou o C? Justifique;\nCalcule o desvio padrão para o tratamento A e interprete;\nMultiplique os dados do tratamento A por 1.000,0 e calcule o desvio padrão;\nConfronte os resultados de (d) com (e) e comente a diferença.\n\n\n\nExercício 4.2 Num concurso de produtividade de milho foram sorteadas seis parcelas de 40 \\(\\textrm{m}^2\\), em lavouras de dois produtores rurais de uma determinada região produtora de milho. Na colheita foram pesados os rendimentos das parcelas, em kg, fornecendo os seguintes resultados:\n\n\n\nProdutor A\nProdutor B\n\n\n\n\n24,0\n17,0\n\n\n23,0\n23,0\n\n\n26,0\n18,9\n\n\n21,0\n22,0\n\n\n27,0\n19,0\n\n\n23,0\n21,0\n\n\n\n\nQual foi o rendimento médio, em kg/parcela, e o erro padrão da média de cada produtor;\nQual produtor teve o rendimento médio estimado com maior precisão? Justifique;\nQual é a produtividade média do produtor A em t/ha;\nCalcule a produtividade média, em t/ha, e o erro padrão da média para o produtor B;\nSe a lavoura do produtor B tem 400 ha, qual será a sua produção total;\nQuantas parcelas você recomendaria usar num próximo concurso, para estimar a produtividade média do produtor A com um erro padrão 30% menor.\n\n\n\nExercício 4.3 Tem-se abaixo informações climáticas mensais de uma determinada região produtora de arroz:\n\n\n\nMedida\nMédia\nDesvio padrão\n\n\n\n\nTemperatura \\((^{\\circ}\\)C)\n22,0\n2,0\n\n\nPrecipitação \\((\\textrm{mm})\\)\n100,0\n15,5\n\n\n\n\nQual das medidas (temperatura ou precipitação) possui maior variabilidade. Justifique;\nUma vez registrados os dados descobriu-se que o instrumento utilizado para medir a precipitação estava aumentando sistematicamente 4 unidades (4~mm) em cada medição. Após corrigido o erro, qual atributo meteorológico é mais variável. Justifique.\n\n\n\nExercício 4.4 Para estudar a produtividade de um canavial um Engenheiro Agrônomo demarcou nele em vários pontos escolhidos ao acaso, 10 pequenas áreas de 100 \\(\\textrm{m}^2\\) cada, cuja produção foi pesada. Os resultados obtidos, em kg, foram os seguintes:\n\\[\n650,0;  850,0;  710,0;  920,0;  780,0;  820,0;  900,0;  780,0;  740,0;  950,0\n\\]\n\nCalcule a variância, o desvio padrão, o coeficiente de variação e o erro padrão da média da produção de cana-de-açúcar por área de 100 \\(\\textrm{m}^2\\);\nVocê acha que a variabilidade dos dados em relação à sua média é grande ou pequena. Justifique.\n\n\n\nExercício 4.5 Em relação ao estudo do problema anterior, o Engenheiro Agrônomo achou que a variabilidade dos dados era muito grande, e que apenas 10 áreas de 100 \\(\\textrm{m}^2\\) não podiam representar bem a produtividade do canavial. Assim ele avaliou no lugar de 10, uma amostra de 50 áreas de 100 \\(\\textrm{m}^2\\), seguindo a mesma metodologia explicada no problema anterior. Os resultados obtidos, em kg, são apresentados na seguinte tabela de distribuição de frequências.\n\n\n\nTabela 4.2: Produção de cana-de-açúcar, em kg, por áreas de 100 \\(\\textrm{m}^2\\), Fazenda XX, 2007.2\n\n\n\n\n\nProdução \\(\\mathbf{(kg)}\\)\n\\(\\mathbf{\\tilde{X}_i}\\)\n\\(\\mathbf{F_i}\\)\n\n\n\n\n\\(\\left[624,0  \\right. ;\\left. 668,0  \\right)\\)\n646,0\n1\n\n\n\\(\\left[668,0  \\right. ;\\left. 712,0  \\right)\\)\n690,0\n5\n\n\n\\(\\left[712,0  \\right. ;\\left. 756,0  \\right)\\)\n734,0\n15\n\n\n\\(\\left[756,0 \\right. ;\\left. 800,0 \\right)\\)\n778,0\n13\n\n\n\\(\\left[800,0  \\right. ;\\left. 844,0  \\right)\\)\n822,0\n7\n\n\n\\(\\left[844,0  \\right. ;\\left. 888,0  \\right)\\)\n866,0\n5\n\n\n\\(\\left[888,0  \\right. ;\\left. 932,0  \\right)\\)\n910,0\n3\n\n\n\\(\\left[932,0  \\right. ;\\left. 976,0  \\right)\\)\n954,0\n1\n\n\nTotal\n\n50\n\n\n\n\n\n\n\nCalcule a variância, o desvio padrão e o coeficiente de variação, da produção de cana-de-açúcar por área de 100 \\(\\textrm{m}^2\\);\nApós registrada a produção de cada uma das 50 áreas de 100 \\(\\textrm{m}^2\\), o Engenheiro Agrônomo descobriu um erro sistemático na pesagem da cana-de-açúcar. Para obter a pesagem certa ele determinou que, em cada um dos 50 dados obtidos deveria ser acrescido 6,0 kg e depois o resultado deveria ser multiplicado por 0,9. Qual o valor correto da variância, do desvio padrão e do coeficiente de variação. O pesquisador conseguiu diminuir a variabilidade? Justifique.\n\n\n\nExercício 4.6 Os ganhos de peso, em kg, de 60 novilhos da raça guzerá, mantidos numa pastagem em determinado período foram os seguintes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n36,0\n45,0\n60,0\n39,0\n57,0\n32,0\n39,0\n40,0\n63,0\n37,0\n\n\n42,0\n42,0\n44,0\n30,0\n47,0\n39,0\n15,0\n39,0\n25,0\n39,0\n\n\n57,0\n48,0\n44,0\n37,0\n44,0\n38,0\n21,0\n56,0\n52,0\n50,0\n\n\n31,0\n34,0\n36,0\n38,0\n43,0\n24,0\n38,0\n41,0\n46,0\n42,0\n\n\n28,0\n31,0\n32,0\n49,0\n39,0\n19,0\n49,0\n39,0\n42,0\n43,0\n\n\n20,0\n58,0\n34,0\n56,0\n35,0\n50,0\n27,0\n36,0\n40,0\n37,0\n\n\n\n\nCalcule os coeficientes de assimetria e de curtose e discuta os resultados;\nConstrua o gráfico Box-Plot e interprete.\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#footnotes",
    "href": "cap04.html#footnotes",
    "title": "4  Medidas de Dispersão",
    "section": "",
    "text": "Fonte: Dados fictícios.↩︎\nFonte: Dados fictícios.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de Dispersão</span>"
    ]
  },
  {
    "objectID": "cap05.html",
    "href": "cap05.html",
    "title": "5  Probabilidades",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap06.html",
    "href": "cap06.html",
    "title": "6  Distribuições de Probabilidades",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuições de Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap07.html",
    "href": "cap07.html",
    "title": "7  Amostragem",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Amostragem</span>"
    ]
  },
  {
    "objectID": "cap08.html",
    "href": "cap08.html",
    "title": "8  Distribuições de Amostragem",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Distribuições de Amostragem</span>"
    ]
  },
  {
    "objectID": "cap09.html",
    "href": "cap09.html",
    "title": "9  Teoria da Estimação",
    "section": "",
    "text": "9.1 Introdução\nToda população é descrita por um certo modelo probabilístico \\(f(x | \\theta)\\), com parâmetro(s) \\(\\theta\\) desconhecido(s), e o interesse é obter algum tipo de informação acerca desse(s) parâmetro(s). O que se dispõe é de uma amostra, ou seja, de partes de elementos da população. A partir de uma amostra aleatória é possível obter aproximações numéricas para o(s) parâmetro(s) \\(\\theta\\) do modelo, e esse processo é chamado estimação. Assim, um dos objetivos da Estatística é obter informações sobre os parâmetros populacionais através das estimativas amostrais.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#conceitos-básicos",
    "href": "cap09.html#conceitos-básicos",
    "title": "9  Teoria da Estimação",
    "section": "9.2 Conceitos Básicos",
    "text": "9.2 Conceitos Básicos\nPara formalizar as ideias que serão apresentadas alguns conceitos são úteis.\n\n9.2.1 Parâmetro\nUm parâmetro é um valor desconhecido associado a uma característica da população, e em geral representado por letras gregas.\n\nExemplo 9.1 A média \\(\\mu\\) e a variância \\(\\sigma^2\\) de uma população são parâmetros.\n\n\n\n9.2.2 Estimador\nO estimador é a função ou expressão algébrica que estima o valor de um parâmetro populacional, baseando-se nas observações de uma amostra aleatória.\n\nExemplo 9.2  \n\n\\(\\bar{x}=\\frac{\\sum_{i=1}^{n}x_i}{n}\\) é um estimador da média populacional \\(\\mu\\);\n\\(s^2=\\frac{\\sum_{i=1}^{n}x_i^2-\\frac{\\left(\\sum_{i=1}^{n}x_i\\right)^2}{n}}{n-1}\\) é um estimador da variância populacional \\(\\sigma^2\\).\n\n\n\n\n9.2.3 Estimativa\nUma estimativa é uma aproximação numérica para um parâmetro associado a um modelo probabilístico, ou seja, é o valor obtido pelo estimador numa determinada amostra aleatória.\n\nExemplo 9.3 Numa certa variedade de milho tem-se uma estimativa da altura média desta variedade, dada por:\n\\[\n\\bar{x}=200,0~\\textrm{cm}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#tipos-de-estimativas",
    "href": "cap09.html#tipos-de-estimativas",
    "title": "9  Teoria da Estimação",
    "section": "9.3 Tipos de Estimativas",
    "text": "9.3 Tipos de Estimativas\nBasicamente existem dois processos de estimação. O primeiro deles é a chamada estimação pontual, pela qual um valor numérico é obtido através de um estimador, como sendo uma aproximação numérica para o parâmetro populacional.\n\nExemplo 9.4 Numa amostra aleatória de n elementos os valores de \\(\\bar{x}\\) e \\(s^2\\) estimam \\(\\mu\\) e \\(\\sigma^2\\), respectivamente, por ponto.\n\n\nExemplo 9.5 Seja uma amostra de 40 plantas de uma variedade de milho, em que a variável altura, apresentou uma média de \\(200,0\\) cm e um desvio padrão de \\(10,0\\) cm.\nNesta amostra a média amostral, \\(\\bar{x}=200,0\\) cm, é uma estimativa por ponto da média populacional \\(\\mu\\), e o desvio padrão amostral, \\(s = 10,0\\) cm, é uma estimativa por ponto do desvio padrão populacional \\(\\sigma\\).\n\nO segundo processo de estimação é a estimação por intervalo, no qual algum tipo de intervalo é construído, de tal maneira que se possa atribuir probabilidades de que o valor real do parâmetro esteja ali contido. Neste caso, o parâmetro populacional é estimado por dois valores, obtidos através de cálculos com os dados amostrais, que formam um intervalo, dentro do qual se espera encontrar o verdadeiro valor do parâmetro. A vantagem desse processo é que mostra a precisão da estimativa.\n\nExemplo 9.6 Considerando o exemplo anterior tem-se que a expressão: \\[\nIC_{95,0\\%}(\\mu):~[196,90~\\textrm{cm};~ 203,10~\\textrm{cm}],\n\\] é uma estimativa por intervalo para \\(\\mu\\) com uma confiança de 95,0% e um erro de 3,10 cm.\n\nAssim, a associação entre estimativas pontuais acerca de um parâmetro populacional, e o conhecimento de probabilidades de que o parâmetro esteja contido em certos intervalos, possibilitará, em geral, promover uma inferência informativa a respeito do parâmetro desconhecido.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#métodos-de-estimação-pontual",
    "href": "cap09.html#métodos-de-estimação-pontual",
    "title": "9  Teoria da Estimação",
    "section": "9.4 Métodos de Estimação Pontual",
    "text": "9.4 Métodos de Estimação Pontual\nOs métodos de obtenção de estimativas pontuais, os quais não serão discutidos em detalhes aqui, são:\n\nMétodo dos Momentos;\nMétodo dos Quadrados Mínimos;\nMétodo da Máxima Verossimilhança.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#propriedades-dos-estimadores-pontuais",
    "href": "cap09.html#propriedades-dos-estimadores-pontuais",
    "title": "9  Teoria da Estimação",
    "section": "9.5 Propriedades dos Estimadores Pontuais",
    "text": "9.5 Propriedades dos Estimadores Pontuais\nEm função da existência de vários métodos para estimação de parâmetros, é importante analisar algumas propriedades dos estimadores, que possa auxiliar na escolha de um estimador para um parâmetro em particular. Essas propriedades são:\n\nVício: Um estimador \\(\\hat{\\theta}\\) de um parâmetro \\(\\theta\\) é não viciado, ou não tendencioso, ou não viesado, se: \\[\nE(\\hat{\\theta})=\\theta.\n\\]\n\n\nExemplo 9.7 A média amostral, \\(\\bar{x} = \\sum_{i = 1}^{n}x_i / n\\), é um estimador não viciado da média populacional \\(\\mu\\), pois pode-se provar que:\n\\[\nE(\\bar{x})=\\mu.\n\\]\n\nOu seja, um estimador é não viciado se o seu valor esperado coincide com o parâmetro de interesse.\n\nExemplo 9.8 A variância amostral, \\(\\hat{\\sigma}^2 = \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 / n\\), é um estimador viciado para \\(\\sigma^2\\).\nPode ser demonstrado que:\n\\[\nE(\\hat{\\sigma}^2)=\\left(\\frac{n-1}{n}\\right) \\sigma^2.\n\\]\nPor outro lado tem-se que: \\[\nE\\left(\\frac{n}{n-1}\\hat{\\sigma}^2\\right)=\\sigma^2\n\\] Note que:\n\\[\n\\left(\\frac{n}{n-1}\\hat{\\sigma}^2\\right)=\\left(\\frac{n}{n-1}\\right)\\frac{\\sum_{i=1}^{n}\\left(x_i- \\bar{x} \\right)^2}{n}=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(x_i- \\bar{x} \\right)^2=s^2.\n\\]\nLogo, \\(s^2\\) é um estimador não viciado para \\(\\sigma^2\\).\n\n\nConsistência: Um estimador \\(\\hat{\\theta}\\) é consistente se à medida que o tamanho n da amostra aumenta, seu valor esperado converge para o parâmetro de interesse, e sua variância converge para zero. Ou seja, \\(\\hat{\\theta}\\) é consistente se as duas propriedades são satisfeitas:\n\n\n\\(\\lim_{n \\to \\infty} E(\\hat{\\theta}) = \\theta\\);\n\\(\\lim_{n \\to \\infty} V(\\hat{\\theta}) = 0\\).\n\n\nEficiência: Dados dois estimadores \\(\\hat{\\theta}_1\\) e \\(\\hat{\\theta}_2\\), não viciados para um parâmetro \\(\\theta\\), diz-se que \\(\\hat{\\theta}_1\\) é mais eficiente que \\(\\hat{\\theta}_2\\) se: \\(V(\\hat{\\theta}_1)\\) &lt; \\(V(\\hat{\\theta}_2)\\). Isto é, dentre todos os estimadores não viciados de um parâmetro \\(\\theta\\), aquele que tiver menor variância é o estimador mais eficiente de \\(\\theta\\).\n\n\nExemplo 9.9 Numa amostra a média amostral \\(\\bar{x}\\) é um estimador mais eficiente da média populacional \\(\\mu\\) que a mediana \\(md\\), pois pode-se provar que: \\[\nV(\\bar{x})=\\frac{\\sigma^2}{n}~\\textrm{e}~ V(md)=\\frac{\\pi}{2}\\times \\frac{\\sigma^2}{n}.\n\\]\nLogo \\(V(\\bar{\\text{x}}) &lt; V(md)\\).\n\nNo caso de uma estimativa por intervalo, o comprimento do intervalo de confiança dá uma idéia da eficiência da estimativa.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#estimação-por-intervalo",
    "href": "cap09.html#estimação-por-intervalo",
    "title": "9  Teoria da Estimação",
    "section": "9.6 Estimação por intervalo",
    "text": "9.6 Estimação por intervalo\nOs estimadores pontuais fornecem como estimativa um único valor numérico para o parâmetro \\(\\theta\\) de interesse, associado ao modelo probabilístico \\(f(x | \\theta)\\). A inferência pode e deve ser complementada, sempre que possível, com pressuposições acerca de probabilidades de \\(\\theta\\) estarem próximos ou não de suas estimativas pontuais. Por serem variáveis aleatórias, os estimadores possuem uma distribuição de probabilidade, e levando este fato em consideração, pode-se apresentar uma estimativa mais informativa para o parâmetro de interesse, que inclua uma medida de precisão do valor obtido. Este método de estimação, denominado estimação por intervalo, incorpora à estimativa pontual do parâmetro, informações a respeito de sua variabilidade, permitindo a construção de intervalos com probabilidades conhecidas de que o valor paramétrico esteja contido nesse intervalo.\nAssim, intervalos de confiança são obtidos através da distribuição amostral de seus estimadores.\nSeja \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\) uma amostra aleatória coletada numa população descrita pelo modelo probabilístico \\(f(x | \\theta)\\). Sejam \\(T_1(x)\\) e \\(T_2(x)\\) duas estatísticas que satisfaçam: \\(T_1(x) &lt; T_2(x)\\), e também que: \\(P[T_1(x) &lt; \\theta &lt; T_2(x)]=1 - \\alpha\\).\nO intervalo aleatório: \\([T_1(x); T_2(x)]\\) é chamado de intervalo de confiança para \\(\\theta\\) com \\((1 - \\alpha)100,0\\%\\) de probabilidade. A probabilidade \\((1 - \\alpha)\\) é chamada coeficiente de confiança do intervalo. O comprimento do intervalo de confiança é dado por: \\[\\begin{align*}\n    L(x)=T_2(x) - T_1(x).\n\\end{align*}\\]\nLogo, a construção de intervalos de confiança consiste na obtenção de \\(T_1(x)\\) e \\(T_2(x)\\).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#construção-de-intervalos-de-confiança",
    "href": "cap09.html#construção-de-intervalos-de-confiança",
    "title": "9  Teoria da Estimação",
    "section": "9.7 Construção de Intervalos de Confiança",
    "text": "9.7 Construção de Intervalos de Confiança\nBasicamente os intervalos de confiança podem ser construídos utilizando a distribuição de quantidades pivotais.\nConsidere uma amostra aleatória \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\) de uma população descrita pelo modelo probabilístico \\(f(x | \\theta)\\). Uma função \\(g(x; \\theta)\\), cuja distribuição não dependa de \\(\\theta\\), é chamada de quantidade pivotal.\n\nExemplo 9.10 Considere um modelo probabilístico correspondente a uma distribuição normal de média \\(\\mu\\) e variância \\(\\sigma^2\\). Seja, \\[\nZ=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}.\n\\]\nNeste caso é \\(Z\\) uma quantidade pivotal, pois \\(Z\\) é uma variável aleatória com distribuição normal padronizada, ou seja, \\(Z\\sim N(0,0; 1,0)\\), e não depende de \\(\\mu\\) e \\(\\sigma^2\\).\n\nNas próximas seções, serão utilizados as distribuições de probabilidades e resultados, vistos no Capítulo 8, para a construção de intervalos de confiança para parâmetros populacionais de interesse.\n\n9.7.1 Intervalo de Confiança para a Média de uma Distribuição Normal\nA média estimada a partir de uma amostra aleatória, é apenas uma estimativa por ponto da verdadeira média populacional \\(\\mu\\). A média verdadeira é um parâmetro que na grande maioria das vezes é desconhecida. Entretanto, a partir do conhecimento das distribuições teóricas de \\(Z\\) e \\(t\\), pode-se construir um intervalo que deve conter a verdadeira média populacional \\(\\mu\\).\nPara a construção do intervalo de confiança para a média, tem-se as seguintes situações, descritas a seguir.\n\n\n9.7.2 Grandes Amostras ou Variância Populacional Conhecida\nO intervalo de confiança associado a um determinado nível de confiança, para a média populacional \\(\\mu\\), quando se tem grandes amostras \\((n\\geq 30)\\), ou variância populacional \\(\\sigma^2\\) conhecida, pode ser deduzido da seguinte forma.\nFoi visto no capítulo anterior de acordo com o teorema central do limite que: \\[\n\\bar{\\text{x}} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\n\\]\nLogo, na distribuição de \\(\\bar{x}\\) o valor de \\(Z\\) é obtido por: \\[\nZ=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}},\n\\tag{9.1}\\] em que \\(Z \\sim N(0,0; 1,0)\\).\nNa distribuição de \\(\\bar{x}\\) pode-se esquematizar uma probabilidade de \\((1 - \\alpha)\\), conforme Figura 9.1.\n\n\n\n\n\n\nFigura 9.1: Área correspondente a probabilidade \\(P(-Z_{\\alpha/2} &lt; Z &lt; Z_{\\alpha/2})\\).\n\n\n\nLogo, \\[\nP\\left[-Z_\\frac{\\alpha}{2} &lt; Z &lt; Z_\\frac{\\alpha}{2} \\right]=1 - \\alpha.\n\\tag{9.2}\\]\nSubstituindo (9.1) em (9.2), tem-se: \\[\nP\\left[-Z_\\frac{\\alpha}{2} &lt; \\frac{\\bar{\\text{x}}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}} &lt; Z_\\frac{\\alpha}{2} \\right]=1 - \\alpha.\n\\]\nMultiplicando cada termo da desigualdade por: \\(\\frac{\\sigma}{\\sqrt{n}}\\), obtém-se: \\[\nP\\left[-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; \\bar{\\text{x}}-\\mu &lt; Z_\\frac{\\alpha}{2}\\times \\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nSubtraindo \\(\\bar{x}\\) de cada termo da desigualdade a expressão fica: \\[\nP\\left[-\\bar{\\text{x}}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; -\\mu &lt; -\\bar{\\text{x}}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nMultiplicando cada termo da desigualdade por (-1), tem-se: \\[\nP\\left[\\bar{\\text{x}}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &gt; \\mu &gt; \\bar{\\text{x}}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\]\nInvertendo os extremos do intervalo obtém-se a expressão (9.3), para a construção do intervalo de confiança para \\(\\mu\\) com \\((1 - \\alpha)100,0\\%\\) de probabilidade. \\[\nP\\left[\\bar{x}-Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} &lt; \\mu &lt; \\bar{x}+Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}} \\right]=1 - \\alpha,\n\\tag{9.3}\\] em que:\n\n\\(\\bar{x} \\pm Z_\\frac{\\alpha}{2}\\times\\frac{\\sigma}{\\sqrt{n}}\\) são os limites de confiança;\n\\((1 - \\alpha)100,0\\%\\) é o grau ou nível de confiança.\n\nA representação gráfica de (9.3) pode ser observada na Figura 9.2.\n\n\n\n\n\n\nFigura 9.2: Região do estimador intervalar para \\(\\mu\\) de uma população normal.\n\n\n\nNão conhecendo-se o valor de \\(\\sigma\\) (desvio padrão populacional), pode-se usar o valor de \\(s\\) (desvio padrão amostral), desde que \\(n\\geq 30\\).\n\nExemplo 9.11 Seja uma amostra de 40 plantas de uma variedade de milho, em que a variável altura, apresentou uma média de 200,0 cm e variância de 100,0 cm\\(^2\\). Construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\). Neste caso, não se conhece a variância populacional \\(\\sigma^2\\), e sim, a variância amostral \\(s^2\\). Como o tamanho da amostra é n = 40, considera-se razoável a utilização do desvio padrão amostral. Para construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\), tem-se:\n\n\\(n=40\\);\n\\(\\bar{\\text{x}}=200,0\\) cm;\n\\(s^2=100,0\\) cm\\(^2 \\Rightarrow s=\\sqrt{100,0}=10,0\\) cm;\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\). \\[\nZ_\\frac{\\alpha}{2}=Z_{0,025}=?\n\\]\n\nConsultando a Tabela A 1, tem-se que o valor de Z que deixa uma probabilidade acima dele de 0,025 é igual a 1,96. Dentro do corpo da tabela consulta-se o valor referente a 0,025, conforme esquema abaixo.\n\n\n\nLogo, \\[\nZ_{0,025}=1,96.\n\\]\nAtravés da expressão (9.3), tem-se que: \\[\n200,0-1,96\\frac{10}{\\sqrt{40}} &lt; \\mu &lt; 200,0+1,96\\frac{10}{\\sqrt{40}}\n\\] \\[\n200,0 - 3,10 &lt; \\mu &lt; 200,0 + 3,10\n\\] \\[\n\\Rightarrow IC_{0,95}(\\mu): [196,90~\\textrm{cm}; 203,10~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 95,0% a confiança, da verdadeira altura média das plantas de milho estar entre 196,90 e 203,10 cm. Do ponto de vista de amostragem isto quer dizer que, se forem retiradas várias amostras aleatórias dentro desta população, calculando-se os valores de \\(\\bar{x}\\) e \\(s\\) para cada amostra, e construindo o intervalo de confiança para \\(\\mu\\) em cada amostra, 95,0% dos intervalos conterão em seu interior o verdadeiro valor da média populacional \\(\\mu\\).\n\n\nExemplo 9.12 Considerando o Exemplo 9.11, construir um intervalo de confiança de 99,0% para a média populacional \\(\\mu\\).\nAssim, tem-se: \\[\n(1 - \\alpha)=0,99 \\Rightarrow \\alpha=0,01 \\Rightarrow \\frac{\\alpha}{2}=0,005.\n\\] \\[\nZ_\\frac{\\alpha}{2}=Z_{0,005}=?\n\\]\nConsultando a Tabela A 1, o valor de Z que deixa uma probabilidade acima dele de 0,005 (média de 0,0051 e 0,0049) é igual a 2,575 ( média de 2,57 e 2,58). Dentro do corpo da tabela consulta-se o valor referente a 0,005 ou mais próximo, conforme esquema abaixo:\n\n\n\nLogo, \\[\nZ_{0,005}=2,575.\n\\] Através da expressão (9.3), tem-se que: \\[\n200,0-2,575\\frac{10}{\\sqrt{40}} &lt; \\mu &lt; 200,0+2,575\\frac{10}{\\sqrt{40}}\n\\] \\[\n200,0 - 4,07 &lt; \\mu &lt; 200,0 + 4,07\n\\] \\[\n\\Rightarrow IC_{0,99}(\\mu): [195,93~\\textrm{cm}; 204,07~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 99,0% a confiança, da verdadeira altura média das plantas de milho estar entre 195,93 e 204,07 cm.\n\nO erro da estimativa é dado pela expressão (9.4). \\[\ne=\\bar{\\text{x}} - \\mu.\n\\tag{9.4}\\]\nO erro máximo da estimativa na construção do intervalo de confiança é dado pela expressão (9.5). \\[\ne=Z_\\frac{\\alpha}{2}\\frac{\\sigma}{\\sqrt{n}}.\n\\tag{9.5}\\]\n\nExemplo 9.13 Nos Exemplos 9.11 e 9.12, tem-se que:\n\n\\(\\alpha=5,0\\%=0,05 \\Rightarrow e=3,10\\) cm, ou seja, com 95,0% de confiança, a média, \\(\\bar{\\text{x}}=200,0\\) cm, estima a média populacional \\(\\mu\\) com um erro máximo de 3,10 cm;\n\\(\\alpha=1,0\\%=0,01 \\Rightarrow e=4,07\\) cm, ou seja, com 99,0% de confiança, a média, \\(\\bar{\\text{x}}=200,0\\) cm, estima a média populacional \\(\\mu\\) com um erro máximo de 4,07 cm.\n\nAs consequências da redução de \\(\\alpha\\) são: - O coeficiente de confiança \\((1 - \\alpha)100,0\\%\\) aumenta: \\[\n95,0\\% \\Rightarrow 99,0\\%.\n\\]\n\nO erro da estimativa aumenta:\n\n\\[\n3,10~\\textrm{cm}~\\Rightarrow~4,07~\\textrm{cm}.\n\\]\n\nO comprimento do intervalo de confiança aumenta: \\[\n[196,9~\\textrm{cm};~203,10~\\textrm{cm}]~\\Rightarrow~ [195,93~\\textrm{cm};~204,07~\\textrm{cm}].\n\\]\n\nTem-se que, a única forma de aumentar a confiança e reduzir o comprimento do intervalo, simultaneamente, é aumentando o tamanho da amostra.\n\nA partir do intervalo de confiança para a média \\(\\mu\\), pode-se dimensionar o tamanho da amostra estatisticamente para estimar a média \\(\\mu\\).\nNa abordagem estatística considerada para determinar o tamanho da amostra, o nível de precisão e o erro da estimativa são especificados antecipadamente.\nA expressão do erro máximo é dada por. \\[\ne=Z_\\frac{\\alpha}{2}\\frac{\\sigma}{\\sqrt{n}}.\n\\tag{9.6}\\]\nIsolando \\(n\\) em (9.6), obtém-se a expressão (9.7) para dimensionar o tamanho da amostra estatisticamente. \\[\nn=\\left(\\frac{Z_\\frac{\\alpha}{2}\\sigma}{e} \\right)^2.\n\\tag{9.7}\\]\n\nExemplo 9.14 No Exemplo 9.11, tem-se que:\n\nn=40;\n\\(\\bar{\\text{x}}=200,0\\) cm;\n\\(s=10,0\\) cm;\n\\(\\alpha=5,0\\%=0,05\\);\n\\(e=3,10\\) cm.\n\nQuantas plantas deverão ser examinadas num próximo estudo, para estimar \\(\\mu\\) com um erro de 2,8 cm e uma confiança de 95,0%?\nNeste caso, tem-se que:\n\n\\(e=2,8\\) cm;\n\\(\\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(Z_{0,025}=1,96\\).\n\nLogo, através da expressão (9.7), tem-se que:\n\\[\nn=\\left(\\frac{1,96(10,0)}{2,8}\\right)^2=49~\\textrm{plantas}.\n\\]\n\n\n9.7.2.1 Pequenas Amostras e Variância Populacional Desconhecida\nGeralmente não se conhece o valor da variância populacional \\(\\sigma^2\\). Foi visto que a variância populacional \\(\\sigma^2\\) pode ser estimada a partir da variância amostral \\(s^2\\). Assim, é possível construir um intervalo de confiança de \\((1 – \\alpha)100,0\\%\\) para a média populacional \\(\\mu\\), utilizando a distribuição \\(t\\) em lugar de \\(Z\\). Deste modo, é possível obter o intervalo de confiança para pequenas amostras, \\((n &lt; 30)\\), quando somente a variância amostral \\(s^2\\) é conhecida.\nNesse caso, utiliza-se da distribuição da variável \\(t\\), dada por: \\[\nt=\\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}},\n\\tag{9.8}\\] em que \\(t\\) segue uma distribuição \\(t-Student\\) com \\(\\nu = n – 1\\) graus de liberdade.\nO intervalo de confiança para \\(\\mu\\) com nível de confiança de \\((1 – \\alpha)100,0\\%\\), é dado pela expressão (9.9).\n\\[\nP\\left[\\bar{x}-t_{\\left(\\nu;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}} &lt; \\mu &lt; \\bar{x}+t_{\\left(\\nu;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}} \\right]=1 - \\alpha.\n\\tag{9.9}\\]\nO erro máximo da estimativa é dado por: \\[\ne=t_{\\left(v;\\frac{\\alpha}{2} \\right)} \\frac{s}{\\sqrt{n}}\n\\]\nO tamanho da amostra para estimar a média é obtido pela expressão (9.10). \\[\nn=\\left(\\frac{t_{\\left(v;\\frac{\\alpha}{2} \\right)}s}{e} \\right)^2.\n\\tag{9.10}\\]\n\nExemplo 9.15 Seja uma amostra de 20 árvores, de uma espécie de Eucalipto pertencente a um povoamento florestal, em que a variável DAP (diâmetro à altura do peito) apresentou uma média de 18,0 cm e um desvio padrão de 2,5 cm. Construir um intervalo de confiança de 95,0% para a média populacional \\(\\mu\\).\nNeste caso, tem-se:\n\n\\(n=20 \\Rightarrow v=n-1=20-1=19\\) graus de liberdade;\n\\(\\bar{x}=18,0\\) cm;\n\\(s=2,5\\) cm;\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\).\n\n\\[\nt_{\\left(v;\\frac{\\alpha}{2} \\right)}=t_{\\left(19;0,025\\right)}=?\n\\]\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930, conforme esquema abaixo:\n\n\n\nLogo, \\[\nt_{\\left(19;0,025\\right)}=2,0930.\n\\]\nAtravés da expressão (9.9), tem-se que: \\[\n18,0-2,0930\\frac{2,5}{\\sqrt{20}} &lt; \\mu &lt; 18,0+2,0930\\frac{2,5}{\\sqrt{20}}\n\\] \\[\n18,0 - 1,17 &lt; \\mu &lt; 18,0 + 1,17\n\\]\n\\[\n\\Rightarrow IC_{0,95}(\\mu):~[16,83~\\textrm{cm};~ 19,17~\\textrm{cm}].\n\\]\nEsse resultado mostra que é de 95,0% a confiança, do verdadeiro DAP médio das árvores de Eucalipto estar entre 16,83 e 19,17 cm. Do ponto de vista de amostragem isto quer dizer que, se forem retiradas várias amostras aleatórias dentro desta população, calculando-se os valores de \\(\\bar{\\text{x}}\\) e \\(s\\) para cada amostra, e construindo o intervalo de confiança para \\(\\mu\\) em cada amostra, 95,0% dos intervalos conterão em seu interior o verdadeiro valor da média populacional \\(\\mu\\).\n\n\n\n\n9.7.3 Intervalo de Confiança para a Diferença entre duas Médias Independentes\nA diferença de médias amostrais, \\(\\bar{x}_1-\\bar{x}_2\\), estima a diferença de médias populacionais, \\(\\mu_1 - \\mu_2\\), por ponto. A partir do conhecimento das distribuições teóricas \\(Z\\) e \\(t\\), pode-se construir um intervalo de confiança de \\((1 – \\alpha)100,0\\%\\) para a diferença de médias \\(\\mu_1 - \\mu_2\\).\nPara a construção do intervalo de confiança para a diferença entre duas médias independentes, tem-se as seguintes situações, descritas a seguir.\n\n9.7.3.1 Grandes Amostras ou Variâncias Populacionais Conhecidas\nO intervalo de confiança associado a um determinado nível de confiança, para a diferença entre duas médias, \\(\\mu_1 - \\mu_2\\), quando se tem grandes amostras, \\(n_1\\) e \\(n_2 \\geq 30\\), ou variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), conhecidas, é dado pela expressão (9.11).\n\\[\nP\\left[(\\bar{x}_{1}-\\bar{x}_{2})-Z_\\frac{\\alpha}{2}\\sqrt{\\frac{\\sigma_{1}^2}{n_1}+\\frac{\\sigma_{2}^2}{n_2}} &lt; (\\mu_1 - \\mu_2) &lt;\\right.\n\\] \\[\n\\left.(\\bar{x}_{1}-\\bar{x}_{2})+Z_\\frac{\\alpha}{2}\\sqrt{\\frac{\\sigma_{1}^2}{n_1}+\\frac{\\sigma_{2}^2}{n_2}}\\right]=1 - \\alpha.\n\\tag{9.11}\\]\nNão se conhecendo \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) pode-se usar \\(s_{1}^2\\) e \\(s_{2}^2\\), desde que \\(n_1\\) e \\(n_2 \\geq 30\\).\n\nExemplo 9.16 Sejam:\n\n\\(X_1:\\) Peso de suínos da raça 1, em kg;\n\n\n\\(X_2:\\) Peso de suínos da raça 2, em kg.\n\nEm que:\n\n\\(X_1 \\sim N(\\mu_1; 166,0)\\)\n\n\n\\(X_2 \\sim N(\\mu_2; 127,0)\\)\n\nSe da população de suínos da raça 1 e da raça 2, são retiradas amostras de tamanhos: \\(n_1 = 10\\) e \\(n_2 = 11\\), respectivamente, obtendo-se: \\(\\bar{x}_{1}=110,0\\) kg e \\(\\bar{x}_{2}=107,0\\) kg. Construir um intervalo com 95,0% de confiança para a diferença de médias das duas raças.\nTem-se então que:\n\n\\(\\sigma_{1}^2=166,0\\) Kg\\(^2\\) e \\(\\sigma_{2}^2=127,0\\) Kg\\(^2\\);\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=110,0 - 107,0 = 3,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025 \\Rightarrow Z_{0,025}=1,96\\) (Tabela A 1).\n\nAtravés da expressão (9.11), tem-se que:\n\\[\n3,0-1,96\\sqrt{\\frac{166,0}{10}+\\frac{127,0}{11}} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n3,0+1,96\\sqrt{\\frac{166,0}{10}+\\frac{127,0}{11}}\n\\]\n\\[\n3,0-10,4 &lt; (\\mu_1 - \\mu_2) &lt; 3,0+10,4.\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-7,4 kg; 13,4 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -7,4 e 13,4 kg. Como o intervalo de confiança abrange o zero, pode-se concluir que o peso médio da raça 1 não difere do peso médio raça 2. Caso o intervalo de confiança não tivesse abrangido o zero, concluiria-se que as médias difeririam entre si.\n\n\n\n9.7.3.2 Pequenas Amostras e Variâncias Populacionais Desconhecidas\nO intervalo de confiança associado a um determinado nível de confiança, para a diferença entre duas médias, \\(\\mu_1 - \\mu_2\\), quando se tem pequenas amostras, \\(n_1 &lt; 30\\) e \\(n_2 &lt; 30\\), e variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), desconhecidas, pode ser determinado considerando as seguintes situações:\n\nVariâncias Populacionais Iguais: Neste caso, para saber se as variâncias populacionais, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\), são iguais, deve-se fazer primeiro o Teste F, o qual será visto com detalhes no Capítulo 10.\n\nDessa forma, um intervalo de confiança de \\((1 - \\alpha)100,0\\%\\), para a diferença de médias, \\(\\mu_1 - \\mu_2\\), pode ser construído utilizando a distribuição \\(t\\), e é dado pela expressão (9.12).\n\\[\nP\\left[(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{s_{p}^2\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)} &lt; (\\mu_1 - \\mu_2) &lt; \\right.\n\\] \\[\n\\left.(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{s_{p}^2\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)} \\right]=1 - \\alpha,\n\\tag{9.12}\\]\nem que:\n\n\\(s_{p}^2=\\frac{(n_{1}-1)s_{1}^2+(n_{2}-1)s_{2}^2}{n_{1}+n_{2}-2}\\) (variância ponderada);\n\\(t_{\\left(\\nu; \\frac{\\alpha}{2}\\right)}\\) é o valor tabelado de \\(t\\), para: \\(\\nu=n_{1}+n_{2} -2\\) graus de liberdade, que deixa uma probabilidade acima dele de \\(\\frac{\\alpha}{2}\\).\n\n\nExemplo 9.17  \nSejam:\n\n\\(X_1:\\) Peso de suínos da raça 1, em kg;\n\n\n\\(X_2:\\) Peso de suínos da raça 2, em kg.\n\nSe da população de suínos da raça 1 e da raça 2, são retiradas amostras de tamanhos: \\(n_1 = 10\\) e \\(n_2 = 11\\), respectivamente, obtendo-se: \\(\\bar{x}_{1}=112,0\\) kg e \\(s_{1}^2=156,0\\) kg\\(^2\\); \\(\\bar{x}_{2}=105,0\\) kg e \\(s_{2}^2=165,0\\) kg\\(^2\\).\nConsiderando que, \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) são iguais, construir um intervalo de confiança de 95,0% de confiança para a diferença de médias das duas raças.\nTem-se então que:\n\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=112,0 - 105,0 = 7,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(s_{p}^2=\\frac{(n_{1}-1)s_{1}^2+(n_{2}-1)s_{2}^2}{n_{1}+n_{2}-2}=\\frac{(10-1)156,0+(11-1)165,0}{10+11-2}=160,74\\) kg\\(^2\\);\n\\(v=n_{1}+n_{2} -2=10+11-2=19\\) graus de liberdade.\n\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930.\nLogo,\n\n\\(t_{\\left(v;\\frac{\\alpha}{2}\\right)}=t_{\\left(19; 0,025\\right)}=2,0930\\).\n\nAtravés da expressão (9.12), tem-se que:\n\\[\n7,0-2,0930\\sqrt{160,74\\left(\\frac{1}{10}+\\frac{1}{11} \\right)} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n7,0+2,0930\\sqrt{160,74\\left(\\frac{1}{10}+\\frac{1}{11} \\right)}\n\\]\n\\[\n7,0-11,60 &lt; (\\mu_1 - \\mu_2) &lt; 7,0+11,60.\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-4,60 kg; 18,60 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -4,60 e 18,60 kg. Pode-se concluir que, as duas raças de suínos não diferem entre si com relação ao peso médio, pois o intervalo de confiança abrange o zero.\n\n\nVariâncias Populacionais Diferentes:\n\nNeste caso, também deve-se fazer primeiro o Teste F para verificar se as variâncias são diferentes.\nO intervalo de confiança de \\((1 - \\alpha)100,0\\%\\), para a diferença de médias, \\(\\mu_1 - \\mu_2\\), é dado pela expressão 9.13. \\[\nP\\left[(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)} &lt; (\\mu_1 - \\mu_2) &lt; \\right.\n\\] \\[\n\\left.(\\bar{x}_1-\\bar{x}_2)-t_{\\left(v;\\frac{\\alpha}{2}\\right)}\\sqrt{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)} \\right]=1 - \\alpha,\n\\tag{9.13}\\] em que: \\(t_{\\left(\\nu; \\frac{\\alpha}{2}\\right)}\\) é o valor tabelado de \\(t\\) com \\(\\nu\\) graus de liberdade que deixa uma probabilidade acima dele de \\(\\frac{\\alpha}{2}\\), sendo “\\(\\nu\\)” dado pela expressão (9.14).\n\\[\n\\nu=\\frac{\\left(\\frac{s_{1}^2}{n_1}+\\frac{s_{2}^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_{1}^2}{n_1}\\right)^2}{n_{1}-1}+\\frac{\\left(\\frac{s_{2}^2}{n_2}\\right)^2}{n_{2}-1}},\n\\tag{9.14}\\] conhecida como Fórmula de Satterthwaite.\n\nExemplo 9.18 Considerando o Exemplo 9.17, e supondo que \\(\\sigma_{1}^2\\) e \\(\\sigma_{2}^2\\) sejam estatisticamente diferentes, construir um intervalo de confiança de 95,0% de confiança para a diferença de médias das duas raças.\nAssim, tem-se que:\n\n\\(({\\bar{\\text{x}}_1-\\bar{\\text{x}_2}})=112,0 - 105,0 = 7,0\\) kg \\(\\Rightarrow\\) estimativa por ponto de \\((\\mu_1 - \\mu_2)\\);\n\\((1 - \\alpha)=0,95 \\Rightarrow \\alpha=0,05 \\Rightarrow \\frac{\\alpha}{2}=0,025\\);\n\\(\\nu=\\frac{\\left(\\frac{156,0}{10}+\\frac{165,0}{11}\\right)^2}{\\frac{\\left(\\frac{156,0}{10}\\right)^2}{10-1}+\\frac{\\left(\\frac{165,0}{11}\\right)^2}{11-1}}=19\\) graus de liberdade.\n\nConsultando a Tabela A 3, tem-se que o valor de \\(t\\) que deixa uma probabilidade acima dele de 2,5% com 19 graus de liberdade é igual a 2,0930. Logo,\n\n\\(t_{\\left(v;\\frac{\\alpha}{2}\\right)}=t_{(19; 0,025)}=2,0930\\).\n\n Através de (9.13), tem-se que:\n\\[\n7,0-2,0930\\sqrt{\\left(\\frac{156,0}{10}+\\frac{165,0}{11} \\right)} &lt; (\\mu_1 - \\mu_2) &lt;\n\\] \\[\n7,0+2,0930\\sqrt{\\left(\\frac{156,0}{10}+\\frac{165,0}{11} \\right)}\n\\]\nLogo,\n\n\\(\\Rightarrow IC_{0,95}(\\mu_1 - \\mu_2)\\):[-4,58 kg; 18,58 kg].\n\n Esse resultado mostra que é de 95,0% a confiança, da verdadeira diferença dos pesos médios entre as duas raças de suínos estar entre -4,58 e 18,58 kg. Pode-se concluir que, as duas raças de suínos não diferem entre si com relação ao peso médio, pois o intervalo de confiança abrange o zero. Considere a Tabela 9.1.\n\n\n\n\n9.7.4 Intervalo de Confiança para a Média em Amostras Dependentes\nA análise em amostras dependentes é apropriada quando a variável é medida antes e depois, por exemplo, peso de suínos antes e depois de serem submetidos a uma dieta com uma ração especial.\n\n\n\nTabela 9.1: Amostras dependentes.\n\n\n\n\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da Estimação</span>"
    ]
  },
  {
    "objectID": "cap10.html",
    "href": "cap10.html",
    "title": "10  Teoria da Decisão",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Teoria da Decisão</span>"
    ]
  },
  {
    "objectID": "cap11.html",
    "href": "cap11.html",
    "title": "11  Correlação e Regressão Linear Simples",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlação e Regressão Linear Simples</span>"
    ]
  },
  {
    "objectID": "tabelas.html",
    "href": "tabelas.html",
    "title": "Tabelas",
    "section": "",
    "text": "Tabela A 1: Distribuição normal padronizada. Probabilidades do valor de \\(Z\\) estar entre 0,0 e o valor de \\(Z\\) padronizado \\((Z_c)\\) – \\(P(0,0 &lt; Z &lt; Z_c)\\). Para valores negativos de \\(Z\\) as probabilidades são obtidas por simetria.    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbf{Z_c}\\)\n0,00\n0,01\n0,02\n0,03\n0,04\n0,05\n0,06\n0,07\n0,08\n0,09\n\n\n\n\n0,0\n0,0000\n0,0040\n0,0080\n0,0120\n0,0160\n0,0199\n0,0239\n0,0279\n0,0319\n0,0359\n\n\n0,1\n0,0398\n0,0438\n0,0478\n0,0517\n0,0557\n0,0596\n0,0636\n0,0675\n0,0714\n0,0753\n\n\n0,2\n0,0793\n0,0832\n0,0871\n0,0910\n0,0948\n0,0987\n0,1026\n0,1064\n0,1103\n0,1141\n\n\n0,3\n0,1179\n0,1217\n0,1255\n0,1293\n0,1331\n0,1368\n0,1406\n0,1443\n0,1480\n0,1517\n\n\n0,4\n0,1554\n0,1591\n0,1628\n0,1664\n0,1700\n0,1736\n0,1772\n0,1808\n0,1844\n0,1879\n\n\n0,5\n0,1915\n0,1950\n0,1985\n0,2019\n0,2054\n0,2088\n0,2123\n0,2157\n0,2190\n0,2224\n\n\n0,6\n0,2257\n0,2291\n0,2324\n0,2357\n0,2389\n0,2422\n0,2454\n0,2486\n0,2517\n0,2549\n\n\n0,7\n0,2580\n0,2611\n0,2642\n0,2673\n0,2704\n0,2734\n0,2764\n0,2794\n0,2823\n0,2852\n\n\n0,8\n0,2881\n0,2910\n0,2939\n0,2967\n0,2995\n0,3023\n0,3051\n0,3078\n0,3106\n0,3133\n\n\n0,9\n0,3159\n0,3186\n0,3212\n0,3238\n0,3264\n0,3289\n0,3315\n0,3340\n0,3365\n0,3389\n\n\n1,0\n0,3413\n0,3438\n0,3461\n0,3485\n0,3508\n0,3531\n0,3554\n0,3577\n0,3599\n0,3621\n\n\n1,1\n0,3643\n0,3665\n0,3686\n0,3708\n0,3729\n0,3749\n0,3770\n0,3790\n0,3810\n0,3830\n\n\n1,2\n0,3849\n0,3869\n0,3888\n0,3907\n0,3925\n0,3944\n0,3962\n0,3980\n0,3997\n0,4015\n\n\n1,3\n0,4032\n0,4049\n0,4066\n0,4082\n0,4099\n0,4115\n0,4131\n0,4147\n0,4162\n0,4177\n\n\n1,4\n0,4192\n0,4207\n0,4222\n0,4236\n0,4251\n0,4265\n0,4279\n0,4292\n0,4306\n0,4319\n\n\n1,5\n0,4332\n0,4345\n0,4357\n0,4370\n0,4382\n0,4394\n0,4406\n0,4418\n0,4429\n0,4441\n\n\n1,6\n0,4452\n0,4463\n0,4474\n0,4484\n0,4495\n0,4505\n0,4515\n0,4525\n0,4535\n0,4545\n\n\n1,7\n0,4554\n0,4564\n0,4573\n0,4582\n0,4591\n0,4599\n0,4608\n0,4616\n0,4625\n0,4633\n\n\n1,8\n0,4641\n0,4649\n0,4656\n0,4664\n0,4671\n0,4678\n0,4686\n0,4693\n0,4699\n0,4706\n\n\n1,9\n0,4713\n0,4719\n0,4726\n0,4732\n0,4738\n0,4744\n0,4750\n0,4756\n0,4761\n0,4767\n\n\n2,0\n0,4772\n0,4778\n0,4783\n0,4788\n0,4793\n0,4798\n0,4803\n0,4808\n0,4812\n0,4817\n\n\n2,1\n0,4821\n0,4826\n0,4830\n0,4834\n0,4838\n0,4842\n0,4846\n0,4850\n0,4854\n0,4857\n\n\n2,2\n0,4861\n0,4864\n0,4868\n0,4871\n0,4875\n0,4878\n0,4881\n0,4884\n0,4887\n0,4890\n\n\n2,3\n0,4893\n0,4896\n0,4898\n0,4901\n0,4904\n0,4906\n0,4909\n0,4911\n0,4913\n0,4916\n\n\n2,4\n0,4918\n0,4920\n0,4922\n0,4925\n0,4927\n0,4929\n0,4931\n0,4932\n0,4934\n0,4936\n\n\n2,5\n0,4938\n0,4940\n0,4941\n0,4943\n0,4945\n0,4946\n0,4948\n0,4949\n0,4951\n0,4952\n\n\n2,6\n0,4953\n0,4955\n0,4956\n0,4957\n0,4959\n0,4960\n0,4961\n0,4962\n0,4963\n0,4964\n\n\n2,7\n0,4965\n0,4966\n0,4967\n0,4968\n0,4969\n0,4970\n0,4971\n0,4972\n0,4973\n0,4974\n\n\n2,8\n0,4974\n0,4975\n0,4976\n0,4977\n0,4977\n0,4978\n0,4979\n0,4979\n0,4980\n0,4981\n\n\n2,9\n0,4981\n0,4982\n0,4982\n0,4983\n0,4984\n0,4984\n0,4985\n0,4985\n0,4986\n0,4986\n\n\n3,0\n0,4987\n0,4987\n0,4987\n0,4988\n0,4988\n0,4989\n0,4989\n0,4989\n0,4990\n0,4990\n\n\n3,1\n0,4990\n0,4991\n0,4991\n0,4991\n0,4992\n0,4992\n0,4992\n0,4992\n0,4993\n0,4993\n\n\n3,2\n0,4993\n0,4993\n0,4994\n0,4994\n0,4994\n0,4994\n0,4994\n0,4995\n0,4995\n0,4995\n\n\n3,3\n0,4995\n0,4995\n0,4995\n0,4996\n0,4996\n0,4996\n0,4996\n0,4996\n0,4996\n0,4997\n\n\n3,4\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4997\n0,4998\n\n\n3,5\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n0,4998\n\n\n3,6\n0,4998\n0,4998\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,7\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,8\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n0,4999\n\n\n3,9\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n0,5000\n\n\n\n\n\n\n\n\n\nTabela A 2: Distribuição normal padronizada. Probabilidades do valor de \\(Z\\) ser maior que o de valor de \\(Z\\) padronizado \\((Z_c)\\) ser igual a \\(\\alpha\\). \\(P(Z &gt; Z_{c}) = \\alpha\\). Para valores negativos de \\(Z\\) as probabilidades são obtidas por simetria. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbf{Z_c}\\)\n0,00\n0,01\n0,02\n0,03\n0,04\n0,05\n0,06\n0,07\n0,08\n0,09\n\n\n\n\n0,0\n0,5000\n0,4960\n0,4920\n0,4880\n0,4840\n0,4801\n0,4761\n0,4721\n0,4681\n0,4641\n\n\n0,1\n0,4602\n0,4562\n0,4522\n0,4483\n0,4443\n0,4404\n0,4364\n0,4325\n0,4286\n0,4247\n\n\n0,2\n0,4207\n0,4168\n0,4129\n0,409\n0,4052\n0,4013\n0,3974\n0,3936\n0,3897\n0,3859\n\n\n0,3\n0,3821\n0,3783\n0,3745\n0,3707\n0,3669\n0,3632\n0,3594\n0,3557\n0,352\n0,3483\n\n\n0,4\n0,3446\n0,3409\n0,3372\n0,3336\n0,33\n0,3264\n0,3228\n0,3192\n0,3156\n0,3121\n\n\n0,5\n0,3085\n0,305\n0,3015\n0,2981\n0,2946\n0,2912\n0,2877\n0,2843\n0,281\n0,2776\n\n\n0,6\n0,2743\n0,2709\n0,2676\n0,2643\n0,2611\n0,2578\n0,2546\n0,2514\n0,2483\n0,2451\n\n\n0,7\n0,242\n0,2389\n0,2358\n0,2327\n0,2296\n0,2266\n0,2236\n0,2206\n0,2177\n0,2148\n\n\n0,8\n0,2119\n0,209\n0,2061\n0,2033\n0,2005\n0,1977\n0,1949\n0,1922\n0,1894\n0,1867\n\n\n0,9\n0,1841\n0,1814\n0,1788\n0,1762\n0,1736\n0,1711\n0,1685\n0,1660\n0,1635\n0,1611\n\n\n1,0\n0,1587\n0,1562\n0,1539\n0,1515\n0,1492\n0,1469\n0,1446\n0,1423\n0,1401\n0,1379\n\n\n1,1\n0,1357\n0,1335\n0,1314\n0,1292\n0,1271\n0,1251\n0,1230\n0,1210\n0,1190\n0,1170\n\n\n1,2\n0,1151\n0,1131\n0,1112\n0,1093\n0,1075\n0,1056\n0,1038\n0,1020\n0,1003\n0,0985\n\n\n1,3\n0,0968\n0,0951\n0,0934\n0,0918\n0,0901\n0,0885\n0,0869\n0,0853\n0,0838\n0,0823\n\n\n1,4\n0,0808\n0,0793\n0,0778\n0,0764\n0,0749\n0,0735\n0,0721\n0,0708\n0,0694\n0,0681\n\n\n1,5\n0,0668\n0,0655\n0,0643\n0,063\n0,0618\n0,0606\n0,0594\n0,0582\n0,0571\n0,0559\n\n\n1,6\n0,0548\n0,0537\n0,0526\n0,0516\n0,0505\n0,0495\n0,0485\n0,0475\n0,0465\n0,0455\n\n\n1,7\n0,0446\n0,0436\n0,0427\n0,0418\n0,0409\n0,0401\n0,0392\n0,0384\n0,0375\n0,0367\n\n\n1,8\n0,0359\n0,0351\n0,0344\n0,0336\n0,0329\n0,0322\n0,0314\n0,0307\n0,0301\n0,0294\n\n\n1,9\n0,0287\n0,0281\n0,0274\n0,0268\n0,0262\n0,0256\n0,0250\n0,0244\n0,0239\n0,0233\n\n\n2,0\n0,0228\n0,0222\n0,0217\n0,0212\n0,0207\n0,0202\n0,0197\n0,0192\n0,0188\n0,0183\n\n\n2,1\n0,0179\n0,0174\n0,0170\n0,0166\n0,0162\n0,0158\n0,0154\n0,015\n0,0146\n0,0143\n\n\n2,2\n0,0139\n0,0136\n0,0132\n0,0129\n0,0125\n0,0122\n0,0119\n0,0116\n0,0113\n0,011\n\n\n2,3\n0,0107\n0,0104\n0,0102\n0,0099\n0,0096\n0,0094\n0,0091\n0,0089\n0,0087\n0,0084\n\n\n2,4\n0,0082\n0,0080\n0,0078\n0,0075\n0,0073\n0,0071\n0,0069\n0,0068\n0,0066\n0,0064\n\n\n2,5\n0,0062\n0,0060\n0,0059\n0,0057\n0,0055\n0,0054\n0,0052\n0,0051\n0,0049\n0,0048\n\n\n2,6\n0,0047\n0,0045\n0,0044\n0,0043\n0,0041\n0,0040\n0,0039\n0,0038\n0,0037\n0,0036\n\n\n2,7\n0,0035\n0,0034\n0,0033\n0,0032\n0,0031\n0,0030\n0,0029\n0,0028\n0,0027\n0,0026\n\n\n2,8\n0,0026\n0,0025\n0,0024\n0,0023\n0,0023\n0,0022\n0,0021\n0,0021\n0,0020\n0,0019\n\n\n2,9\n0,0019\n0,0018\n0,0018\n0,0017\n0,0016\n0,0016\n0,0015\n0,0015\n0,0014\n0,0014\n\n\n3,0\n0,0013\n0,0013\n0,0013\n0,0012\n0,0012\n0,0011\n0,0011\n0,0011\n0,0010\n0,0010\n\n\n3,1\n0,0010\n0,0009\n0,0009\n0,0009\n0,0008\n0,0008\n0,0008\n0,0008\n0,0007\n0,0007\n\n\n3,2\n0,0007\n0,0007\n0,0006\n0,0006\n0,0006\n0,0006\n0,0006\n0,0005\n0,0005\n0,0005\n\n\n3,3\n0,0005\n0,0005\n0,0005\n0,0004\n0,0004\n0,0004\n0,0004\n0,0004\n0,0004\n0,0003\n\n\n3,4\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0003\n0,0002\n\n\n3,5\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n0,0002\n\n\n3,6\n0,0002\n0,0002\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,7\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,8\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n0,0001\n\n\n3,9\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n0,0000\n\n\n\n\n\n\n\n\n\nTabela A 3: Distribuição \\(t-Student\\). Valores de \\(t_{(\\nu; \\alpha)}\\), tal que: \\(P(t &gt; t_{(\\nu; \\alpha)}) = \\alpha\\). Para valores negativos de \\(t_{(\\nu; \\alpha)}\\) os valores de \\(\\alpha\\) são os mesmos, apenas sendo visualizado para o lado esquerdo do gráfico da distribuição \\(t-Student\\), por questão de simetria. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\nu\\)/\\(\\alpha\\)\n10,00%\n5,00%\n2,50%\n1,00%\n0,50%\n0,25%\n0,10%\n0,05%\n\n\n\n\n1\n3,0777\n6,3137\n12,7062\n31,8210\n63,6559\n127,3211\n318,2888\n636,5776\n\n\n2\n1,8856\n2,9200\n4,3027\n6,9645\n9,9250\n14,0892\n22,3285\n31,5998\n\n\n3\n1,6377\n2,3534\n3,1824\n4,5407\n5,8408\n7,4532\n10,2143\n12,9244\n\n\n4\n1,5332\n2,1318\n2,7765\n3,7469\n4,6041\n5,5975\n7,1729\n8,6101\n\n\n5\n1,4759\n2,0150\n2,5706\n3,3649\n4,0321\n4,7733\n5,8935\n6,8685\n\n\n6\n1,4398\n1,9432\n2,4469\n3,1427\n3,7074\n4,3168\n5,2075\n5,9587\n\n\n7\n1,4149\n1,8946\n2,3646\n2,9979\n3,4995\n4,0294\n4,7853\n5,4081\n\n\n8\n1,3968\n1,8595\n2,3060\n2,8965\n3,3554\n3,8325\n4,5008\n5,0414\n\n\n9\n1,3830\n1,8331\n2,2622\n2,8214\n3,2498\n3,6896\n4,2969\n4,7809\n\n\n10\n1,3722\n1,8125\n2,2281\n2,7638\n3,1693\n3,5814\n4,1437\n4,5868\n\n\n11\n1,3634\n1,7959\n2,2010\n2,7181\n3,1058\n3,4966\n4,0248\n4,4369\n\n\n12\n1,3562\n1,7823\n2,1788\n2,6810\n3,0545\n3,4284\n3,9296\n4,3178\n\n\n13\n1,3502\n1,7709\n2,1604\n2,6503\n3,0123\n3,3725\n3,8520\n4,2209\n\n\n14\n1,3450\n1,7613\n2,1448\n2,6245\n2,9768\n3,3257\n3,7874\n4,1403\n\n\n15\n1,3406\n1,7531\n2,1315\n2,6025\n2,9467\n3,2860\n3,7329\n4,0728\n\n\n16\n1,3368\n1,7459\n2,1199\n2,5835\n2,9208\n3,2520\n3,6861\n4,0149\n\n\n17\n1,3334\n1,7396\n2,1098\n2,5669\n2,8982\n3,2224\n3,6458\n3,9651\n\n\n18\n1,3304\n1,7341\n2,1009\n2,5524\n2,8784\n3,1966\n3,6105\n3,9217\n\n\n19\n1,3277\n1,7291\n2,0930\n2,5395\n2,8609\n3,1737\n3,5793\n3,8833\n\n\n20\n1,3253\n1,7247\n2,0860\n2,5280\n2,8453\n3,1534\n3,5518\n3,8496\n\n\n21\n1,3232\n1,7207\n2,0796\n2,5176\n2,8314\n3,1352\n3,5271\n3,8193\n\n\n22\n1,3212\n1,7171\n2,0739\n2,5083\n2,8188\n3,1188\n3,5050\n3,7922\n\n\n23\n1,3195\n1,7139\n2,0687\n2,4999\n2,8073\n3,1040\n3,4850\n3,7676\n\n\n24\n1,3178\n1,7109\n2,0639\n2,4922\n2,7970\n3,0905\n3,4668\n3,7454\n\n\n25\n1,3163\n1,7081\n2,0595\n2,4851\n2,7874\n3,0782\n3,4502\n3,7251\n\n\n26\n1,3150\n1,7056\n2,0555\n2,4786\n2,7787\n3,0669\n3,4350\n3,7067\n\n\n27\n1,3137\n1,7033\n2,0518\n2,4727\n2,7707\n3,0565\n3,4210\n3,6895\n\n\n28\n1,3125\n1,7011\n2,0484\n2,4671\n2,7633\n3,0470\n3,4082\n3,6739\n\n\n29\n1,3114\n1,6991\n2,0452\n2,4620\n2,7564\n3,0380\n3,3963\n3,6595\n\n\n30\n1,3104\n1,6973\n2,0423\n2,4573\n2,7500\n3,0298\n3,3852\n3,6460\n\n\n31\n1,3095\n1,6955\n2,0395\n2,4528\n2,7440\n3,0221\n3,3749\n3,6335\n\n\n32\n1,3086\n1,6939\n2,0369\n2,4487\n2,7385\n3,0149\n3,3653\n3,6218\n\n\n33\n1,3077\n1,6924\n2,0345\n2,4448\n2,7333\n3,0082\n3,3563\n3,6109\n\n\n34\n1,3070\n1,6909\n2,0322\n2,4411\n2,7284\n3,0020\n3,3480\n3,6007\n\n\n35\n1,3062\n1,6896\n2,0301\n2,4377\n2,7238\n2,9961\n3,3400\n3,5911\n\n\n36\n1,3055\n1,6883\n2,0281\n2,4345\n2,7195\n2,9905\n3,3326\n3,5821\n\n\n37\n1,3049\n1,6871\n2,0262\n2,4314\n2,7154\n2,9853\n3,3256\n3,5737\n\n\n38\n1,3042\n1,6860\n2,0244\n2,4286\n2,7116\n2,9803\n3,3190\n3,5657\n\n\n39\n1,3036\n1,6849\n2,0227\n2,4258\n2,7079\n2,9756\n3,3127\n3,5581\n\n\n40\n1,3031\n1,6839\n2,0211\n2,4233\n2,7045\n2,9712\n3,3069\n3,5510\n\n\n50\n1,2987\n1,6759\n2,0086\n2,4033\n2,6778\n2,9370\n3,2614\n3,4960\n\n\n60\n1,2958\n1,6706\n2,0003\n2,3901\n2,6603\n2,9146\n3,2317\n3,4602\n\n\n120\n1,2886\n1,6576\n1,9799\n2,3578\n2,6174\n2,8599\n3,1595\n3,3734\n\n\n200\n1,2858\n1,6525\n1,9719\n2,3451\n2,6006\n2,8385\n3,1315\n3,3398\n\n\n400\n1,2837\n1,6487\n1,9659\n2,3357\n2,5882\n2,8227\n3,1108\n3,3151\n\n\n600\n1,2830\n1,6474\n1,9639\n2,3326\n2,5841\n2,8175\n3,1039\n3,3068\n\n\n\\(\\infty\\)\n1,2816\n1,6449\n1,9600\n2,3264\n2,5759\n2,8071\n3,0903\n3,2906\n\n\n\n\n\n\n\n\n\n\nBANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação Agrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos Agrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem. São Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à Inferência Estatística. 2. ed. São Paulo: SBM, 2010. p. 159\n\n\nCOCHRAN, W.; COX, G. M. Experimental Designs. 2. ed. New York: John Wiley & Sons, 2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo: Saraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso Introdutório. 3. ed. São Paulo: EDUSP, 2008. p. 256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis. 3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias. 3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de Probabilidade e Estatística. 7. ed. São Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística. 2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of Experiments. 9. ed. New Jersey: Wiley, 2019. p. 752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada e Probabilidade para Engenheiros. 7. ed. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the Theory of Statistics. New York: John Wiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística. São Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística Experimental. 15. ed. Piracicaba: FEALQ, 2022. p. 451\n\n\nSILVA, N. N. Amostragem Probabilística. 3. ed. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de Regressão Linear e Não-Linear. Brasília: EMBRAPA, 1998. p. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of statistics: A biometrical approach. 2. ed. New York: McGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Tabelas"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "BANZATTO, D. A.; NASCIMENTO KRONKA, S. DO. Experimentação\nAgrícola. Jaboticabal: Funep, 2006. p. 237\n\n\nBARBIN, D. Planejamento e Análise Estatística de Experimentos\nAgrômica. Arapongas: Midas, 2003. p. 208\n\n\nBOLFARINE, H.; BUSSAB, W. O. Elementos de Amostragem.\nSão Paulo: Edgard Blucher, 2005. p. 274\n\n\nBOLFARINE, H.; SANDOVAL, M. C. Introdução à\nInferência Estatística. 2. ed. São\nPaulo: SBM, 2010. p. 159\n\n\nBUSSAB, W. O.; MORETTIN, P. A. Estatística Básica. 6.\ned. São Paulo: Saraiva, 2010. p. 526\n\n\nCOCHRAN, W.; COX, G. M. Experimental\nDesigns. 2. ed. New York: John Wiley & Sons,\n2005. p. 618\n\n\nCRESPO, A. A. Estatística Fácil. 19. ed. São Paulo:\nSaraiva, 2009. p. 232\n\n\nDANTAS, C. A. B. Probabilidade: Um Curso\nIntrodutório. 3. ed. São Paulo: EDUSP, 2008. p.\n256\n\n\nDRAPER, N. R.; SMITH, H. Applied regression analysis.\n3. ed. New York: Wiley, 1998. p. 736\n\n\nMAGALHAES, M. N. Probabilidade e variáveis aleatórias.\n3. ed. São Paulo: EDUSP, 2011. p. 424\n\n\nMAGALHAES, M. N.; LIMA, A. C. P. Noções de\nProbabilidade e Estatística. 7. ed.\nSão Paulo: EDUSP, 2023. p. 428\n\n\nMEYER, P. L. Probabilidade: aplicações á estatística.\n2. ed. Rio de Janeiro: LTC, 2000. p. 426\n\n\nMONTGOMERY, D. C. Design and Analysis of\nExperiments. 9. ed. New Jersey: Wiley, 2019. p.\n752\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatísta Aplicada\ne Probabilidade para Engenheiros. 7.\ned. Rio de Janeiro: LTC, 2021. p. 416\n\n\nMOOD, A. M.; GRAYBILL, F. A.; BOES, D. C. Introduction to the\nTheory of Statistics. New York: John\nWiley & Sons, 1974. p. 564\n\n\nPAGANO, M.; GAUVREAU, K. Princípios de Bioestatística.\nSão Paulo: Thomson, 2004. p. 506\n\n\nPIMENTEL-GOMES, F. Curso de Estatística\nExperimental. 15. ed. Piracicaba: FEALQ, 2022. p.\n451\n\n\nSILVA, N. N. Amostragem Probabilística. 3.\ned. São Paulo: EDUSP, 2015. p. 136\n\n\nSOUZA, G. S. Introdução aos Modelos de\nRegressão Linear e\nNão-Linear. Brasília: EMBRAPA, 1998.\np. 489\n\n\nSTEEL, R. G. D.; TORRIE, J. H. Principles and procedures of\nstatistics: A biometrical approach. 2. ed. New York:\nMcGraw-Hill Book Company, 1980. p. 512",
    "crumbs": [
      "Referências"
    ]
  }
]